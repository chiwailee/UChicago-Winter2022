{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: not using Google CoLab\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive', force_remount=True)\n",
    "    COLAB = True\n",
    "    print(\"Note: using Google CoLab\")\n",
    "    %tensorflow_version 2.x\n",
    "except:\n",
    "    print(\"Note: not using Google CoLab\")\n",
    "    COLAB = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from sklearn import metrics\n",
    "import datetime\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_sequences(seq_size, obs):\n",
    "    x = []\n",
    "    y = []\n",
    "\n",
    "    for i in range(len(obs)-SEQUENCE_SIZE):\n",
    "        #print(i)\n",
    "        window = obs[i:(i+SEQUENCE_SIZE)]\n",
    "        after_window = obs[i+SEQUENCE_SIZE]\n",
    "        window = [[x] for x in window]\n",
    "        #print(\"{} - {}\".format(window,after_window))\n",
    "        x.append(window)\n",
    "        y.append(after_window)\n",
    "        \n",
    "    return np.array(x),np.array(y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transformer_encoder(inputs, head_size, num_heads, ff_dim, dropout=0):\n",
    "    # Normalization and Attention\n",
    "    x = layers.LayerNormalization(epsilon=1e-6)(inputs)\n",
    "    x = layers.MultiHeadAttention(\n",
    "        key_dim=head_size, num_heads=num_heads, dropout=dropout\n",
    "    )(x, x)\n",
    "    x = layers.Dropout(dropout)(x)\n",
    "    res = x + inputs\n",
    "\n",
    "    # Feed Forward Part\n",
    "    x = layers.LayerNormalization(epsilon=1e-6)(res)\n",
    "    x = layers.Conv1D(filters=ff_dim, kernel_size=1, activation=\"relu\")(x)\n",
    "    x = layers.Dropout(dropout)(x)\n",
    "    x = layers.Conv1D(filters=inputs.shape[-1], kernel_size=1)(x)\n",
    "    return x + res\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(\n",
    "    input_shape,\n",
    "    head_size,\n",
    "    num_heads,\n",
    "    ff_dim,\n",
    "    num_transformer_blocks,\n",
    "    mlp_units,\n",
    "    dropout=0,\n",
    "    mlp_dropout=0,\n",
    "):\n",
    "    inputs = keras.Input(shape=input_shape)\n",
    "    x = inputs\n",
    "    for _ in range(num_transformer_blocks):\n",
    "        x = transformer_encoder(x, head_size, num_heads, ff_dim, dropout)\n",
    "\n",
    "    #x = layers.GlobalAveragePooling2D(data_format=\"channels_first\")(x)\n",
    "    x = layers.GlobalAveragePooling1D(data_format=\"channels_first\")(x)\n",
    "    for dim in mlp_units:\n",
    "        x = layers.Dense(dim, activation=\"relu\")(x)\n",
    "        x = layers.Dropout(mlp_dropout)(x)\n",
    "    outputs = layers.Dense(1)(x)\n",
    "    return keras.Model(inputs, outputs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0, array([0.00617791], dtype=float32), -0.00546775, -0.00546775], [1, array([0.00173255], dtype=float32), 0.0234365, 0.0234365], [2, array([-0.00107555], dtype=float32), -0.00078075, 0.00078075], [3, array([0.00076251], dtype=float32), -0.00625, -0.00625], [4, array([-0.0007264], dtype=float32), -0.05, 0.05], [5, array([0.00289931], dtype=float32), 0.001562, 0.001562], [6, array([0.00077582], dtype=float32), -0.01171875, -0.01171875], [7, array([-0.00166608], dtype=float32), 0.009376, -0.009376], [8, array([-0.00210872], dtype=float32), -0.003126, 0.003126], [9, array([0.00040555], dtype=float32), -0.01328075, -0.01328075], [10, array([0.00115814], dtype=float32), 0.0296875, 0.0296875], [11, array([-0.00460203], dtype=float32), 0.009375, -0.009375], [12, array([0.00050185], dtype=float32), -0.0265625, -0.0265625], [13, array([0.00418288], dtype=float32), 0.064062, 0.064062], [14, array([-0.00613332], dtype=float32), -0.02265625, 0.02265625], [15, array([0.0044188], dtype=float32), 0.0281255, 0.0281255], [16, array([-0.00277654], dtype=float32), 0.001563, -0.001563], [17, array([-0.00070494], dtype=float32), 0.01328125, -0.01328125], [18, array([-1.0616408e-05], dtype=float32), -0.023438, 0.023438], [19, array([0.00858804], dtype=float32), 0.00625, 0.00625], [20, array([0.00089296], dtype=float32), 0.06015625, 0.06015625], [21, array([-0.00484575], dtype=float32), -0.0187495, 0.0187495], [22, array([-0.00179436], dtype=float32), -0.01484375, 0.01484375], [23, array([-0.00212246], dtype=float32), 0.0015625, -0.0015625], [24, array([-0.00176537], dtype=float32), -0.03671925, 0.03671925], [25, array([0.00737179], dtype=float32), 0.092187, 0.092187], [26, array([-0.00524245], dtype=float32), 0.01640675, -0.01640675], [27, array([-0.00046627], dtype=float32), 0.009375, -0.009375], [28, array([-0.00380733], dtype=float32), -0.00390625, 0.00390625], [29, array([-0.00719234], dtype=float32), -0.02734375, 0.02734375], [30, array([0.00720136], dtype=float32), -0.01171825, -0.01171825], [31, array([0.01097228], dtype=float32), -0.0187505, -0.0187505], [32, array([0.00249604], dtype=float32), 0.00546925, 0.00546925], [33, array([-0.00054201], dtype=float32), -0.01328225, 0.01328225], [34, array([-0.00105946], dtype=float32), -0.01484375, 0.01484375], [35, array([0.00138547], dtype=float32), -0.026562, -0.026562], [36, array([-0.00108513], dtype=float32), 0.00546925, -0.00546925], [37, array([-0.00313228], dtype=float32), 0.01796775, -0.01796775], [38, array([-0.00200753], dtype=float32), 0.00234425, -0.00234425], [39, array([-0.00039524], dtype=float32), -0.051563, 0.051563], [0, array([1.1488388e-05], dtype=float32), -0.01796875, -0.01796875], [1, array([-0.00223229], dtype=float32), -0.05078175, 0.05078175], [2, array([0.00525362], dtype=float32), -0.05234425, -0.05234425], [3, array([0.0013318], dtype=float32), 0.00234425, 0.00234425], [4, array([-0.00231642], dtype=float32), 0.10859325, -0.10859325], [5, array([-0.00859621], dtype=float32), -0.0609375, 0.0609375], [6, array([0.00724884], dtype=float32), 0.03671975, 0.03671975], [7, array([-0.00756254], dtype=float32), -0.09453225, 0.09453225], [8, array([0.00648635], dtype=float32), -0.0437495, -0.0437495], [9, array([0.00761665], dtype=float32), 0.026563, 0.026563], [10, array([-0.00487091], dtype=float32), -0.04765675, 0.04765675], [11, array([0.00621043], dtype=float32), -0.00390625, -0.00390625], [12, array([-0.00550027], dtype=float32), 0.009375, -0.009375], [13, array([-0.00337517], dtype=float32), -0.079688, 0.079688], [14, array([0.00396407], dtype=float32), 0.04453175, 0.04453175], [15, array([-0.00139511], dtype=float32), -0.06953175, 0.06953175], [16, array([0.02040805], dtype=float32), 0.015625, 0.015625], [17, array([0.00835034], dtype=float32), 0.00546975, 0.00546975], [18, array([0.00152839], dtype=float32), 0.00546825, 0.00546825], [19, array([0.00428499], dtype=float32), -0.04609325, -0.04609325], [20, array([0.00332931], dtype=float32), -0.06171975, -0.06171975], [21, array([0.00462793], dtype=float32), 0.00859475, 0.00859475], [22, array([-0.00833336], dtype=float32), -0.0203135, 0.0203135], [23, array([-0.00287161], dtype=float32), 0.02109425, -0.02109425], [24, array([-0.01226306], dtype=float32), -0.0031245, 0.0031245], [25, array([-0.00193276], dtype=float32), -0.010938, 0.010938], [26, array([-0.00308635], dtype=float32), 0.03125, -0.03125], [27, array([-0.00310514], dtype=float32), 0.00703075, -0.00703075], [28, array([-0.00188391], dtype=float32), 0.0046875, -0.0046875], [29, array([0.00060876], dtype=float32), 0.00546875, 0.00546875], [30, array([-0.00351211], dtype=float32), -0.00546775, 0.00546775], [31, array([0.00079405], dtype=float32), -0.0796875, -0.0796875], [32, array([0.0100346], dtype=float32), 0.03359275, 0.03359275], [33, array([-0.000318], dtype=float32), -0.0390625, 0.0390625], [34, array([0.00543598], dtype=float32), 0.010938, 0.010938], [35, array([-0.0014414], dtype=float32), 0.007813, -0.007813], [36, array([0.0029839], dtype=float32), -0.0187505, -0.0187505], [37, array([0.00412009], dtype=float32), -0.03046825, -0.03046825], [38, array([0.00467204], dtype=float32), -0.0093755, -0.0093755], [39, array([-0.00506719], dtype=float32), 0.01640625, -0.01640625], [0, array([-0.0209294], dtype=float32), 0.025, -0.025], [1, array([0.0161191], dtype=float32), 0.00546825, 0.00546825], [2, array([-0.00506127], dtype=float32), -0.07265575, 0.07265575], [3, array([0.02355838], dtype=float32), 0.06015625, 0.06015625], [4, array([-0.00236788], dtype=float32), 0.01328125, -0.01328125], [5, array([0.02676175], dtype=float32), 0.0937495, 0.0937495], [6, array([-0.00999558], dtype=float32), 0.01171925, -0.01171925], [7, array([0.01245243], dtype=float32), 0.02109375, 0.02109375], [8, array([0.00679693], dtype=float32), -0.035938, -0.035938], [9, array([0.02241916], dtype=float32), 0.01953175, 0.01953175], [10, array([-0.0099274], dtype=float32), 0.0093755, -0.0093755], [11, array([0.01783759], dtype=float32), -0.00625, -0.00625], [12, array([0.00155977], dtype=float32), -0.09765625, -0.09765625], [13, array([0.00426421], dtype=float32), -0.0046885, -0.0046885], [14, array([-0.00154721], dtype=float32), -0.010937, 0.010937], [15, array([-0.00188405], dtype=float32), -0.007813, 0.007813], [16, array([-0.00302363], dtype=float32), -0.003124, 0.003124], [17, array([-0.01014774], dtype=float32), -0.01015725, 0.01015725], [18, array([-0.00058056], dtype=float32), -0.021875, 0.021875], [19, array([-0.00449602], dtype=float32), 0.02265675, -0.02265675], [20, array([-0.00671546], dtype=float32), 0.0125005, -0.0125005], [21, array([0.00197536], dtype=float32), -0.006251, -0.006251], [22, array([-0.00166949], dtype=float32), 0.017188, -0.017188], [23, array([-0.00443112], dtype=float32), 0.04765575, -0.04765575], [24, array([-0.00804157], dtype=float32), -0.0624995, 0.0624995], [25, array([0.00533468], dtype=float32), -0.03515625, -0.03515625], [26, array([-0.00241187], dtype=float32), -0.02734325, 0.02734325], [27, array([0.00727179], dtype=float32), 0.01796775, 0.01796775], [28, array([-0.00415652], dtype=float32), -0.042187, 0.042187], [29, array([0.00094074], dtype=float32), 0.007812, 0.007812], [30, array([-0.00518629], dtype=float32), -0.010937, 0.010937], [31, array([-0.00858766], dtype=float32), 0.0046875, -0.0046875], [32, array([-0.00255356], dtype=float32), 0.04765575, -0.04765575], [33, array([-0.00679417], dtype=float32), -0.00703075, 0.00703075], [34, array([-0.00564085], dtype=float32), 0.04453125, -0.04453125], [35, array([-0.00481944], dtype=float32), 0.0234375, -0.0234375], [36, array([-0.00673742], dtype=float32), -0.020312, 0.020312], [37, array([-0.00097253], dtype=float32), -0.02421875, 0.02421875], [38, array([0.00354438], dtype=float32), 0.045312, 0.045312], [39, array([-0.00338585], dtype=float32), 0.0359375, -0.0359375], [0, array([-0.00259112], dtype=float32), 0.02109375, -0.02109375], [1, array([-0.00720434], dtype=float32), -0.025001, 0.025001], [2, array([0.00195172], dtype=float32), 0.01015625, 0.01015625], [3, array([-0.00575479], dtype=float32), 0.0828125, -0.0828125], [4, array([-0.00565678], dtype=float32), -0.02109275, 0.02109275], [5, array([0.00480478], dtype=float32), -0.00390675, -0.00390675], [6, array([-0.00038056], dtype=float32), 0.03984375, -0.03984375], [7, array([-0.00339347], dtype=float32), 0.035937, -0.035937], [8, array([-0.00255495], dtype=float32), -0.02421825, 0.02421825], [9, array([0.00548775], dtype=float32), 0.0281245, 0.0281245], [10, array([-0.007657], dtype=float32), -0.02734275, 0.02734275], [11, array([0.01284468], dtype=float32), 0.02109375, 0.02109375], [12, array([0.002529], dtype=float32), -0.00078125, -0.00078125], [13, array([0.00237548], dtype=float32), 0.0062495, 0.0062495], [14, array([-0.00089057], dtype=float32), 0.025, -0.025], [15, array([-0.00043454], dtype=float32), -0.0171875, 0.0171875], [16, array([0.00085855], dtype=float32), -0.05546875, -0.05546875], [17, array([0.00549524], dtype=float32), -0.05625, -0.05625], [18, array([0.006901], dtype=float32), -0.02578125, -0.02578125], [19, array([-0.00110695], dtype=float32), 0.0359375, -0.0359375], [20, array([-0.01318573], dtype=float32), -0.0062505, 0.0062505], [21, array([-0.0008988], dtype=float32), -0.02890625, 0.02890625], [22, array([-0.00595423], dtype=float32), -0.0906245, 0.0906245], [23, array([0.00870101], dtype=float32), 0.0296875, 0.0296875], [24, array([-0.00224902], dtype=float32), -0.0187495, 0.0187495], [25, array([0.0078493], dtype=float32), 0.048437, 0.048437], [26, array([-0.00170342], dtype=float32), -0.003125, 0.003125], [27, array([-0.00744322], dtype=float32), 0.023437, -0.023437], [28, array([-0.0025913], dtype=float32), 0.0359385, -0.0359385], [29, array([0.00461116], dtype=float32), 0.01640525, 0.01640525], [30, array([0.00111436], dtype=float32), -0.02578025, -0.02578025], [31, array([0.00591877], dtype=float32), -0.01328175, -0.01328175], [32, array([0.00035424], dtype=float32), -0.03046875, -0.03046875], [33, array([0.00491303], dtype=float32), -0.01015675, -0.01015675], [34, array([0.00034367], dtype=float32), 0.02109475, 0.02109475], [35, array([-0.00358423], dtype=float32), -0.0265635, 0.0265635], [36, array([0.00462171], dtype=float32), 0.00390675, 0.00390675], [37, array([-0.00309691], dtype=float32), 0.0281255, -0.0281255], [38, array([-0.0035809], dtype=float32), -0.004688, 0.004688], [39, array([-0.0018219], dtype=float32), 0.010938, -0.010938], [0, array([-0.00155481], dtype=float32), 0.0249995, -0.0249995], [1, array([0.00436289], dtype=float32), 0.087501, 0.087501], [2, array([-0.00340066], dtype=float32), -0.0125005, 0.0125005], [3, array([0.00613847], dtype=float32), -0.04609425, -0.04609425], [4, array([0.00479532], dtype=float32), 0.001563, 0.001563], [5, array([-0.00037716], dtype=float32), 0.02421825, -0.02421825], [6, array([-0.00212175], dtype=float32), -0.00859325, 0.00859325], [7, array([0.00426226], dtype=float32), -0.017187, -0.017187], [8, array([-0.01239831], dtype=float32), -0.009375, 0.009375], [9, array([0.00125898], dtype=float32), -0.010938, -0.010938], [10, array([-0.00190444], dtype=float32), 0.00078125, -0.00078125], [11, array([0.00262159], dtype=float32), 0.0468745, 0.0468745], [12, array([-0.00129946], dtype=float32), 0.004688, -0.004688], [13, array([-0.00293684], dtype=float32), -0.02734425, 0.02734425], [14, array([0.00255306], dtype=float32), 0.02265675, 0.02265675], [15, array([-0.00246799], dtype=float32), -0.00078125, 0.00078125], [16, array([-0.00061491], dtype=float32), 0.00546925, -0.00546925], [17, array([0.0021583], dtype=float32), -0.01953175, -0.01953175], [18, array([0.0007717], dtype=float32), 0.029687, 0.029687], [19, array([-0.00298843], dtype=float32), -0.0171875, 0.0171875], [20, array([0.00341355], dtype=float32), 0.025001, 0.025001], [21, array([0.00027768], dtype=float32), -0.0406255, -0.0406255], [22, array([0.00669659], dtype=float32), 0.01015575, 0.01015575], [23, array([-0.00140979], dtype=float32), -0.05703125, 0.05703125], [24, array([0.00868652], dtype=float32), 0.00390675, 0.00390675], [25, array([0.00070151], dtype=float32), 0.015625, 0.015625], [26, array([-0.00200649], dtype=float32), 0.028125, -0.028125], [27, array([-0.00892894], dtype=float32), -0.0124995, 0.0124995], [28, array([-2.9816641e-05], dtype=float32), -0.03046875, 0.03046875], [29, array([-0.00037634], dtype=float32), -0.01171925, 0.01171925], [30, array([-0.00039104], dtype=float32), -0.00234325, 0.00234325], [31, array([-0.00287896], dtype=float32), -0.026563, 0.026563], [32, array([0.00348493], dtype=float32), 0.0125005, 0.0125005], [33, array([-0.00496445], dtype=float32), -0.01015675, 0.01015675], [34, array([-0.00058259], dtype=float32), -0.01875, 0.01875], [35, array([0.00094154], dtype=float32), 0.03203125, 0.03203125], [36, array([-0.00299977], dtype=float32), -0.01015575, 0.01015575], [37, array([0.00068562], dtype=float32), 0.05234325, 0.05234325], [38, array([-0.00257865], dtype=float32), -0.00546825, 0.00546825], [39, array([0.00342127], dtype=float32), 0.0109365, 0.0109365], [0, array([0.0079603], dtype=float32), -0.01484325, -0.01484325], [1, array([-0.00393889], dtype=float32), -0.010938, 0.010938], [2, array([0.00247874], dtype=float32), -0.00390575, -0.00390575], [3, array([-0.00614595], dtype=float32), 0.0187495, -0.0187495], [4, array([-0.00648092], dtype=float32), -0.01640675, 0.01640675], [5, array([0.00187037], dtype=float32), -0.010937, -0.010937], [6, array([-0.00298194], dtype=float32), -0.0265625, 0.0265625], [7, array([0.00322209], dtype=float32), -0.0015625, -0.0015625], [8, array([-0.00223682], dtype=float32), 0.01875, -0.01875], [9, array([-0.00728491], dtype=float32), 0.009375, -0.009375], [10, array([-0.00236484], dtype=float32), 0.0562495, -0.0562495], [11, array([-0.01219557], dtype=float32), -0.001562, 0.001562], [12, array([0.00456174], dtype=float32), -0.01328075, -0.01328075], [13, array([0.00322842], dtype=float32), -0.01796925, -0.01796925], [14, array([0.00085567], dtype=float32), 0.0062495, 0.0062495], [15, array([-0.00033138], dtype=float32), -0.0656245, 0.0656245], [16, array([0.00637599], dtype=float32), -0.01640675, -0.01640675], [17, array([-0.00561201], dtype=float32), 0.01015625, -0.01015625], [18, array([-0.00333322], dtype=float32), 0.01328175, -0.01328175], [19, array([-0.00308158], dtype=float32), 0.023437, -0.023437], [20, array([-0.00014417], dtype=float32), 0.02265675, -0.02265675], [21, array([-0.00451708], dtype=float32), 0.04375, -0.04375], [22, array([-0.00414319], dtype=float32), 0.023437, -0.023437], [23, array([-0.0035703], dtype=float32), -0.03359275, 0.03359275], [24, array([-0.00253338], dtype=float32), -0.0078135, 0.0078135], [25, array([0.00488189], dtype=float32), -0.014062, -0.014062], [26, array([0.00400533], dtype=float32), -0.0187495, -0.0187495], [27, array([-0.00192246], dtype=float32), -0.03203125, 0.03203125], [28, array([0.00144529], dtype=float32), -0.0218755, -0.0218755], [29, array([0.00129839], dtype=float32), 0.01796925, 0.01796925], [30, array([-0.00731893], dtype=float32), -0.085938, 0.085938], [31, array([0.00620922], dtype=float32), -0.1, -0.1], [32, array([0.02037802], dtype=float32), 0.04453075, 0.04453075], [33, array([-0.00618503], dtype=float32), 0.05078125, -0.05078125], [34, array([-0.01009345], dtype=float32), -0.0015625, 0.0015625], [35, array([0.0014715], dtype=float32), 0.0437505, 0.0437505], [36, array([-0.0004467], dtype=float32), -0.00234375, 0.00234375], [37, array([0.00352835], dtype=float32), -0.07578125, -0.07578125], [38, array([-0.00657358], dtype=float32), 0.00546875, -0.00546875], [39, array([0.01098227], dtype=float32), -0.0265625, -0.0265625], [0, array([0.00380327], dtype=float32), 0.01328125, 0.01328125], [1, array([0.00837305], dtype=float32), 0.0625005, 0.0625005], [2, array([-0.00637782], dtype=float32), 0.02890625, -0.02890625], [3, array([0.01354715], dtype=float32), -0.01328125, -0.01328125], [4, array([-0.00218288], dtype=float32), 0.0203125, -0.0203125], [5, array([-0.0029075], dtype=float32), 0.142187, -0.142187], [6, array([-0.00204005], dtype=float32), -0.02421875, 0.02421875], [7, array([0.01473647], dtype=float32), 0.0343755, 0.0343755], [8, array([-0.00248036], dtype=float32), -0.03359425, 0.03359425], [9, array([0.01807238], dtype=float32), -0.02109425, -0.02109425], [10, array([0.00581555], dtype=float32), -0.02734375, -0.02734375], [11, array([0.00779906], dtype=float32), 0.0046875, 0.0046875], [12, array([0.00154116], dtype=float32), -0.00703075, -0.00703075], [13, array([-0.00045912], dtype=float32), -0.02890675, 0.02890675], [14, array([-0.0002454], dtype=float32), -0.03359325, 0.03359325], [15, array([0.00561974], dtype=float32), 0.028125, 0.028125], [16, array([-0.00458844], dtype=float32), 0.01796825, -0.01796825], [17, array([-0.00282857], dtype=float32), -0.03984275, 0.03984275], [18, array([0.00457935], dtype=float32), -0.00546975, -0.00546975], [19, array([-0.00137336], dtype=float32), -0.01484275, 0.01484275], [20, array([-0.00014301], dtype=float32), 0.06171825, -0.06171825], [21, array([-0.00535367], dtype=float32), 0.00546925, -0.00546925], [22, array([0.00507395], dtype=float32), -0.05546925, -0.05546925], [23, array([0.00511232], dtype=float32), 0.03515575, 0.03515575], [24, array([-0.0011287], dtype=float32), -0.02109375, 0.02109375], [25, array([-0.00258513], dtype=float32), -0.00078125, 0.00078125], [26, array([-0.00086137], dtype=float32), -0.00546825, 0.00546825], [27, array([0.00107271], dtype=float32), 0.01171875, 0.01171875], [28, array([-0.00387798], dtype=float32), -0.04140675, 0.04140675], [29, array([0.0038374], dtype=float32), 0.0734375, 0.0734375], [30, array([-0.00320547], dtype=float32), -0.01328075, 0.01328075], [31, array([0.00584431], dtype=float32), -0.076563, -0.076563], [32, array([0.00280425], dtype=float32), 0.0312505, 0.0312505], [33, array([-0.00201923], dtype=float32), -0.01953175, 0.01953175], [34, array([0.00058254], dtype=float32), 0.0296875, 0.0296875], [35, array([-0.00412371], dtype=float32), 0.05390625, -0.05390625], [36, array([0.00016115], dtype=float32), -0.024999, -0.024999], [37, array([0.00170819], dtype=float32), 0.021874, 0.021874], [38, array([-0.004781], dtype=float32), 0.03203225, -0.03203225], [39, array([-0.0048555], dtype=float32), -0.01484475, 0.01484475], [0, array([-0.01414702], dtype=float32), -0.03359375, 0.03359375], [1, array([0.00258495], dtype=float32), 0.0062505, 0.0062505], [2, array([-0.00322388], dtype=float32), -0.0406255, 0.0406255], [3, array([0.00596229], dtype=float32), 0.0562495, 0.0562495], [4, array([-0.00265934], dtype=float32), 0.02578175, -0.02578175], [5, array([-0.00217347], dtype=float32), 0.01875, -0.01875], [6, array([-0.00412346], dtype=float32), 0.04140675, -0.04140675], [7, array([0.00386828], dtype=float32), -0.00703125, -0.00703125], [8, array([0.00191399], dtype=float32), -0.001563, -0.001563], [9, array([0.00119538], dtype=float32), -0.0265625, -0.0265625], [10, array([0.00435989], dtype=float32), 0.00703075, 0.00703075], [11, array([0.00168762], dtype=float32), 0.034376, 0.034376], [12, array([-0.00598931], dtype=float32), -0.032813, 0.032813], [13, array([-0.00362746], dtype=float32), -0.03359325, 0.03359325], [14, array([0.00184116], dtype=float32), 0.025, 0.025], [15, array([-0.00690673], dtype=float32), 0.02890575, -0.02890575], [16, array([-0.00575079], dtype=float32), 0.0140625, -0.0140625], [17, array([-0.0026101], dtype=float32), -0.010937, 0.010937], [18, array([-0.00157441], dtype=float32), -0.01328225, 0.01328225], [19, array([0.00428833], dtype=float32), 0.0203125, 0.0203125], [20, array([-0.00271073], dtype=float32), -0.020312, 0.020312], [21, array([0.00063777], dtype=float32), -0.00859425, -0.00859425], [22, array([-0.00057336], dtype=float32), -0.0249995, 0.0249995], [23, array([0.00117187], dtype=float32), -0.123438, -0.123438], [24, array([0.00899935], dtype=float32), -0.0031245, -0.0031245], [25, array([-0.0004509], dtype=float32), -0.0046875, 0.0046875], [26, array([0.00172125], dtype=float32), -0.023437, -0.023437], [27, array([0.00171017], dtype=float32), 0.02109275, 0.02109275], [28, array([-0.00771863], dtype=float32), -0.00859375, 0.00859375], [29, array([0.00669391], dtype=float32), 0.0812505, 0.0812505], [30, array([-0.00028515], dtype=float32), -0.071875, 0.071875], [31, array([0.00083954], dtype=float32), -0.00390675, -0.00390675], [32, array([-0.01001911], dtype=float32), 0.00859425, -0.00859425], [33, array([0.00613533], dtype=float32), 0.00859375, 0.00859375], [34, array([-0.0006635], dtype=float32), 0.0109375, -0.0109375], [35, array([0.00415623], dtype=float32), 0.03359325, 0.03359325], [36, array([-0.01121433], dtype=float32), -0.00234325, 0.00234325], [37, array([0.00279536], dtype=float32), 0.007812, 0.007812], [38, array([-0.00047704], dtype=float32), 0.003126, -0.003126], [39, array([0.00018288], dtype=float32), 0.015624, 0.015624], [0, array([0.00263268], dtype=float32), 0.00703075, 0.00703075], [1, array([-0.00462151], dtype=float32), -0.0125, 0.0125], [2, array([-0.00068048], dtype=float32), 0.00625, -0.00625], [3, array([-0.0020267], dtype=float32), 0.01953075, -0.01953075], [4, array([-0.00103203], dtype=float32), 0.01640725, -0.01640725], [5, array([-0.00669771], dtype=float32), -0.015625, 0.015625], [6, array([0.00107898], dtype=float32), 0.0062495, 0.0062495], [7, array([-0.00314073], dtype=float32), 0.08359425, -0.08359425], [8, array([-0.00765121], dtype=float32), 0.012499, -0.012499], [9, array([-0.00341761], dtype=float32), 0.128126, -0.128126], [10, array([-0.01749223], dtype=float32), 0.02578125, -0.02578125], [11, array([-0.00256357], dtype=float32), -0.067188, 0.067188], [12, array([0.00037706], dtype=float32), 0.0578125, 0.0578125], [13, array([-0.00095355], dtype=float32), -0.0671875, 0.0671875], [14, array([-0.00561674], dtype=float32), 0.0015625, -0.0015625], [15, array([0.01177401], dtype=float32), 0.0515625, 0.0515625], [16, array([-0.01482076], dtype=float32), -0.03671825, 0.03671825], [17, array([-0.0023953], dtype=float32), 0.02265525, -0.02265525], [18, array([-0.00821053], dtype=float32), 0.025001, -0.025001], [19, array([-0.00042049], dtype=float32), -0.0062505, 0.0062505], [20, array([0.00251749], dtype=float32), -0.01640575, -0.01640575], [21, array([0.00182663], dtype=float32), -0.045313, -0.045313], [22, array([0.00285803], dtype=float32), -0.03828075, -0.03828075], [23, array([0.00348053], dtype=float32), 0.00234275, 0.00234275], [24, array([-0.00226914], dtype=float32), -0.0515625, 0.0515625], [25, array([0.00494409], dtype=float32), -0.00859375, -0.00859375], [26, array([-0.00325337], dtype=float32), -0.007812, 0.007812], [27, array([-9.168702e-05], dtype=float32), -0.0406255, 0.0406255], [28, array([0.00150793], dtype=float32), 0.020313, 0.020313], [29, array([-0.00803776], dtype=float32), 0.0140625, -0.0140625], [30, array([-0.0047666], dtype=float32), 0.0, -0.0], [31, array([0.00342941], dtype=float32), 0.01796925, 0.01796925], [32, array([-0.00449862], dtype=float32), 0.009375, -0.009375], [33, array([-0.00367585], dtype=float32), 0.00078125, -0.00078125], [34, array([-0.00043518], dtype=float32), 0.05078075, -0.05078075], [35, array([-0.01049907], dtype=float32), 0.01328125, -0.01328125], [36, array([-0.00050766], dtype=float32), 0.004688, -0.004688], [37, array([4.5131077e-05], dtype=float32), -0.00234425, -0.00234425], [38, array([0.00057626], dtype=float32), 0.0015625, 0.0015625], [39, array([0.00202178], dtype=float32), -0.04453125, -0.04453125], [0, array([-0.00190329], dtype=float32), -0.03828075, 0.03828075], [1, array([0.00365406], dtype=float32), 0.042187, 0.042187], [2, array([-0.00466318], dtype=float32), -0.085937, 0.085937], [3, array([0.01030558], dtype=float32), 0.02265575, 0.02265575], [4, array([-0.001346], dtype=float32), -0.021875, 0.021875], [5, array([0.00061174], dtype=float32), 0.04609325, 0.04609325], [6, array([-0.00809406], dtype=float32), -0.023437, 0.023437], [7, array([0.006349], dtype=float32), -0.03203125, -0.03203125], [8, array([-0.00361679], dtype=float32), 0.015625, -0.015625], [9, array([-0.0023745], dtype=float32), -0.00859375, 0.00859375], [10, array([-0.00247029], dtype=float32), -0.00703175, 0.00703175], [11, array([0.00577306], dtype=float32), -0.0078115, -0.0078115], [12, array([-0.00365823], dtype=float32), 0.00234325, -0.00234325], [13, array([-0.00062371], dtype=float32), -0.0203125, 0.0203125], [14, array([0.0025862], dtype=float32), -0.015625, -0.015625], [15, array([0.00042562], dtype=float32), -0.01328075, -0.01328075], [16, array([0.00052038], dtype=float32), 0.0046865, 0.0046865], [17, array([-0.00245916], dtype=float32), -0.0593745, 0.0593745], [18, array([0.0026398], dtype=float32), 0.010938, 0.010938], [19, array([-0.00096756], dtype=float32), 0.04609325, -0.04609325], [20, array([-0.00278922], dtype=float32), 0.02734425, -0.02734425], [21, array([-0.003736], dtype=float32), 0.05859275, -0.05859275], [22, array([0.000797], dtype=float32), 0.01484475, 0.01484475], [23, array([-0.00320003], dtype=float32), -0.05234425, 0.05234425], [24, array([0.00710636], dtype=float32), -0.017187, -0.017187], [25, array([0.00957709], dtype=float32), 0.049999, 0.049999], [26, array([0.00307891], dtype=float32), -0.00859325, -0.00859325], [27, array([0.00020273], dtype=float32), 0.00390675, 0.00390675], [28, array([-0.00390939], dtype=float32), 0.0062495, -0.0062495], [29, array([-0.00658566], dtype=float32), 0.01171875, -0.01171875], [30, array([-0.00515354], dtype=float32), -0.0031255, 0.0031255], [31, array([0.00210299], dtype=float32), -0.03828075, -0.03828075], [32, array([0.00247932], dtype=float32), -0.010937, -0.010937], [33, array([0.00470637], dtype=float32), -0.025001, -0.025001], [34, array([0.00473085], dtype=float32), 0.03828175, 0.03828175], [35, array([-0.00169638], dtype=float32), 0.0187505, -0.0187505], [36, array([-0.00366334], dtype=float32), -0.02734425, 0.02734425], [37, array([-0.00100641], dtype=float32), 0.00859375, -0.00859375], [38, array([0.00099979], dtype=float32), 0.032813, 0.032813], [39, array([-0.00596098], dtype=float32), 0.0312495, -0.0312495], [0, array([0.00993815], dtype=float32), -0.01171825, -0.01171825], [1, array([0.01919545], dtype=float32), -0.01015675, -0.01015675], [2, array([0.0031799], dtype=float32), 0.0203125, 0.0203125], [3, array([0.00531528], dtype=float32), -0.00078075, -0.00078075], [4, array([0.00034814], dtype=float32), -0.00390675, -0.00390675], [5, array([0.00268784], dtype=float32), -0.05390675, -0.05390675], [6, array([0.00872885], dtype=float32), 0.02890675, 0.02890675], [7, array([-0.00540875], dtype=float32), -0.0046875, 0.0046875], [8, array([0.00117791], dtype=float32), 0.01484375, 0.01484375], [9, array([-0.00235777], dtype=float32), 0.01328125, -0.01328125], [10, array([0.00238206], dtype=float32), -0.014063, -0.014063], [11, array([0.00313204], dtype=float32), 0.037501, 0.037501], [12, array([-0.00089637], dtype=float32), -0.04609425, 0.04609425], [13, array([0.00863682], dtype=float32), -5e-07, -5e-07], [14, array([0.00193474], dtype=float32), 0.02734475, 0.02734475], [15, array([-0.00023172], dtype=float32), 0.02734325, -0.02734325], [16, array([-0.00273196], dtype=float32), -0.01328125, 0.01328125], [17, array([0.00128381], dtype=float32), -0.07109325, -0.07109325], [18, array([0.0053497], dtype=float32), -0.0187505, -0.0187505], [19, array([-0.00018575], dtype=float32), -0.040625, 0.040625], [20, array([0.01021587], dtype=float32), -0.0125, -0.0125], [21, array([0.00043278], dtype=float32), 0.0281255, 0.0281255], [22, array([-0.00657871], dtype=float32), -0.01484425, 0.01484425], [23, array([0.00420088], dtype=float32), -0.023437, -0.023437], [24, array([0.00551231], dtype=float32), -0.0390625, -0.0390625], [25, array([0.00546357], dtype=float32), 0.0281245, 0.0281245], [26, array([0.00107833], dtype=float32), -0.02578125, -0.02578125], [27, array([0.00409957], dtype=float32), -0.0078125, -0.0078125], [28, array([0.00286571], dtype=float32), -0.015625, -0.015625], [29, array([0.00701533], dtype=float32), 0.03984425, 0.03984425], [30, array([-0.00418109], dtype=float32), 0.00546825, -0.00546825], [31, array([-0.00054573], dtype=float32), -0.01171875, 0.01171875], [32, array([0.00012958], dtype=float32), -0.06328125, -0.06328125], [33, array([0.01072963], dtype=float32), 0.0125005, 0.0125005], [34, array([-0.00027532], dtype=float32), -0.01796925, 0.01796925], [35, array([0.00224433], dtype=float32), -0.0359375, -0.0359375], [36, array([0.00167419], dtype=float32), 0.010937, 0.010937], [37, array([0.00213484], dtype=float32), -0.00234375, -0.00234375], [38, array([-0.00052058], dtype=float32), -0.029687, 0.029687], [39, array([0.00636202], dtype=float32), 0.0124995, 0.0124995], [0, array([-0.00350295], dtype=float32), -0.0281245, 0.0281245], [1, array([-0.00013989], dtype=float32), 0.0078125, -0.0078125], [2, array([-0.00281196], dtype=float32), -0.00546975, 0.00546975], [3, array([-0.00029693], dtype=float32), 0.01171925, -0.01171925], [4, array([-0.0007937], dtype=float32), -0.0109375, 0.0109375], [5, array([-0.00391014], dtype=float32), 0.0156255, -0.0156255], [6, array([-0.00325283], dtype=float32), -0.0281255, 0.0281255], [7, array([-5.109841e-05], dtype=float32), 0.0062505, -0.0062505], [8, array([0.00050052], dtype=float32), -0.01328225, -0.01328225], [9, array([0.00134085], dtype=float32), -0.0109365, -0.0109365], [10, array([0.00275147], dtype=float32), -0.0187505, -0.0187505], [11, array([0.00204582], dtype=float32), 0.017188, 0.017188], [12, array([-0.00245923], dtype=float32), 0.015624, -0.015624], [13, array([-0.00385162], dtype=float32), -0.0078115, 0.0078115], [14, array([0.00089682], dtype=float32), -0.00390725, -0.00390725], [15, array([-0.00154551], dtype=float32), 0.01171925, -0.01171925], [16, array([-0.00058517], dtype=float32), 0.009375, -0.009375], [17, array([0.00020052], dtype=float32), 0.03359375, 0.03359375], [18, array([-0.00230161], dtype=float32), 0.02265625, -0.02265625], [19, array([-0.00430302], dtype=float32), -0.01328125, 0.01328125], [20, array([0.0021265], dtype=float32), 0.0124995, 0.0124995], [21, array([0.00043643], dtype=float32), -0.0078125, -0.0078125], [22, array([0.00219393], dtype=float32), -0.015624, -0.015624], [23, array([0.00472452], dtype=float32), -0.025, -0.025], [24, array([0.00413034], dtype=float32), -0.028126, -0.028126], [25, array([0.00136138], dtype=float32), 0.06953175, 0.06953175], [26, array([-0.00981272], dtype=float32), 0.16484375, -0.16484375], [27, array([-0.00282343], dtype=float32), -0.053125, 0.053125], [28, array([0.00888714], dtype=float32), -0.03359425, -0.03359425], [29, array([0.01194258], dtype=float32), 0.01640725, 0.01640725], [30, array([0.00411092], dtype=float32), 0.01953025, 0.01953025], [31, array([0.00469281], dtype=float32), -0.009375, -0.009375], [32, array([0.01095414], dtype=float32), -0.00234325, -0.00234325], [33, array([-0.00891442], dtype=float32), 0.08515675, -0.08515675], [34, array([0.00087482], dtype=float32), -0.0140635, -0.0140635], [35, array([0.0065229], dtype=float32), -0.10859375, -0.10859375], [36, array([-0.01000777], dtype=float32), 0.031251, -0.031251], [37, array([-0.01412267], dtype=float32), -0.00546875, 0.00546875], [38, array([0.00478946], dtype=float32), -0.0046875, -0.0046875], [39, array([-0.00280857], dtype=float32), -0.05546925, 0.05546925], [0, array([-0.00180476], dtype=float32), 0.00390625, -0.00390625], [1, array([0.00132947], dtype=float32), 0.00390525, 0.00390525], [2, array([0.00139118], dtype=float32), 0.02421975, 0.02421975], [3, array([0.00259317], dtype=float32), -0.0187505, -0.0187505], [4, array([0.00566922], dtype=float32), 0.0015625, 0.0015625], [5, array([0.00354125], dtype=float32), 0.01015675, 0.01015675], [6, array([1.2044635e-05], dtype=float32), -0.012501, -0.012501], [7, array([0.00301369], dtype=float32), 0.0109385, 0.0109385], [8, array([-0.00055533], dtype=float32), 0.0140615, -0.0140615], [9, array([-0.00512541], dtype=float32), -0.0078115, 0.0078115], [10, array([0.00263531], dtype=float32), -0.001563, -0.001563], [11, array([0.00160299], dtype=float32), -0.01875, -0.01875], [12, array([0.00245156], dtype=float32), 0.015625, 0.015625], [13, array([0.00078499], dtype=float32), 0.0328125, 0.0328125], [14, array([-0.0022058], dtype=float32), 0.00703125, -0.00703125], [15, array([-0.00084561], dtype=float32), -0.028125, 0.028125], [16, array([0.00345012], dtype=float32), 0.0437495, 0.0437495], [17, array([-0.00272602], dtype=float32), 0.02265675, -0.02265675], [18, array([0.00394363], dtype=float32), -0.0218745, -0.0218745], [19, array([0.00192545], dtype=float32), -0.03515625, -0.03515625], [20, array([0.00547039], dtype=float32), 0.009375, 0.009375], [21, array([-0.00620127], dtype=float32), -0.0171885, 0.0171885], [22, array([0.00386356], dtype=float32), -0.010937, -0.010937], [23, array([-0.00428506], dtype=float32), 0.01796875, -0.01796875], [24, array([-0.00555859], dtype=float32), 0.0265625, -0.0265625], [25, array([0.0033311], dtype=float32), -0.00859375, -0.00859375], [26, array([0.00340368], dtype=float32), -0.0062505, -0.0062505], [27, array([0.00346643], dtype=float32), 0.07265625, 0.07265625], [28, array([-0.00765496], dtype=float32), -0.004687, 0.004687], [29, array([0.0020292], dtype=float32), -0.0078125, -0.0078125], [30, array([0.00253352], dtype=float32), 0.02109375, 0.02109375], [31, array([-0.00446673], dtype=float32), 0.0781245, -0.0781245], [32, array([-0.00031867], dtype=float32), -0.014062, 0.014062], [33, array([-0.00562642], dtype=float32), 0.01484325, -0.01484325], [34, array([-0.0008949], dtype=float32), 0.03203175, -0.03203175], [35, array([-9.1595095e-05], dtype=float32), 0.00703075, -0.00703075], [36, array([0.00166957], dtype=float32), -0.10703025, -0.10703025], [37, array([0.01100717], dtype=float32), 0.00546825, 0.00546825], [38, array([-0.00201582], dtype=float32), 0.00703125, -0.00703125], [39, array([0.00723039], dtype=float32), -0.02109375, -0.02109375], [0, array([-0.00273816], dtype=float32), -0.00078075, 0.00078075], [1, array([0.00292308], dtype=float32), 0.00625, 0.00625], [2, array([-0.00032773], dtype=float32), -0.037501, 0.037501], [3, array([0.00601828], dtype=float32), 0.004688, 0.004688], [4, array([-0.00268291], dtype=float32), -0.01953075, 0.01953075], [5, array([0.00481636], dtype=float32), 0.09609375, 0.09609375], [6, array([-0.01791355], dtype=float32), -0.007813, 0.007813], [7, array([0.01128423], dtype=float32), -0.02734325, -0.02734325], [8, array([0.00306747], dtype=float32), 0.02734275, 0.02734275], [9, array([-0.00113197], dtype=float32), 0.0281255, -0.0281255], [10, array([0.00155484], dtype=float32), -0.0124995, -0.0124995], [11, array([0.0069632], dtype=float32), 0.03828025, 0.03828025], [12, array([-0.00496079], dtype=float32), 0.0062505, -0.0062505], [13, array([0.00142162], dtype=float32), -0.03125, -0.03125], [14, array([0.01150123], dtype=float32), -0.001562, -0.001562], [15, array([0.00273795], dtype=float32), 0.02578075, 0.02578075], [16, array([-0.00192976], dtype=float32), -0.01015675, 0.01015675], [17, array([0.00116537], dtype=float32), -0.01640625, -0.01640625], [18, array([0.00154424], dtype=float32), 0.00703175, 0.00703175], [19, array([-0.0021715], dtype=float32), -0.0296875, 0.0296875], [20, array([0.00164375], dtype=float32), 0.0343755, 0.0343755], [21, array([-0.00606755], dtype=float32), -0.0046885, 0.0046885], [22, array([0.00226867], dtype=float32), -0.04921775, -0.04921775], [23, array([0.00672156], dtype=float32), 0.0234365, 0.0234365], [24, array([0.00054234], dtype=float32), 0.0046885, 0.0046885], [25, array([0.00065581], dtype=float32), -0.01484375, -0.01484375], [26, array([0.00350513], dtype=float32), -0.0218755, -0.0218755], [27, array([-0.00141835], dtype=float32), -0.0109375, 0.0109375], [28, array([0.00041429], dtype=float32), -0.001563, -0.001563], [29, array([0.00116656], dtype=float32), 0.0015635, 0.0015635], [30, array([-0.00115844], dtype=float32), -0.01328175, 0.01328175], [31, array([0.00583085], dtype=float32), 0.01484325, 0.01484325], [32, array([-0.00108487], dtype=float32), 0.01328175, -0.01328175], [33, array([-0.00113695], dtype=float32), 0.04609375, -0.04609375], [34, array([-0.00696755], dtype=float32), -0.01015625, 0.01015625], [35, array([-0.00092702], dtype=float32), -0.01015675, 0.01015675], [36, array([1.5027472e-05], dtype=float32), -0.01875, -0.01875], [37, array([0.00418485], dtype=float32), 0.028125, 0.028125], [38, array([-0.00349464], dtype=float32), 0.00234475, -0.00234475], [39, array([0.00214028], dtype=float32), 0.017187, 0.017187], [0, array([-0.001137], dtype=float32), -0.0437495, 0.0437495], [1, array([0.00350134], dtype=float32), 0.01953175, 0.01953175], [2, array([-0.00188511], dtype=float32), 0.0031245, -0.0031245], [3, array([-0.00197231], dtype=float32), -0.06640675, 0.06640675], [4, array([0.00144811], dtype=float32), 0.00703175, 0.00703175], [5, array([0.00076279], dtype=float32), -0.08125, -0.08125], [6, array([0.00691317], dtype=float32), 0.010938, 0.010938], [7, array([0.00420609], dtype=float32), -0.007813, -0.007813], [8, array([0.00339972], dtype=float32), 0.0109375, 0.0109375], [9, array([-0.00306996], dtype=float32), -0.00234325, 0.00234325], [10, array([-0.00042298], dtype=float32), 0.0, -0.0], [11, array([-0.00295166], dtype=float32), -0.00546925, 0.00546925], [12, array([0.00134161], dtype=float32), -0.0062495, -0.0062495], [13, array([-0.00395498], dtype=float32), -0.00234425, 0.00234425], [14, array([0.00702664], dtype=float32), -0.05625, -0.05625], [15, array([0.00535411], dtype=float32), -0.01640625, -0.01640625], [16, array([0.00066569], dtype=float32), 0.0, 0.0], [17, array([-0.00128719], dtype=float32), -0.0593745, 0.0593745], [18, array([-0.00234838], dtype=float32), 0.015625, -0.015625], [19, array([-8.4940984e-05], dtype=float32), -0.00859375, 0.00859375], [20, array([0.00126113], dtype=float32), -0.02109375, -0.02109375], [21, array([-0.00166399], dtype=float32), -0.0218755, 0.0218755], [22, array([0.00328061], dtype=float32), -0.0031245, -0.0031245], [23, array([-0.00025947], dtype=float32), 0.0968745, -0.0968745], [24, array([-0.00508067], dtype=float32), 0.02890675, -0.02890675], [25, array([0.00103257], dtype=float32), 0.00234375, 0.00234375], [26, array([0.00991902], dtype=float32), 0.00546775, 0.00546775], [27, array([0.00141055], dtype=float32), 0.03828125, 0.03828125], [28, array([0.00324836], dtype=float32), 0.0031255, 0.0031255], [29, array([0.00267549], dtype=float32), 0.03203075, 0.03203075], [30, array([-0.00781974], dtype=float32), -0.03046775, 0.03046775], [31, array([0.00455807], dtype=float32), -0.03046925, -0.03046925], [32, array([0.00366664], dtype=float32), 0.01796925, 0.01796925], [33, array([0.00462387], dtype=float32), -0.0125, -0.0125], [34, array([-0.0003319], dtype=float32), -0.01328125, 0.01328125], [35, array([0.00540188], dtype=float32), 0.05859325, 0.05859325], [36, array([-0.00944334], dtype=float32), 0.00546875, -0.00546875], [37, array([-0.00266133], dtype=float32), 0.0250005, -0.0250005], [38, array([-0.00321076], dtype=float32), 0.04296875, -0.04296875], [39, array([0.00360577], dtype=float32), -0.06875, -0.06875], [0, array([-0.00961537], dtype=float32), -0.0375005, 0.0375005], [1, array([0.01332608], dtype=float32), 0.05234425, 0.05234425], [2, array([0.0027801], dtype=float32), -0.00078075, -0.00078075], [3, array([0.003215], dtype=float32), -0.06796875, -0.06796875], [4, array([-0.00331198], dtype=float32), -0.01484375, 0.01484375], [5, array([-0.01415186], dtype=float32), 0.00234275, -0.00234275], [6, array([-0.00417756], dtype=float32), -0.0203125, 0.0203125], [7, array([-0.00565503], dtype=float32), 0.045313, -0.045313], [8, array([-0.00432016], dtype=float32), 0.017188, -0.017188], [9, array([-0.00024404], dtype=float32), -0.0046885, 0.0046885], [10, array([-0.00977254], dtype=float32), 0.00546975, -0.00546975], [11, array([0.00406635], dtype=float32), 0.009375, 0.009375], [12, array([-0.00295553], dtype=float32), -0.00234375, 0.00234375], [13, array([0.00446821], dtype=float32), 0.02734325, 0.02734325], [14, array([-0.00376547], dtype=float32), 0.0125, -0.0125], [15, array([-0.00265757], dtype=float32), -0.00703125, 0.00703125], [16, array([-0.00197323], dtype=float32), 0.023438, -0.023438], [17, array([0.00028758], dtype=float32), -0.0515635, -0.0515635], [18, array([-0.00013271], dtype=float32), 0.003125, -0.003125], [19, array([0.00057438], dtype=float32), -0.0015625, -0.0015625], [20, array([-0.00326177], dtype=float32), 0.07109375, -0.07109375], [21, array([0.00158642], dtype=float32), -0.03515575, -0.03515575], [22, array([0.00841648], dtype=float32), -0.01796825, -0.01796825], [23, array([-0.00019884], dtype=float32), 0.0015625, -0.0015625], [24, array([0.00087691], dtype=float32), 0.0203115, 0.0203115], [25, array([-0.00720902], dtype=float32), -0.03515525, 0.03515525], [26, array([0.00433812], dtype=float32), -0.01796925, -0.01796925], [27, array([-0.00185235], dtype=float32), -0.0328125, 0.0328125], [28, array([-0.00325125], dtype=float32), 0.023437, -0.023437], [29, array([-0.00446493], dtype=float32), -0.0281245, 0.0281245], [30, array([0.00414656], dtype=float32), -0.01484375, -0.01484375], [31, array([-0.00074388], dtype=float32), 0.0125, -0.0125], [32, array([-0.00519815], dtype=float32), 0.023438, -0.023438], [33, array([-0.00259329], dtype=float32), 0.0062495, -0.0062495], [34, array([0.00109682], dtype=float32), 0.0140625, 0.0140625], [35, array([0.00147172], dtype=float32), -0.01171875, -0.01171875], [36, array([0.00082036], dtype=float32), -0.00234425, -0.00234425], [37, array([-0.00224437], dtype=float32), -0.018749, 0.018749], [38, array([0.0016135], dtype=float32), -0.01171875, -0.01171875], [39, array([0.00138227], dtype=float32), 0.00234325, 0.00234325]]\n"
     ]
    }
   ],
   "source": [
    "print (pnls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration x =  7000  to row-stepsize  7797\n",
      "Model: \"model_43\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_44 (InputLayer)          [(None, 10, 1)]      0           []                               \n",
      "                                                                                                  \n",
      " layer_normalization_344 (Layer  (None, 10, 1)       2           ['input_44[0][0]']               \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " multi_head_attention_172 (Mult  (None, 10, 1)       7169        ['layer_normalization_344[0][0]',\n",
      " iHeadAttention)                                                  'layer_normalization_344[0][0]']\n",
      "                                                                                                  \n",
      " dropout_387 (Dropout)          (None, 10, 1)        0           ['multi_head_attention_172[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " tf.__operators__.add_344 (TFOp  (None, 10, 1)       0           ['dropout_387[0][0]',            \n",
      " Lambda)                                                          'input_44[0][0]']               \n",
      "                                                                                                  \n",
      " layer_normalization_345 (Layer  (None, 10, 1)       2           ['tf.__operators__.add_344[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " conv1d_344 (Conv1D)            (None, 10, 4)        8           ['layer_normalization_345[0][0]']\n",
      "                                                                                                  \n",
      " dropout_388 (Dropout)          (None, 10, 4)        0           ['conv1d_344[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d_345 (Conv1D)            (None, 10, 1)        5           ['dropout_388[0][0]']            \n",
      "                                                                                                  \n",
      " tf.__operators__.add_345 (TFOp  (None, 10, 1)       0           ['conv1d_345[0][0]',             \n",
      " Lambda)                                                          'tf.__operators__.add_344[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_346 (Layer  (None, 10, 1)       2           ['tf.__operators__.add_345[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " multi_head_attention_173 (Mult  (None, 10, 1)       7169        ['layer_normalization_346[0][0]',\n",
      " iHeadAttention)                                                  'layer_normalization_346[0][0]']\n",
      "                                                                                                  \n",
      " dropout_389 (Dropout)          (None, 10, 1)        0           ['multi_head_attention_173[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " tf.__operators__.add_346 (TFOp  (None, 10, 1)       0           ['dropout_389[0][0]',            \n",
      " Lambda)                                                          'tf.__operators__.add_345[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_347 (Layer  (None, 10, 1)       2           ['tf.__operators__.add_346[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " conv1d_346 (Conv1D)            (None, 10, 4)        8           ['layer_normalization_347[0][0]']\n",
      "                                                                                                  \n",
      " dropout_390 (Dropout)          (None, 10, 4)        0           ['conv1d_346[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d_347 (Conv1D)            (None, 10, 1)        5           ['dropout_390[0][0]']            \n",
      "                                                                                                  \n",
      " tf.__operators__.add_347 (TFOp  (None, 10, 1)       0           ['conv1d_347[0][0]',             \n",
      " Lambda)                                                          'tf.__operators__.add_346[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_348 (Layer  (None, 10, 1)       2           ['tf.__operators__.add_347[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " multi_head_attention_174 (Mult  (None, 10, 1)       7169        ['layer_normalization_348[0][0]',\n",
      " iHeadAttention)                                                  'layer_normalization_348[0][0]']\n",
      "                                                                                                  \n",
      " dropout_391 (Dropout)          (None, 10, 1)        0           ['multi_head_attention_174[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " tf.__operators__.add_348 (TFOp  (None, 10, 1)       0           ['dropout_391[0][0]',            \n",
      " Lambda)                                                          'tf.__operators__.add_347[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_349 (Layer  (None, 10, 1)       2           ['tf.__operators__.add_348[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " conv1d_348 (Conv1D)            (None, 10, 4)        8           ['layer_normalization_349[0][0]']\n",
      "                                                                                                  \n",
      " dropout_392 (Dropout)          (None, 10, 4)        0           ['conv1d_348[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d_349 (Conv1D)            (None, 10, 1)        5           ['dropout_392[0][0]']            \n",
      "                                                                                                  \n",
      " tf.__operators__.add_349 (TFOp  (None, 10, 1)       0           ['conv1d_349[0][0]',             \n",
      " Lambda)                                                          'tf.__operators__.add_348[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_350 (Layer  (None, 10, 1)       2           ['tf.__operators__.add_349[0][0]'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " multi_head_attention_175 (Mult  (None, 10, 1)       7169        ['layer_normalization_350[0][0]',\n",
      " iHeadAttention)                                                  'layer_normalization_350[0][0]']\n",
      "                                                                                                  \n",
      " dropout_393 (Dropout)          (None, 10, 1)        0           ['multi_head_attention_175[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " tf.__operators__.add_350 (TFOp  (None, 10, 1)       0           ['dropout_393[0][0]',            \n",
      " Lambda)                                                          'tf.__operators__.add_349[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_351 (Layer  (None, 10, 1)       2           ['tf.__operators__.add_350[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " conv1d_350 (Conv1D)            (None, 10, 4)        8           ['layer_normalization_351[0][0]']\n",
      "                                                                                                  \n",
      " dropout_394 (Dropout)          (None, 10, 4)        0           ['conv1d_350[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d_351 (Conv1D)            (None, 10, 1)        5           ['dropout_394[0][0]']            \n",
      "                                                                                                  \n",
      " tf.__operators__.add_351 (TFOp  (None, 10, 1)       0           ['conv1d_351[0][0]',             \n",
      " Lambda)                                                          'tf.__operators__.add_350[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " global_average_pooling1d_43 (G  (None, 10)          0           ['tf.__operators__.add_351[0][0]'\n",
      " lobalAveragePooling1D)                                          ]                                \n",
      "                                                                                                  \n",
      " dense_86 (Dense)               (None, 128)          1408        ['global_average_pooling1d_43[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      " dropout_395 (Dropout)          (None, 128)          0           ['dense_86[0][0]']               \n",
      "                                                                                                  \n",
      " dense_87 (Dense)               (None, 1)            129         ['dropout_395[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 30,281\n",
      "Trainable params: 30,281\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/10\n",
      "88/88 [==============================] - 15s 147ms/step - loss: 0.0011 - val_loss: 0.0013\n",
      "Epoch 2/10\n",
      "88/88 [==============================] - 12s 140ms/step - loss: 9.9237e-04 - val_loss: 0.0012\n",
      "Epoch 3/10\n",
      "88/88 [==============================] - 12s 137ms/step - loss: 0.0010 - val_loss: 0.0012\n",
      "Epoch 4/10\n",
      "88/88 [==============================] - 11s 126ms/step - loss: 9.8259e-04 - val_loss: 0.0012\n",
      "Epoch 5/10\n",
      "88/88 [==============================] - 11s 129ms/step - loss: 9.7221e-04 - val_loss: 0.0012\n",
      "Epoch 6/10\n",
      "88/88 [==============================] - 11s 130ms/step - loss: 9.5540e-04 - val_loss: 0.0012\n",
      "Epoch 7/10\n",
      "88/88 [==============================] - 11s 129ms/step - loss: 9.6757e-04 - val_loss: 0.0012\n",
      "Epoch 8/10\n",
      "88/88 [==============================] - 11s 128ms/step - loss: 9.3784e-04 - val_loss: 0.0012\n",
      "Epoch 9/10\n",
      "88/88 [==============================] - 11s 129ms/step - loss: 9.1361e-04 - val_loss: 0.0012\n",
      "Epoch 10/10\n",
      "88/88 [==============================] - 11s 129ms/step - loss: 9.3534e-04 - val_loss: 0.0012\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 7.6940e-04\n",
      "2/2 [==============================] - 0s 9ms/step\n",
      "Score (RMSE): 0.027738016364741647\n",
      "time to execute =  0:01:59.764437\n",
      "Iteration x =  7050  to row-stepsize  7797\n",
      "Model: \"model_44\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_45 (InputLayer)          [(None, 10, 1)]      0           []                               \n",
      "                                                                                                  \n",
      " layer_normalization_352 (Layer  (None, 10, 1)       2           ['input_45[0][0]']               \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " multi_head_attention_176 (Mult  (None, 10, 1)       7169        ['layer_normalization_352[0][0]',\n",
      " iHeadAttention)                                                  'layer_normalization_352[0][0]']\n",
      "                                                                                                  \n",
      " dropout_396 (Dropout)          (None, 10, 1)        0           ['multi_head_attention_176[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " tf.__operators__.add_352 (TFOp  (None, 10, 1)       0           ['dropout_396[0][0]',            \n",
      " Lambda)                                                          'input_45[0][0]']               \n",
      "                                                                                                  \n",
      " layer_normalization_353 (Layer  (None, 10, 1)       2           ['tf.__operators__.add_352[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " conv1d_352 (Conv1D)            (None, 10, 4)        8           ['layer_normalization_353[0][0]']\n",
      "                                                                                                  \n",
      " dropout_397 (Dropout)          (None, 10, 4)        0           ['conv1d_352[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d_353 (Conv1D)            (None, 10, 1)        5           ['dropout_397[0][0]']            \n",
      "                                                                                                  \n",
      " tf.__operators__.add_353 (TFOp  (None, 10, 1)       0           ['conv1d_353[0][0]',             \n",
      " Lambda)                                                          'tf.__operators__.add_352[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_354 (Layer  (None, 10, 1)       2           ['tf.__operators__.add_353[0][0]'\n",
      " Normalization)                                                  ]                                \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                                                  \n",
      " multi_head_attention_177 (Mult  (None, 10, 1)       7169        ['layer_normalization_354[0][0]',\n",
      " iHeadAttention)                                                  'layer_normalization_354[0][0]']\n",
      "                                                                                                  \n",
      " dropout_398 (Dropout)          (None, 10, 1)        0           ['multi_head_attention_177[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " tf.__operators__.add_354 (TFOp  (None, 10, 1)       0           ['dropout_398[0][0]',            \n",
      " Lambda)                                                          'tf.__operators__.add_353[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_355 (Layer  (None, 10, 1)       2           ['tf.__operators__.add_354[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " conv1d_354 (Conv1D)            (None, 10, 4)        8           ['layer_normalization_355[0][0]']\n",
      "                                                                                                  \n",
      " dropout_399 (Dropout)          (None, 10, 4)        0           ['conv1d_354[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d_355 (Conv1D)            (None, 10, 1)        5           ['dropout_399[0][0]']            \n",
      "                                                                                                  \n",
      " tf.__operators__.add_355 (TFOp  (None, 10, 1)       0           ['conv1d_355[0][0]',             \n",
      " Lambda)                                                          'tf.__operators__.add_354[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_356 (Layer  (None, 10, 1)       2           ['tf.__operators__.add_355[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " multi_head_attention_178 (Mult  (None, 10, 1)       7169        ['layer_normalization_356[0][0]',\n",
      " iHeadAttention)                                                  'layer_normalization_356[0][0]']\n",
      "                                                                                                  \n",
      " dropout_400 (Dropout)          (None, 10, 1)        0           ['multi_head_attention_178[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " tf.__operators__.add_356 (TFOp  (None, 10, 1)       0           ['dropout_400[0][0]',            \n",
      " Lambda)                                                          'tf.__operators__.add_355[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_357 (Layer  (None, 10, 1)       2           ['tf.__operators__.add_356[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " conv1d_356 (Conv1D)            (None, 10, 4)        8           ['layer_normalization_357[0][0]']\n",
      "                                                                                                  \n",
      " dropout_401 (Dropout)          (None, 10, 4)        0           ['conv1d_356[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d_357 (Conv1D)            (None, 10, 1)        5           ['dropout_401[0][0]']            \n",
      "                                                                                                  \n",
      " tf.__operators__.add_357 (TFOp  (None, 10, 1)       0           ['conv1d_357[0][0]',             \n",
      " Lambda)                                                          'tf.__operators__.add_356[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_358 (Layer  (None, 10, 1)       2           ['tf.__operators__.add_357[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " multi_head_attention_179 (Mult  (None, 10, 1)       7169        ['layer_normalization_358[0][0]',\n",
      " iHeadAttention)                                                  'layer_normalization_358[0][0]']\n",
      "                                                                                                  \n",
      " dropout_402 (Dropout)          (None, 10, 1)        0           ['multi_head_attention_179[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " tf.__operators__.add_358 (TFOp  (None, 10, 1)       0           ['dropout_402[0][0]',            \n",
      " Lambda)                                                          'tf.__operators__.add_357[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_359 (Layer  (None, 10, 1)       2           ['tf.__operators__.add_358[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " conv1d_358 (Conv1D)            (None, 10, 4)        8           ['layer_normalization_359[0][0]']\n",
      "                                                                                                  \n",
      " dropout_403 (Dropout)          (None, 10, 4)        0           ['conv1d_358[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d_359 (Conv1D)            (None, 10, 1)        5           ['dropout_403[0][0]']            \n",
      "                                                                                                  \n",
      " tf.__operators__.add_359 (TFOp  (None, 10, 1)       0           ['conv1d_359[0][0]',             \n",
      " Lambda)                                                          'tf.__operators__.add_358[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " global_average_pooling1d_44 (G  (None, 10)          0           ['tf.__operators__.add_359[0][0]'\n",
      " lobalAveragePooling1D)                                          ]                                \n",
      "                                                                                                  \n",
      " dense_88 (Dense)               (None, 128)          1408        ['global_average_pooling1d_44[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      " dropout_404 (Dropout)          (None, 128)          0           ['dense_88[0][0]']               \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                                                  \n",
      " dense_89 (Dense)               (None, 1)            129         ['dropout_404[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 30,281\n",
      "Trainable params: 30,281\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/10\n",
      "88/88 [==============================] - 14s 133ms/step - loss: 0.0010 - val_loss: 0.0013\n",
      "Epoch 2/10\n",
      "88/88 [==============================] - 11s 129ms/step - loss: 0.0010 - val_loss: 0.0012\n",
      "Epoch 3/10\n",
      "88/88 [==============================] - 11s 128ms/step - loss: 0.0010 - val_loss: 0.0013\n",
      "Epoch 4/10\n",
      "88/88 [==============================] - 11s 128ms/step - loss: 9.5359e-04 - val_loss: 0.0012\n",
      "Epoch 5/10\n",
      "88/88 [==============================] - 11s 129ms/step - loss: 9.8985e-04 - val_loss: 0.0012\n",
      "Epoch 6/10\n",
      "88/88 [==============================] - 11s 129ms/step - loss: 9.7684e-04 - val_loss: 0.0012\n",
      "Epoch 7/10\n",
      "88/88 [==============================] - 11s 129ms/step - loss: 9.5785e-04 - val_loss: 0.0012\n",
      "Epoch 8/10\n",
      "88/88 [==============================] - 11s 129ms/step - loss: 9.4143e-04 - val_loss: 0.0012\n",
      "Epoch 9/10\n",
      "88/88 [==============================] - 11s 128ms/step - loss: 9.6146e-04 - val_loss: 0.0012\n",
      "Epoch 10/10\n",
      "88/88 [==============================] - 11s 129ms/step - loss: 9.1404e-04 - val_loss: 0.0012\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0016\n",
      "2/2 [==============================] - 0s 10ms/step\n",
      "Score (RMSE): 0.04004489173971932\n",
      "time to execute =  0:03:57.058439\n",
      "Iteration x =  7100  to row-stepsize  7797\n",
      "Model: \"model_45\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_46 (InputLayer)          [(None, 10, 1)]      0           []                               \n",
      "                                                                                                  \n",
      " layer_normalization_360 (Layer  (None, 10, 1)       2           ['input_46[0][0]']               \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " multi_head_attention_180 (Mult  (None, 10, 1)       7169        ['layer_normalization_360[0][0]',\n",
      " iHeadAttention)                                                  'layer_normalization_360[0][0]']\n",
      "                                                                                                  \n",
      " dropout_405 (Dropout)          (None, 10, 1)        0           ['multi_head_attention_180[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " tf.__operators__.add_360 (TFOp  (None, 10, 1)       0           ['dropout_405[0][0]',            \n",
      " Lambda)                                                          'input_46[0][0]']               \n",
      "                                                                                                  \n",
      " layer_normalization_361 (Layer  (None, 10, 1)       2           ['tf.__operators__.add_360[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " conv1d_360 (Conv1D)            (None, 10, 4)        8           ['layer_normalization_361[0][0]']\n",
      "                                                                                                  \n",
      " dropout_406 (Dropout)          (None, 10, 4)        0           ['conv1d_360[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d_361 (Conv1D)            (None, 10, 1)        5           ['dropout_406[0][0]']            \n",
      "                                                                                                  \n",
      " tf.__operators__.add_361 (TFOp  (None, 10, 1)       0           ['conv1d_361[0][0]',             \n",
      " Lambda)                                                          'tf.__operators__.add_360[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_362 (Layer  (None, 10, 1)       2           ['tf.__operators__.add_361[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " multi_head_attention_181 (Mult  (None, 10, 1)       7169        ['layer_normalization_362[0][0]',\n",
      " iHeadAttention)                                                  'layer_normalization_362[0][0]']\n",
      "                                                                                                  \n",
      " dropout_407 (Dropout)          (None, 10, 1)        0           ['multi_head_attention_181[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " tf.__operators__.add_362 (TFOp  (None, 10, 1)       0           ['dropout_407[0][0]',            \n",
      " Lambda)                                                          'tf.__operators__.add_361[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_363 (Layer  (None, 10, 1)       2           ['tf.__operators__.add_362[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " conv1d_362 (Conv1D)            (None, 10, 4)        8           ['layer_normalization_363[0][0]']\n",
      "                                                                                                  \n",
      " dropout_408 (Dropout)          (None, 10, 4)        0           ['conv1d_362[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d_363 (Conv1D)            (None, 10, 1)        5           ['dropout_408[0][0]']            \n",
      "                                                                                                  \n",
      " tf.__operators__.add_363 (TFOp  (None, 10, 1)       0           ['conv1d_363[0][0]',             \n",
      " Lambda)                                                          'tf.__operators__.add_362[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_364 (Layer  (None, 10, 1)       2           ['tf.__operators__.add_363[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " multi_head_attention_182 (Mult  (None, 10, 1)       7169        ['layer_normalization_364[0][0]',\n",
      " iHeadAttention)                                                  'layer_normalization_364[0][0]']\n",
      "                                                                                                  \n",
      " dropout_409 (Dropout)          (None, 10, 1)        0           ['multi_head_attention_182[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " tf.__operators__.add_364 (TFOp  (None, 10, 1)       0           ['dropout_409[0][0]',            \n",
      " Lambda)                                                          'tf.__operators__.add_363[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_365 (Layer  (None, 10, 1)       2           ['tf.__operators__.add_364[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " conv1d_364 (Conv1D)            (None, 10, 4)        8           ['layer_normalization_365[0][0]']\n",
      "                                                                                                  \n",
      " dropout_410 (Dropout)          (None, 10, 4)        0           ['conv1d_364[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d_365 (Conv1D)            (None, 10, 1)        5           ['dropout_410[0][0]']            \n",
      "                                                                                                  \n",
      " tf.__operators__.add_365 (TFOp  (None, 10, 1)       0           ['conv1d_365[0][0]',             \n",
      " Lambda)                                                          'tf.__operators__.add_364[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_366 (Layer  (None, 10, 1)       2           ['tf.__operators__.add_365[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " multi_head_attention_183 (Mult  (None, 10, 1)       7169        ['layer_normalization_366[0][0]',\n",
      " iHeadAttention)                                                  'layer_normalization_366[0][0]']\n",
      "                                                                                                  \n",
      " dropout_411 (Dropout)          (None, 10, 1)        0           ['multi_head_attention_183[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " tf.__operators__.add_366 (TFOp  (None, 10, 1)       0           ['dropout_411[0][0]',            \n",
      " Lambda)                                                          'tf.__operators__.add_365[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_367 (Layer  (None, 10, 1)       2           ['tf.__operators__.add_366[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " conv1d_366 (Conv1D)            (None, 10, 4)        8           ['layer_normalization_367[0][0]']\n",
      "                                                                                                  \n",
      " dropout_412 (Dropout)          (None, 10, 4)        0           ['conv1d_366[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d_367 (Conv1D)            (None, 10, 1)        5           ['dropout_412[0][0]']            \n",
      "                                                                                                  \n",
      " tf.__operators__.add_367 (TFOp  (None, 10, 1)       0           ['conv1d_367[0][0]',             \n",
      " Lambda)                                                          'tf.__operators__.add_366[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " global_average_pooling1d_45 (G  (None, 10)          0           ['tf.__operators__.add_367[0][0]'\n",
      " lobalAveragePooling1D)                                          ]                                \n",
      "                                                                                                  \n",
      " dense_90 (Dense)               (None, 128)          1408        ['global_average_pooling1d_45[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      " dropout_413 (Dropout)          (None, 128)          0           ['dense_90[0][0]']               \n",
      "                                                                                                  \n",
      " dense_91 (Dense)               (None, 1)            129         ['dropout_413[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 30,281\n",
      "Trainable params: 30,281\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/10\n",
      "88/88 [==============================] - 15s 136ms/step - loss: 0.0011 - val_loss: 0.0013\n",
      "Epoch 2/10\n",
      "88/88 [==============================] - 12s 132ms/step - loss: 9.5564e-04 - val_loss: 0.0013\n",
      "Epoch 3/10\n",
      "88/88 [==============================] - 12s 132ms/step - loss: 9.4773e-04 - val_loss: 0.0013\n",
      "Epoch 4/10\n",
      "88/88 [==============================] - 12s 132ms/step - loss: 9.6823e-04 - val_loss: 0.0013\n",
      "Epoch 5/10\n",
      "88/88 [==============================] - 12s 132ms/step - loss: 9.7669e-04 - val_loss: 0.0013\n",
      "Epoch 6/10\n",
      "88/88 [==============================] - 12s 132ms/step - loss: 9.4410e-04 - val_loss: 0.0013\n",
      "Epoch 7/10\n",
      "88/88 [==============================] - 12s 132ms/step - loss: 9.3429e-04 - val_loss: 0.0013\n",
      "Epoch 8/10\n",
      "88/88 [==============================] - 12s 133ms/step - loss: 9.2637e-04 - val_loss: 0.0013\n",
      "Epoch 9/10\n",
      "88/88 [==============================] - 12s 132ms/step - loss: 9.0948e-04 - val_loss: 0.0013\n",
      "Epoch 10/10\n",
      "88/88 [==============================] - 12s 132ms/step - loss: 9.1435e-04 - val_loss: 0.0013\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0013\n",
      "2/2 [==============================] - 0s 9ms/step\n",
      "Score (RMSE): 0.03584847364420953\n",
      "time to execute =  0:05:57.444078\n",
      "Iteration x =  7150  to row-stepsize  7797\n",
      "Model: \"model_46\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_47 (InputLayer)          [(None, 10, 1)]      0           []                               \n",
      "                                                                                                  \n",
      " layer_normalization_368 (Layer  (None, 10, 1)       2           ['input_47[0][0]']               \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " multi_head_attention_184 (Mult  (None, 10, 1)       7169        ['layer_normalization_368[0][0]',\n",
      " iHeadAttention)                                                  'layer_normalization_368[0][0]']\n",
      "                                                                                                  \n",
      " dropout_414 (Dropout)          (None, 10, 1)        0           ['multi_head_attention_184[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " tf.__operators__.add_368 (TFOp  (None, 10, 1)       0           ['dropout_414[0][0]',            \n",
      " Lambda)                                                          'input_47[0][0]']               \n",
      "                                                                                                  \n",
      " layer_normalization_369 (Layer  (None, 10, 1)       2           ['tf.__operators__.add_368[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " conv1d_368 (Conv1D)            (None, 10, 4)        8           ['layer_normalization_369[0][0]']\n",
      "                                                                                                  \n",
      " dropout_415 (Dropout)          (None, 10, 4)        0           ['conv1d_368[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d_369 (Conv1D)            (None, 10, 1)        5           ['dropout_415[0][0]']            \n",
      "                                                                                                  \n",
      " tf.__operators__.add_369 (TFOp  (None, 10, 1)       0           ['conv1d_369[0][0]',             \n",
      " Lambda)                                                          'tf.__operators__.add_368[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_370 (Layer  (None, 10, 1)       2           ['tf.__operators__.add_369[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " multi_head_attention_185 (Mult  (None, 10, 1)       7169        ['layer_normalization_370[0][0]',\n",
      " iHeadAttention)                                                  'layer_normalization_370[0][0]']\n",
      "                                                                                                  \n",
      " dropout_416 (Dropout)          (None, 10, 1)        0           ['multi_head_attention_185[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " tf.__operators__.add_370 (TFOp  (None, 10, 1)       0           ['dropout_416[0][0]',            \n",
      " Lambda)                                                          'tf.__operators__.add_369[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_371 (Layer  (None, 10, 1)       2           ['tf.__operators__.add_370[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " conv1d_370 (Conv1D)            (None, 10, 4)        8           ['layer_normalization_371[0][0]']\n",
      "                                                                                                  \n",
      " dropout_417 (Dropout)          (None, 10, 4)        0           ['conv1d_370[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d_371 (Conv1D)            (None, 10, 1)        5           ['dropout_417[0][0]']            \n",
      "                                                                                                  \n",
      " tf.__operators__.add_371 (TFOp  (None, 10, 1)       0           ['conv1d_371[0][0]',             \n",
      " Lambda)                                                          'tf.__operators__.add_370[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_372 (Layer  (None, 10, 1)       2           ['tf.__operators__.add_371[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " multi_head_attention_186 (Mult  (None, 10, 1)       7169        ['layer_normalization_372[0][0]',\n",
      " iHeadAttention)                                                  'layer_normalization_372[0][0]']\n",
      "                                                                                                  \n",
      " dropout_418 (Dropout)          (None, 10, 1)        0           ['multi_head_attention_186[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " tf.__operators__.add_372 (TFOp  (None, 10, 1)       0           ['dropout_418[0][0]',            \n",
      " Lambda)                                                          'tf.__operators__.add_371[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_373 (Layer  (None, 10, 1)       2           ['tf.__operators__.add_372[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " conv1d_372 (Conv1D)            (None, 10, 4)        8           ['layer_normalization_373[0][0]']\n",
      "                                                                                                  \n",
      " dropout_419 (Dropout)          (None, 10, 4)        0           ['conv1d_372[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d_373 (Conv1D)            (None, 10, 1)        5           ['dropout_419[0][0]']            \n",
      "                                                                                                  \n",
      " tf.__operators__.add_373 (TFOp  (None, 10, 1)       0           ['conv1d_373[0][0]',             \n",
      " Lambda)                                                          'tf.__operators__.add_372[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_374 (Layer  (None, 10, 1)       2           ['tf.__operators__.add_373[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " multi_head_attention_187 (Mult  (None, 10, 1)       7169        ['layer_normalization_374[0][0]',\n",
      " iHeadAttention)                                                  'layer_normalization_374[0][0]']\n",
      "                                                                                                  \n",
      " dropout_420 (Dropout)          (None, 10, 1)        0           ['multi_head_attention_187[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " tf.__operators__.add_374 (TFOp  (None, 10, 1)       0           ['dropout_420[0][0]',            \n",
      " Lambda)                                                          'tf.__operators__.add_373[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_375 (Layer  (None, 10, 1)       2           ['tf.__operators__.add_374[0][0]'\n",
      " Normalization)                                                  ]                                \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                                                  \n",
      " conv1d_374 (Conv1D)            (None, 10, 4)        8           ['layer_normalization_375[0][0]']\n",
      "                                                                                                  \n",
      " dropout_421 (Dropout)          (None, 10, 4)        0           ['conv1d_374[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d_375 (Conv1D)            (None, 10, 1)        5           ['dropout_421[0][0]']            \n",
      "                                                                                                  \n",
      " tf.__operators__.add_375 (TFOp  (None, 10, 1)       0           ['conv1d_375[0][0]',             \n",
      " Lambda)                                                          'tf.__operators__.add_374[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " global_average_pooling1d_46 (G  (None, 10)          0           ['tf.__operators__.add_375[0][0]'\n",
      " lobalAveragePooling1D)                                          ]                                \n",
      "                                                                                                  \n",
      " dense_92 (Dense)               (None, 128)          1408        ['global_average_pooling1d_46[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      " dropout_422 (Dropout)          (None, 128)          0           ['dense_92[0][0]']               \n",
      "                                                                                                  \n",
      " dense_93 (Dense)               (None, 1)            129         ['dropout_422[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 30,281\n",
      "Trainable params: 30,281\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/10\n",
      "88/88 [==============================] - 15s 138ms/step - loss: 0.0011 - val_loss: 0.0014\n",
      "Epoch 2/10\n",
      "88/88 [==============================] - 12s 132ms/step - loss: 0.0010 - val_loss: 0.0014\n",
      "Epoch 3/10\n",
      "88/88 [==============================] - 12s 132ms/step - loss: 9.6422e-04 - val_loss: 0.0014\n",
      "Epoch 4/10\n",
      "88/88 [==============================] - 12s 133ms/step - loss: 9.8027e-04 - val_loss: 0.0014\n",
      "Epoch 5/10\n",
      "88/88 [==============================] - 12s 132ms/step - loss: 9.4374e-04 - val_loss: 0.0014\n",
      "Epoch 6/10\n",
      "88/88 [==============================] - 12s 133ms/step - loss: 9.7426e-04 - val_loss: 0.0014\n",
      "Epoch 7/10\n",
      "88/88 [==============================] - 12s 132ms/step - loss: 9.4052e-04 - val_loss: 0.0014\n",
      "Epoch 8/10\n",
      "88/88 [==============================] - 12s 133ms/step - loss: 9.2342e-04 - val_loss: 0.0014\n",
      "Epoch 9/10\n",
      "88/88 [==============================] - 12s 133ms/step - loss: 9.4772e-04 - val_loss: 0.0014\n",
      "Epoch 10/10\n",
      "88/88 [==============================] - 12s 133ms/step - loss: 8.9722e-04 - val_loss: 0.0013\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0011\n",
      "2/2 [==============================] - 0s 10ms/step\n",
      "Score (RMSE): 0.032989987912223205\n",
      "time to execute =  0:07:58.094078\n",
      "Iteration x =  7200  to row-stepsize  7797\n",
      "Model: \"model_47\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_48 (InputLayer)          [(None, 10, 1)]      0           []                               \n",
      "                                                                                                  \n",
      " layer_normalization_376 (Layer  (None, 10, 1)       2           ['input_48[0][0]']               \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " multi_head_attention_188 (Mult  (None, 10, 1)       7169        ['layer_normalization_376[0][0]',\n",
      " iHeadAttention)                                                  'layer_normalization_376[0][0]']\n",
      "                                                                                                  \n",
      " dropout_423 (Dropout)          (None, 10, 1)        0           ['multi_head_attention_188[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " tf.__operators__.add_376 (TFOp  (None, 10, 1)       0           ['dropout_423[0][0]',            \n",
      " Lambda)                                                          'input_48[0][0]']               \n",
      "                                                                                                  \n",
      " layer_normalization_377 (Layer  (None, 10, 1)       2           ['tf.__operators__.add_376[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " conv1d_376 (Conv1D)            (None, 10, 4)        8           ['layer_normalization_377[0][0]']\n",
      "                                                                                                  \n",
      " dropout_424 (Dropout)          (None, 10, 4)        0           ['conv1d_376[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d_377 (Conv1D)            (None, 10, 1)        5           ['dropout_424[0][0]']            \n",
      "                                                                                                  \n",
      " tf.__operators__.add_377 (TFOp  (None, 10, 1)       0           ['conv1d_377[0][0]',             \n",
      " Lambda)                                                          'tf.__operators__.add_376[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_378 (Layer  (None, 10, 1)       2           ['tf.__operators__.add_377[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " multi_head_attention_189 (Mult  (None, 10, 1)       7169        ['layer_normalization_378[0][0]',\n",
      " iHeadAttention)                                                  'layer_normalization_378[0][0]']\n",
      "                                                                                                  \n",
      " dropout_425 (Dropout)          (None, 10, 1)        0           ['multi_head_attention_189[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " tf.__operators__.add_378 (TFOp  (None, 10, 1)       0           ['dropout_425[0][0]',            \n",
      " Lambda)                                                          'tf.__operators__.add_377[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_379 (Layer  (None, 10, 1)       2           ['tf.__operators__.add_378[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " conv1d_378 (Conv1D)            (None, 10, 4)        8           ['layer_normalization_379[0][0]']\n",
      "                                                                                                  \n",
      " dropout_426 (Dropout)          (None, 10, 4)        0           ['conv1d_378[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d_379 (Conv1D)            (None, 10, 1)        5           ['dropout_426[0][0]']            \n",
      "                                                                                                  \n",
      " tf.__operators__.add_379 (TFOp  (None, 10, 1)       0           ['conv1d_379[0][0]',             \n",
      " Lambda)                                                          'tf.__operators__.add_378[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_380 (Layer  (None, 10, 1)       2           ['tf.__operators__.add_379[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " multi_head_attention_190 (Mult  (None, 10, 1)       7169        ['layer_normalization_380[0][0]',\n",
      " iHeadAttention)                                                  'layer_normalization_380[0][0]']\n",
      "                                                                                                  \n",
      " dropout_427 (Dropout)          (None, 10, 1)        0           ['multi_head_attention_190[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " tf.__operators__.add_380 (TFOp  (None, 10, 1)       0           ['dropout_427[0][0]',            \n",
      " Lambda)                                                          'tf.__operators__.add_379[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_381 (Layer  (None, 10, 1)       2           ['tf.__operators__.add_380[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " conv1d_380 (Conv1D)            (None, 10, 4)        8           ['layer_normalization_381[0][0]']\n",
      "                                                                                                  \n",
      " dropout_428 (Dropout)          (None, 10, 4)        0           ['conv1d_380[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d_381 (Conv1D)            (None, 10, 1)        5           ['dropout_428[0][0]']            \n",
      "                                                                                                  \n",
      " tf.__operators__.add_381 (TFOp  (None, 10, 1)       0           ['conv1d_381[0][0]',             \n",
      " Lambda)                                                          'tf.__operators__.add_380[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_382 (Layer  (None, 10, 1)       2           ['tf.__operators__.add_381[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " multi_head_attention_191 (Mult  (None, 10, 1)       7169        ['layer_normalization_382[0][0]',\n",
      " iHeadAttention)                                                  'layer_normalization_382[0][0]']\n",
      "                                                                                                  \n",
      " dropout_429 (Dropout)          (None, 10, 1)        0           ['multi_head_attention_191[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " tf.__operators__.add_382 (TFOp  (None, 10, 1)       0           ['dropout_429[0][0]',            \n",
      " Lambda)                                                          'tf.__operators__.add_381[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_383 (Layer  (None, 10, 1)       2           ['tf.__operators__.add_382[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " conv1d_382 (Conv1D)            (None, 10, 4)        8           ['layer_normalization_383[0][0]']\n",
      "                                                                                                  \n",
      " dropout_430 (Dropout)          (None, 10, 4)        0           ['conv1d_382[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d_383 (Conv1D)            (None, 10, 1)        5           ['dropout_430[0][0]']            \n",
      "                                                                                                  \n",
      " tf.__operators__.add_383 (TFOp  (None, 10, 1)       0           ['conv1d_383[0][0]',             \n",
      " Lambda)                                                          'tf.__operators__.add_382[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " global_average_pooling1d_47 (G  (None, 10)          0           ['tf.__operators__.add_383[0][0]'\n",
      " lobalAveragePooling1D)                                          ]                                \n",
      "                                                                                                  \n",
      " dense_94 (Dense)               (None, 128)          1408        ['global_average_pooling1d_47[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      " dropout_431 (Dropout)          (None, 128)          0           ['dense_94[0][0]']               \n",
      "                                                                                                  \n",
      " dense_95 (Dense)               (None, 1)            129         ['dropout_431[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 30,281\n",
      "Trainable params: 30,281\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/10\n",
      "88/88 [==============================] - 14s 131ms/step - loss: 0.0012 - val_loss: 0.0015\n",
      "Epoch 2/10\n",
      "88/88 [==============================] - 10s 118ms/step - loss: 0.0011 - val_loss: 0.0014\n",
      "Epoch 3/10\n",
      "88/88 [==============================] - 10s 118ms/step - loss: 0.0011 - val_loss: 0.0014\n",
      "Epoch 4/10\n",
      "88/88 [==============================] - 10s 117ms/step - loss: 0.0010 - val_loss: 0.0014\n",
      "Epoch 5/10\n",
      "88/88 [==============================] - 10s 117ms/step - loss: 0.0010 - val_loss: 0.0014\n",
      "Epoch 6/10\n",
      "88/88 [==============================] - 10s 117ms/step - loss: 9.5443e-04 - val_loss: 0.0013\n",
      "Epoch 7/10\n",
      "88/88 [==============================] - 10s 116ms/step - loss: 9.8219e-04 - val_loss: 0.0013\n",
      "Epoch 8/10\n",
      "88/88 [==============================] - 10s 117ms/step - loss: 9.6927e-04 - val_loss: 0.0013\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/10\n",
      "88/88 [==============================] - 10s 117ms/step - loss: 9.4986e-04 - val_loss: 0.0013\n",
      "Epoch 10/10\n",
      "88/88 [==============================] - 10s 117ms/step - loss: 9.3930e-04 - val_loss: 0.0013\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 7.2944e-04\n",
      "2/2 [==============================] - 0s 9ms/step\n",
      "Score (RMSE): 0.027008114546687632\n",
      "time to execute =  0:09:46.083080\n",
      "Iteration x =  7250  to row-stepsize  7797\n",
      "Model: \"model_48\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_49 (InputLayer)          [(None, 10, 1)]      0           []                               \n",
      "                                                                                                  \n",
      " layer_normalization_384 (Layer  (None, 10, 1)       2           ['input_49[0][0]']               \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " multi_head_attention_192 (Mult  (None, 10, 1)       7169        ['layer_normalization_384[0][0]',\n",
      " iHeadAttention)                                                  'layer_normalization_384[0][0]']\n",
      "                                                                                                  \n",
      " dropout_432 (Dropout)          (None, 10, 1)        0           ['multi_head_attention_192[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " tf.__operators__.add_384 (TFOp  (None, 10, 1)       0           ['dropout_432[0][0]',            \n",
      " Lambda)                                                          'input_49[0][0]']               \n",
      "                                                                                                  \n",
      " layer_normalization_385 (Layer  (None, 10, 1)       2           ['tf.__operators__.add_384[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " conv1d_384 (Conv1D)            (None, 10, 4)        8           ['layer_normalization_385[0][0]']\n",
      "                                                                                                  \n",
      " dropout_433 (Dropout)          (None, 10, 4)        0           ['conv1d_384[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d_385 (Conv1D)            (None, 10, 1)        5           ['dropout_433[0][0]']            \n",
      "                                                                                                  \n",
      " tf.__operators__.add_385 (TFOp  (None, 10, 1)       0           ['conv1d_385[0][0]',             \n",
      " Lambda)                                                          'tf.__operators__.add_384[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_386 (Layer  (None, 10, 1)       2           ['tf.__operators__.add_385[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " multi_head_attention_193 (Mult  (None, 10, 1)       7169        ['layer_normalization_386[0][0]',\n",
      " iHeadAttention)                                                  'layer_normalization_386[0][0]']\n",
      "                                                                                                  \n",
      " dropout_434 (Dropout)          (None, 10, 1)        0           ['multi_head_attention_193[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " tf.__operators__.add_386 (TFOp  (None, 10, 1)       0           ['dropout_434[0][0]',            \n",
      " Lambda)                                                          'tf.__operators__.add_385[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_387 (Layer  (None, 10, 1)       2           ['tf.__operators__.add_386[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " conv1d_386 (Conv1D)            (None, 10, 4)        8           ['layer_normalization_387[0][0]']\n",
      "                                                                                                  \n",
      " dropout_435 (Dropout)          (None, 10, 4)        0           ['conv1d_386[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d_387 (Conv1D)            (None, 10, 1)        5           ['dropout_435[0][0]']            \n",
      "                                                                                                  \n",
      " tf.__operators__.add_387 (TFOp  (None, 10, 1)       0           ['conv1d_387[0][0]',             \n",
      " Lambda)                                                          'tf.__operators__.add_386[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_388 (Layer  (None, 10, 1)       2           ['tf.__operators__.add_387[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " multi_head_attention_194 (Mult  (None, 10, 1)       7169        ['layer_normalization_388[0][0]',\n",
      " iHeadAttention)                                                  'layer_normalization_388[0][0]']\n",
      "                                                                                                  \n",
      " dropout_436 (Dropout)          (None, 10, 1)        0           ['multi_head_attention_194[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " tf.__operators__.add_388 (TFOp  (None, 10, 1)       0           ['dropout_436[0][0]',            \n",
      " Lambda)                                                          'tf.__operators__.add_387[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_389 (Layer  (None, 10, 1)       2           ['tf.__operators__.add_388[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " conv1d_388 (Conv1D)            (None, 10, 4)        8           ['layer_normalization_389[0][0]']\n",
      "                                                                                                  \n",
      " dropout_437 (Dropout)          (None, 10, 4)        0           ['conv1d_388[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d_389 (Conv1D)            (None, 10, 1)        5           ['dropout_437[0][0]']            \n",
      "                                                                                                  \n",
      " tf.__operators__.add_389 (TFOp  (None, 10, 1)       0           ['conv1d_389[0][0]',             \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Lambda)                                                          'tf.__operators__.add_388[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_390 (Layer  (None, 10, 1)       2           ['tf.__operators__.add_389[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " multi_head_attention_195 (Mult  (None, 10, 1)       7169        ['layer_normalization_390[0][0]',\n",
      " iHeadAttention)                                                  'layer_normalization_390[0][0]']\n",
      "                                                                                                  \n",
      " dropout_438 (Dropout)          (None, 10, 1)        0           ['multi_head_attention_195[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " tf.__operators__.add_390 (TFOp  (None, 10, 1)       0           ['dropout_438[0][0]',            \n",
      " Lambda)                                                          'tf.__operators__.add_389[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_391 (Layer  (None, 10, 1)       2           ['tf.__operators__.add_390[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " conv1d_390 (Conv1D)            (None, 10, 4)        8           ['layer_normalization_391[0][0]']\n",
      "                                                                                                  \n",
      " dropout_439 (Dropout)          (None, 10, 4)        0           ['conv1d_390[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d_391 (Conv1D)            (None, 10, 1)        5           ['dropout_439[0][0]']            \n",
      "                                                                                                  \n",
      " tf.__operators__.add_391 (TFOp  (None, 10, 1)       0           ['conv1d_391[0][0]',             \n",
      " Lambda)                                                          'tf.__operators__.add_390[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " global_average_pooling1d_48 (G  (None, 10)          0           ['tf.__operators__.add_391[0][0]'\n",
      " lobalAveragePooling1D)                                          ]                                \n",
      "                                                                                                  \n",
      " dense_96 (Dense)               (None, 128)          1408        ['global_average_pooling1d_48[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      " dropout_440 (Dropout)          (None, 128)          0           ['dense_96[0][0]']               \n",
      "                                                                                                  \n",
      " dense_97 (Dense)               (None, 1)            129         ['dropout_440[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 30,281\n",
      "Trainable params: 30,281\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/10\n",
      "88/88 [==============================] - 13s 122ms/step - loss: 0.0011 - val_loss: 0.0014\n",
      "Epoch 2/10\n",
      "88/88 [==============================] - 10s 118ms/step - loss: 0.0010 - val_loss: 0.0014\n",
      "Epoch 3/10\n",
      "88/88 [==============================] - 10s 117ms/step - loss: 0.0010 - val_loss: 0.0013\n",
      "Epoch 4/10\n",
      "88/88 [==============================] - 10s 118ms/step - loss: 0.0010 - val_loss: 0.0013\n",
      "Epoch 5/10\n",
      "88/88 [==============================] - 10s 117ms/step - loss: 9.7522e-04 - val_loss: 0.0013\n",
      "Epoch 6/10\n",
      "88/88 [==============================] - 10s 118ms/step - loss: 9.6356e-04 - val_loss: 0.0013\n",
      "Epoch 7/10\n",
      "88/88 [==============================] - 10s 118ms/step - loss: 9.7540e-04 - val_loss: 0.0013\n",
      "Epoch 8/10\n",
      "88/88 [==============================] - 10s 117ms/step - loss: 9.3146e-04 - val_loss: 0.0013\n",
      "Epoch 9/10\n",
      "88/88 [==============================] - 10s 118ms/step - loss: 9.2144e-04 - val_loss: 0.0013\n",
      "Epoch 10/10\n",
      "88/88 [==============================] - 10s 118ms/step - loss: 9.2790e-04 - val_loss: 0.0013\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.0013\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "Score (RMSE): 0.03609407251906443\n",
      "time to execute =  0:11:33.489089\n",
      "Iteration x =  7300  to row-stepsize  7797\n",
      "Model: \"model_49\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_50 (InputLayer)          [(None, 10, 1)]      0           []                               \n",
      "                                                                                                  \n",
      " layer_normalization_392 (Layer  (None, 10, 1)       2           ['input_50[0][0]']               \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " multi_head_attention_196 (Mult  (None, 10, 1)       7169        ['layer_normalization_392[0][0]',\n",
      " iHeadAttention)                                                  'layer_normalization_392[0][0]']\n",
      "                                                                                                  \n",
      " dropout_441 (Dropout)          (None, 10, 1)        0           ['multi_head_attention_196[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " tf.__operators__.add_392 (TFOp  (None, 10, 1)       0           ['dropout_441[0][0]',            \n",
      " Lambda)                                                          'input_50[0][0]']               \n",
      "                                                                                                  \n",
      " layer_normalization_393 (Layer  (None, 10, 1)       2           ['tf.__operators__.add_392[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " conv1d_392 (Conv1D)            (None, 10, 4)        8           ['layer_normalization_393[0][0]']\n",
      "                                                                                                  \n",
      " dropout_442 (Dropout)          (None, 10, 4)        0           ['conv1d_392[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d_393 (Conv1D)            (None, 10, 1)        5           ['dropout_442[0][0]']            \n",
      "                                                                                                  \n",
      " tf.__operators__.add_393 (TFOp  (None, 10, 1)       0           ['conv1d_393[0][0]',             \n",
      " Lambda)                                                          'tf.__operators__.add_392[0][0]'\n",
      "                                                                 ]                                \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                                                  \n",
      " layer_normalization_394 (Layer  (None, 10, 1)       2           ['tf.__operators__.add_393[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " multi_head_attention_197 (Mult  (None, 10, 1)       7169        ['layer_normalization_394[0][0]',\n",
      " iHeadAttention)                                                  'layer_normalization_394[0][0]']\n",
      "                                                                                                  \n",
      " dropout_443 (Dropout)          (None, 10, 1)        0           ['multi_head_attention_197[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " tf.__operators__.add_394 (TFOp  (None, 10, 1)       0           ['dropout_443[0][0]',            \n",
      " Lambda)                                                          'tf.__operators__.add_393[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_395 (Layer  (None, 10, 1)       2           ['tf.__operators__.add_394[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " conv1d_394 (Conv1D)            (None, 10, 4)        8           ['layer_normalization_395[0][0]']\n",
      "                                                                                                  \n",
      " dropout_444 (Dropout)          (None, 10, 4)        0           ['conv1d_394[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d_395 (Conv1D)            (None, 10, 1)        5           ['dropout_444[0][0]']            \n",
      "                                                                                                  \n",
      " tf.__operators__.add_395 (TFOp  (None, 10, 1)       0           ['conv1d_395[0][0]',             \n",
      " Lambda)                                                          'tf.__operators__.add_394[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_396 (Layer  (None, 10, 1)       2           ['tf.__operators__.add_395[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " multi_head_attention_198 (Mult  (None, 10, 1)       7169        ['layer_normalization_396[0][0]',\n",
      " iHeadAttention)                                                  'layer_normalization_396[0][0]']\n",
      "                                                                                                  \n",
      " dropout_445 (Dropout)          (None, 10, 1)        0           ['multi_head_attention_198[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " tf.__operators__.add_396 (TFOp  (None, 10, 1)       0           ['dropout_445[0][0]',            \n",
      " Lambda)                                                          'tf.__operators__.add_395[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_397 (Layer  (None, 10, 1)       2           ['tf.__operators__.add_396[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " conv1d_396 (Conv1D)            (None, 10, 4)        8           ['layer_normalization_397[0][0]']\n",
      "                                                                                                  \n",
      " dropout_446 (Dropout)          (None, 10, 4)        0           ['conv1d_396[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d_397 (Conv1D)            (None, 10, 1)        5           ['dropout_446[0][0]']            \n",
      "                                                                                                  \n",
      " tf.__operators__.add_397 (TFOp  (None, 10, 1)       0           ['conv1d_397[0][0]',             \n",
      " Lambda)                                                          'tf.__operators__.add_396[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_398 (Layer  (None, 10, 1)       2           ['tf.__operators__.add_397[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " multi_head_attention_199 (Mult  (None, 10, 1)       7169        ['layer_normalization_398[0][0]',\n",
      " iHeadAttention)                                                  'layer_normalization_398[0][0]']\n",
      "                                                                                                  \n",
      " dropout_447 (Dropout)          (None, 10, 1)        0           ['multi_head_attention_199[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " tf.__operators__.add_398 (TFOp  (None, 10, 1)       0           ['dropout_447[0][0]',            \n",
      " Lambda)                                                          'tf.__operators__.add_397[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_399 (Layer  (None, 10, 1)       2           ['tf.__operators__.add_398[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " conv1d_398 (Conv1D)            (None, 10, 4)        8           ['layer_normalization_399[0][0]']\n",
      "                                                                                                  \n",
      " dropout_448 (Dropout)          (None, 10, 4)        0           ['conv1d_398[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d_399 (Conv1D)            (None, 10, 1)        5           ['dropout_448[0][0]']            \n",
      "                                                                                                  \n",
      " tf.__operators__.add_399 (TFOp  (None, 10, 1)       0           ['conv1d_399[0][0]',             \n",
      " Lambda)                                                          'tf.__operators__.add_398[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " global_average_pooling1d_49 (G  (None, 10)          0           ['tf.__operators__.add_399[0][0]'\n",
      " lobalAveragePooling1D)                                          ]                                \n",
      "                                                                                                  \n",
      " dense_98 (Dense)               (None, 128)          1408        ['global_average_pooling1d_49[0][\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      " dropout_449 (Dropout)          (None, 128)          0           ['dense_98[0][0]']               \n",
      "                                                                                                  \n",
      " dense_99 (Dense)               (None, 1)            129         ['dropout_449[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 30,281\n",
      "Trainable params: 30,281\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/10\n",
      "88/88 [==============================] - 14s 128ms/step - loss: 0.0010 - val_loss: 0.0014\n",
      "Epoch 2/10\n",
      "88/88 [==============================] - 11s 124ms/step - loss: 0.0010 - val_loss: 0.0014\n",
      "Epoch 3/10\n",
      "88/88 [==============================] - 11s 124ms/step - loss: 0.0010 - val_loss: 0.0014\n",
      "Epoch 4/10\n",
      "88/88 [==============================] - 11s 124ms/step - loss: 0.0010 - val_loss: 0.0014\n",
      "Epoch 5/10\n",
      "88/88 [==============================] - 11s 124ms/step - loss: 9.9298e-04 - val_loss: 0.0014\n",
      "Epoch 6/10\n",
      "88/88 [==============================] - 11s 125ms/step - loss: 9.8453e-04 - val_loss: 0.0014\n",
      "Epoch 7/10\n",
      "88/88 [==============================] - 11s 125ms/step - loss: 9.7333e-04 - val_loss: 0.0014\n",
      "Epoch 8/10\n",
      "88/88 [==============================] - 11s 128ms/step - loss: 9.9309e-04 - val_loss: 0.0014\n",
      "Epoch 9/10\n",
      "88/88 [==============================] - 11s 125ms/step - loss: 9.2317e-04 - val_loss: 0.0014\n",
      "Epoch 10/10\n",
      "88/88 [==============================] - 11s 126ms/step - loss: 9.5521e-04 - val_loss: 0.0014\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0015\n",
      "2/2 [==============================] - 0s 9ms/step\n",
      "Score (RMSE): 0.038144444864022985\n",
      "time to execute =  0:13:27.570606\n",
      "Iteration x =  7350  to row-stepsize  7797\n",
      "Model: \"model_50\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_51 (InputLayer)          [(None, 10, 1)]      0           []                               \n",
      "                                                                                                  \n",
      " layer_normalization_400 (Layer  (None, 10, 1)       2           ['input_51[0][0]']               \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " multi_head_attention_200 (Mult  (None, 10, 1)       7169        ['layer_normalization_400[0][0]',\n",
      " iHeadAttention)                                                  'layer_normalization_400[0][0]']\n",
      "                                                                                                  \n",
      " dropout_450 (Dropout)          (None, 10, 1)        0           ['multi_head_attention_200[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " tf.__operators__.add_400 (TFOp  (None, 10, 1)       0           ['dropout_450[0][0]',            \n",
      " Lambda)                                                          'input_51[0][0]']               \n",
      "                                                                                                  \n",
      " layer_normalization_401 (Layer  (None, 10, 1)       2           ['tf.__operators__.add_400[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " conv1d_400 (Conv1D)            (None, 10, 4)        8           ['layer_normalization_401[0][0]']\n",
      "                                                                                                  \n",
      " dropout_451 (Dropout)          (None, 10, 4)        0           ['conv1d_400[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d_401 (Conv1D)            (None, 10, 1)        5           ['dropout_451[0][0]']            \n",
      "                                                                                                  \n",
      " tf.__operators__.add_401 (TFOp  (None, 10, 1)       0           ['conv1d_401[0][0]',             \n",
      " Lambda)                                                          'tf.__operators__.add_400[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_402 (Layer  (None, 10, 1)       2           ['tf.__operators__.add_401[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " multi_head_attention_201 (Mult  (None, 10, 1)       7169        ['layer_normalization_402[0][0]',\n",
      " iHeadAttention)                                                  'layer_normalization_402[0][0]']\n",
      "                                                                                                  \n",
      " dropout_452 (Dropout)          (None, 10, 1)        0           ['multi_head_attention_201[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " tf.__operators__.add_402 (TFOp  (None, 10, 1)       0           ['dropout_452[0][0]',            \n",
      " Lambda)                                                          'tf.__operators__.add_401[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_403 (Layer  (None, 10, 1)       2           ['tf.__operators__.add_402[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " conv1d_402 (Conv1D)            (None, 10, 4)        8           ['layer_normalization_403[0][0]']\n",
      "                                                                                                  \n",
      " dropout_453 (Dropout)          (None, 10, 4)        0           ['conv1d_402[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d_403 (Conv1D)            (None, 10, 1)        5           ['dropout_453[0][0]']            \n",
      "                                                                                                  \n",
      " tf.__operators__.add_403 (TFOp  (None, 10, 1)       0           ['conv1d_403[0][0]',             \n",
      " Lambda)                                                          'tf.__operators__.add_402[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_404 (Layer  (None, 10, 1)       2           ['tf.__operators__.add_403[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " multi_head_attention_202 (Mult  (None, 10, 1)       7169        ['layer_normalization_404[0][0]',\n",
      " iHeadAttention)                                                  'layer_normalization_404[0][0]']\n",
      "                                                                                                  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " dropout_454 (Dropout)          (None, 10, 1)        0           ['multi_head_attention_202[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " tf.__operators__.add_404 (TFOp  (None, 10, 1)       0           ['dropout_454[0][0]',            \n",
      " Lambda)                                                          'tf.__operators__.add_403[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_405 (Layer  (None, 10, 1)       2           ['tf.__operators__.add_404[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " conv1d_404 (Conv1D)            (None, 10, 4)        8           ['layer_normalization_405[0][0]']\n",
      "                                                                                                  \n",
      " dropout_455 (Dropout)          (None, 10, 4)        0           ['conv1d_404[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d_405 (Conv1D)            (None, 10, 1)        5           ['dropout_455[0][0]']            \n",
      "                                                                                                  \n",
      " tf.__operators__.add_405 (TFOp  (None, 10, 1)       0           ['conv1d_405[0][0]',             \n",
      " Lambda)                                                          'tf.__operators__.add_404[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_406 (Layer  (None, 10, 1)       2           ['tf.__operators__.add_405[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " multi_head_attention_203 (Mult  (None, 10, 1)       7169        ['layer_normalization_406[0][0]',\n",
      " iHeadAttention)                                                  'layer_normalization_406[0][0]']\n",
      "                                                                                                  \n",
      " dropout_456 (Dropout)          (None, 10, 1)        0           ['multi_head_attention_203[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " tf.__operators__.add_406 (TFOp  (None, 10, 1)       0           ['dropout_456[0][0]',            \n",
      " Lambda)                                                          'tf.__operators__.add_405[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_407 (Layer  (None, 10, 1)       2           ['tf.__operators__.add_406[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " conv1d_406 (Conv1D)            (None, 10, 4)        8           ['layer_normalization_407[0][0]']\n",
      "                                                                                                  \n",
      " dropout_457 (Dropout)          (None, 10, 4)        0           ['conv1d_406[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d_407 (Conv1D)            (None, 10, 1)        5           ['dropout_457[0][0]']            \n",
      "                                                                                                  \n",
      " tf.__operators__.add_407 (TFOp  (None, 10, 1)       0           ['conv1d_407[0][0]',             \n",
      " Lambda)                                                          'tf.__operators__.add_406[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " global_average_pooling1d_50 (G  (None, 10)          0           ['tf.__operators__.add_407[0][0]'\n",
      " lobalAveragePooling1D)                                          ]                                \n",
      "                                                                                                  \n",
      " dense_100 (Dense)              (None, 128)          1408        ['global_average_pooling1d_50[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      " dropout_458 (Dropout)          (None, 128)          0           ['dense_100[0][0]']              \n",
      "                                                                                                  \n",
      " dense_101 (Dense)              (None, 1)            129         ['dropout_458[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 30,281\n",
      "Trainable params: 30,281\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/10\n",
      "88/88 [==============================] - 15s 143ms/step - loss: 0.0011 - val_loss: 0.0014\n",
      "Epoch 2/10\n",
      "88/88 [==============================] - 11s 124ms/step - loss: 0.0010 - val_loss: 0.0014\n",
      "Epoch 3/10\n",
      "88/88 [==============================] - 11s 124ms/step - loss: 0.0011 - val_loss: 0.0014\n",
      "Epoch 4/10\n",
      "88/88 [==============================] - 11s 124ms/step - loss: 0.0010 - val_loss: 0.0014\n",
      "Epoch 5/10\n",
      "88/88 [==============================] - 11s 124ms/step - loss: 9.8553e-04 - val_loss: 0.0014\n",
      "Epoch 6/10\n",
      "88/88 [==============================] - 11s 123ms/step - loss: 9.9220e-04 - val_loss: 0.0014\n",
      "Epoch 7/10\n",
      "88/88 [==============================] - 11s 124ms/step - loss: 9.7179e-04 - val_loss: 0.0014\n",
      "Epoch 8/10\n",
      "88/88 [==============================] - 11s 124ms/step - loss: 9.5772e-04 - val_loss: 0.0014\n",
      "Epoch 9/10\n",
      "88/88 [==============================] - 11s 125ms/step - loss: 9.6340e-04 - val_loss: 0.0014\n",
      "Epoch 10/10\n",
      "88/88 [==============================] - 11s 124ms/step - loss: 9.2250e-04 - val_loss: 0.0014\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0011\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "Score (RMSE): 0.03333357578730291\n",
      "time to execute =  0:15:21.862131\n",
      "Iteration x =  7400  to row-stepsize  7797\n",
      "Model: \"model_51\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_52 (InputLayer)          [(None, 10, 1)]      0           []                               \n",
      "                                                                                                  \n",
      " layer_normalization_408 (Layer  (None, 10, 1)       2           ['input_52[0][0]']               \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " multi_head_attention_204 (Mult  (None, 10, 1)       7169        ['layer_normalization_408[0][0]',\n",
      " iHeadAttention)                                                  'layer_normalization_408[0][0]']\n",
      "                                                                                                  \n",
      " dropout_459 (Dropout)          (None, 10, 1)        0           ['multi_head_attention_204[0][0]'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " tf.__operators__.add_408 (TFOp  (None, 10, 1)       0           ['dropout_459[0][0]',            \n",
      " Lambda)                                                          'input_52[0][0]']               \n",
      "                                                                                                  \n",
      " layer_normalization_409 (Layer  (None, 10, 1)       2           ['tf.__operators__.add_408[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " conv1d_408 (Conv1D)            (None, 10, 4)        8           ['layer_normalization_409[0][0]']\n",
      "                                                                                                  \n",
      " dropout_460 (Dropout)          (None, 10, 4)        0           ['conv1d_408[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d_409 (Conv1D)            (None, 10, 1)        5           ['dropout_460[0][0]']            \n",
      "                                                                                                  \n",
      " tf.__operators__.add_409 (TFOp  (None, 10, 1)       0           ['conv1d_409[0][0]',             \n",
      " Lambda)                                                          'tf.__operators__.add_408[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_410 (Layer  (None, 10, 1)       2           ['tf.__operators__.add_409[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " multi_head_attention_205 (Mult  (None, 10, 1)       7169        ['layer_normalization_410[0][0]',\n",
      " iHeadAttention)                                                  'layer_normalization_410[0][0]']\n",
      "                                                                                                  \n",
      " dropout_461 (Dropout)          (None, 10, 1)        0           ['multi_head_attention_205[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " tf.__operators__.add_410 (TFOp  (None, 10, 1)       0           ['dropout_461[0][0]',            \n",
      " Lambda)                                                          'tf.__operators__.add_409[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_411 (Layer  (None, 10, 1)       2           ['tf.__operators__.add_410[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " conv1d_410 (Conv1D)            (None, 10, 4)        8           ['layer_normalization_411[0][0]']\n",
      "                                                                                                  \n",
      " dropout_462 (Dropout)          (None, 10, 4)        0           ['conv1d_410[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d_411 (Conv1D)            (None, 10, 1)        5           ['dropout_462[0][0]']            \n",
      "                                                                                                  \n",
      " tf.__operators__.add_411 (TFOp  (None, 10, 1)       0           ['conv1d_411[0][0]',             \n",
      " Lambda)                                                          'tf.__operators__.add_410[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_412 (Layer  (None, 10, 1)       2           ['tf.__operators__.add_411[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " multi_head_attention_206 (Mult  (None, 10, 1)       7169        ['layer_normalization_412[0][0]',\n",
      " iHeadAttention)                                                  'layer_normalization_412[0][0]']\n",
      "                                                                                                  \n",
      " dropout_463 (Dropout)          (None, 10, 1)        0           ['multi_head_attention_206[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " tf.__operators__.add_412 (TFOp  (None, 10, 1)       0           ['dropout_463[0][0]',            \n",
      " Lambda)                                                          'tf.__operators__.add_411[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_413 (Layer  (None, 10, 1)       2           ['tf.__operators__.add_412[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " conv1d_412 (Conv1D)            (None, 10, 4)        8           ['layer_normalization_413[0][0]']\n",
      "                                                                                                  \n",
      " dropout_464 (Dropout)          (None, 10, 4)        0           ['conv1d_412[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d_413 (Conv1D)            (None, 10, 1)        5           ['dropout_464[0][0]']            \n",
      "                                                                                                  \n",
      " tf.__operators__.add_413 (TFOp  (None, 10, 1)       0           ['conv1d_413[0][0]',             \n",
      " Lambda)                                                          'tf.__operators__.add_412[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_414 (Layer  (None, 10, 1)       2           ['tf.__operators__.add_413[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " multi_head_attention_207 (Mult  (None, 10, 1)       7169        ['layer_normalization_414[0][0]',\n",
      " iHeadAttention)                                                  'layer_normalization_414[0][0]']\n",
      "                                                                                                  \n",
      " dropout_465 (Dropout)          (None, 10, 1)        0           ['multi_head_attention_207[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " tf.__operators__.add_414 (TFOp  (None, 10, 1)       0           ['dropout_465[0][0]',            \n",
      " Lambda)                                                          'tf.__operators__.add_413[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " layer_normalization_415 (Layer  (None, 10, 1)       2           ['tf.__operators__.add_414[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " conv1d_414 (Conv1D)            (None, 10, 4)        8           ['layer_normalization_415[0][0]']\n",
      "                                                                                                  \n",
      " dropout_466 (Dropout)          (None, 10, 4)        0           ['conv1d_414[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d_415 (Conv1D)            (None, 10, 1)        5           ['dropout_466[0][0]']            \n",
      "                                                                                                  \n",
      " tf.__operators__.add_415 (TFOp  (None, 10, 1)       0           ['conv1d_415[0][0]',             \n",
      " Lambda)                                                          'tf.__operators__.add_414[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " global_average_pooling1d_51 (G  (None, 10)          0           ['tf.__operators__.add_415[0][0]'\n",
      " lobalAveragePooling1D)                                          ]                                \n",
      "                                                                                                  \n",
      " dense_102 (Dense)              (None, 128)          1408        ['global_average_pooling1d_51[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      " dropout_467 (Dropout)          (None, 128)          0           ['dense_102[0][0]']              \n",
      "                                                                                                  \n",
      " dense_103 (Dense)              (None, 1)            129         ['dropout_467[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 30,281\n",
      "Trainable params: 30,281\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/10\n",
      "88/88 [==============================] - 14s 129ms/step - loss: 0.0011 - val_loss: 0.0014\n",
      "Epoch 2/10\n",
      "88/88 [==============================] - 11s 125ms/step - loss: 0.0010 - val_loss: 0.0014\n",
      "Epoch 3/10\n",
      "88/88 [==============================] - 11s 124ms/step - loss: 9.9177e-04 - val_loss: 0.0014\n",
      "Epoch 4/10\n",
      "88/88 [==============================] - 11s 125ms/step - loss: 9.7847e-04 - val_loss: 0.0014\n",
      "Epoch 5/10\n",
      "88/88 [==============================] - 11s 124ms/step - loss: 9.6641e-04 - val_loss: 0.0014\n",
      "Epoch 6/10\n",
      "88/88 [==============================] - 11s 123ms/step - loss: 9.5891e-04 - val_loss: 0.0014\n",
      "Epoch 7/10\n",
      "88/88 [==============================] - 11s 124ms/step - loss: 9.7890e-04 - val_loss: 0.0014\n",
      "Epoch 8/10\n",
      "88/88 [==============================] - 11s 124ms/step - loss: 9.8200e-04 - val_loss: 0.0014\n",
      "Epoch 9/10\n",
      "88/88 [==============================] - 11s 123ms/step - loss: 9.3096e-04 - val_loss: 0.0014\n",
      "Epoch 10/10\n",
      "88/88 [==============================] - 11s 124ms/step - loss: 9.6453e-04 - val_loss: 0.0014\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0015\n",
      "2/2 [==============================] - 0s 9ms/step\n",
      "Score (RMSE): 0.03823773499944679\n",
      "time to execute =  0:17:15.065131\n",
      "Iteration x =  7450  to row-stepsize  7797\n",
      "Model: \"model_52\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_53 (InputLayer)          [(None, 10, 1)]      0           []                               \n",
      "                                                                                                  \n",
      " layer_normalization_416 (Layer  (None, 10, 1)       2           ['input_53[0][0]']               \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " multi_head_attention_208 (Mult  (None, 10, 1)       7169        ['layer_normalization_416[0][0]',\n",
      " iHeadAttention)                                                  'layer_normalization_416[0][0]']\n",
      "                                                                                                  \n",
      " dropout_468 (Dropout)          (None, 10, 1)        0           ['multi_head_attention_208[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " tf.__operators__.add_416 (TFOp  (None, 10, 1)       0           ['dropout_468[0][0]',            \n",
      " Lambda)                                                          'input_53[0][0]']               \n",
      "                                                                                                  \n",
      " layer_normalization_417 (Layer  (None, 10, 1)       2           ['tf.__operators__.add_416[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " conv1d_416 (Conv1D)            (None, 10, 4)        8           ['layer_normalization_417[0][0]']\n",
      "                                                                                                  \n",
      " dropout_469 (Dropout)          (None, 10, 4)        0           ['conv1d_416[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d_417 (Conv1D)            (None, 10, 1)        5           ['dropout_469[0][0]']            \n",
      "                                                                                                  \n",
      " tf.__operators__.add_417 (TFOp  (None, 10, 1)       0           ['conv1d_417[0][0]',             \n",
      " Lambda)                                                          'tf.__operators__.add_416[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_418 (Layer  (None, 10, 1)       2           ['tf.__operators__.add_417[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " multi_head_attention_209 (Mult  (None, 10, 1)       7169        ['layer_normalization_418[0][0]',\n",
      " iHeadAttention)                                                  'layer_normalization_418[0][0]']\n",
      "                                                                                                  \n",
      " dropout_470 (Dropout)          (None, 10, 1)        0           ['multi_head_attention_209[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " tf.__operators__.add_418 (TFOp  (None, 10, 1)       0           ['dropout_470[0][0]',            \n",
      " Lambda)                                                          'tf.__operators__.add_417[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_419 (Layer  (None, 10, 1)       2           ['tf.__operators__.add_418[0][0]'\n",
      " Normalization)                                                  ]                                \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                                                  \n",
      " conv1d_418 (Conv1D)            (None, 10, 4)        8           ['layer_normalization_419[0][0]']\n",
      "                                                                                                  \n",
      " dropout_471 (Dropout)          (None, 10, 4)        0           ['conv1d_418[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d_419 (Conv1D)            (None, 10, 1)        5           ['dropout_471[0][0]']            \n",
      "                                                                                                  \n",
      " tf.__operators__.add_419 (TFOp  (None, 10, 1)       0           ['conv1d_419[0][0]',             \n",
      " Lambda)                                                          'tf.__operators__.add_418[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_420 (Layer  (None, 10, 1)       2           ['tf.__operators__.add_419[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " multi_head_attention_210 (Mult  (None, 10, 1)       7169        ['layer_normalization_420[0][0]',\n",
      " iHeadAttention)                                                  'layer_normalization_420[0][0]']\n",
      "                                                                                                  \n",
      " dropout_472 (Dropout)          (None, 10, 1)        0           ['multi_head_attention_210[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " tf.__operators__.add_420 (TFOp  (None, 10, 1)       0           ['dropout_472[0][0]',            \n",
      " Lambda)                                                          'tf.__operators__.add_419[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_421 (Layer  (None, 10, 1)       2           ['tf.__operators__.add_420[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " conv1d_420 (Conv1D)            (None, 10, 4)        8           ['layer_normalization_421[0][0]']\n",
      "                                                                                                  \n",
      " dropout_473 (Dropout)          (None, 10, 4)        0           ['conv1d_420[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d_421 (Conv1D)            (None, 10, 1)        5           ['dropout_473[0][0]']            \n",
      "                                                                                                  \n",
      " tf.__operators__.add_421 (TFOp  (None, 10, 1)       0           ['conv1d_421[0][0]',             \n",
      " Lambda)                                                          'tf.__operators__.add_420[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_422 (Layer  (None, 10, 1)       2           ['tf.__operators__.add_421[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " multi_head_attention_211 (Mult  (None, 10, 1)       7169        ['layer_normalization_422[0][0]',\n",
      " iHeadAttention)                                                  'layer_normalization_422[0][0]']\n",
      "                                                                                                  \n",
      " dropout_474 (Dropout)          (None, 10, 1)        0           ['multi_head_attention_211[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " tf.__operators__.add_422 (TFOp  (None, 10, 1)       0           ['dropout_474[0][0]',            \n",
      " Lambda)                                                          'tf.__operators__.add_421[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_423 (Layer  (None, 10, 1)       2           ['tf.__operators__.add_422[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " conv1d_422 (Conv1D)            (None, 10, 4)        8           ['layer_normalization_423[0][0]']\n",
      "                                                                                                  \n",
      " dropout_475 (Dropout)          (None, 10, 4)        0           ['conv1d_422[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d_423 (Conv1D)            (None, 10, 1)        5           ['dropout_475[0][0]']            \n",
      "                                                                                                  \n",
      " tf.__operators__.add_423 (TFOp  (None, 10, 1)       0           ['conv1d_423[0][0]',             \n",
      " Lambda)                                                          'tf.__operators__.add_422[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " global_average_pooling1d_52 (G  (None, 10)          0           ['tf.__operators__.add_423[0][0]'\n",
      " lobalAveragePooling1D)                                          ]                                \n",
      "                                                                                                  \n",
      " dense_104 (Dense)              (None, 128)          1408        ['global_average_pooling1d_52[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      " dropout_476 (Dropout)          (None, 128)          0           ['dense_104[0][0]']              \n",
      "                                                                                                  \n",
      " dense_105 (Dense)              (None, 1)            129         ['dropout_476[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 30,281\n",
      "Trainable params: 30,281\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/10\n",
      "88/88 [==============================] - 14s 129ms/step - loss: 0.0012 - val_loss: 0.0015\n",
      "Epoch 2/10\n",
      "88/88 [==============================] - 11s 125ms/step - loss: 0.0011 - val_loss: 0.0014\n",
      "Epoch 3/10\n",
      "88/88 [==============================] - 11s 125ms/step - loss: 0.0011 - val_loss: 0.0014\n",
      "Epoch 4/10\n",
      "88/88 [==============================] - 11s 126ms/step - loss: 0.0011 - val_loss: 0.0014\n",
      "Epoch 5/10\n",
      "88/88 [==============================] - 11s 126ms/step - loss: 0.0010 - val_loss: 0.0014\n",
      "Epoch 6/10\n",
      "88/88 [==============================] - 11s 126ms/step - loss: 0.0010 - val_loss: 0.0014\n",
      "Epoch 7/10\n",
      "88/88 [==============================] - 11s 125ms/step - loss: 0.0010 - val_loss: 0.0014\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/10\n",
      "88/88 [==============================] - 11s 126ms/step - loss: 9.9313e-04 - val_loss: 0.0014\n",
      "Epoch 9/10\n",
      "88/88 [==============================] - 11s 126ms/step - loss: 0.0010 - val_loss: 0.0014\n",
      "Epoch 10/10\n",
      "88/88 [==============================] - 11s 124ms/step - loss: 9.8167e-04 - val_loss: 0.0014\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 9.8426e-04\n",
      "2/2 [==============================] - 0s 9ms/step\n",
      "Score (RMSE): 0.031372887596273165\n",
      "time to execute =  0:19:09.630132\n",
      "Iteration x =  7500  to row-stepsize  7797\n",
      "Model: \"model_53\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_54 (InputLayer)          [(None, 10, 1)]      0           []                               \n",
      "                                                                                                  \n",
      " layer_normalization_424 (Layer  (None, 10, 1)       2           ['input_54[0][0]']               \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " multi_head_attention_212 (Mult  (None, 10, 1)       7169        ['layer_normalization_424[0][0]',\n",
      " iHeadAttention)                                                  'layer_normalization_424[0][0]']\n",
      "                                                                                                  \n",
      " dropout_477 (Dropout)          (None, 10, 1)        0           ['multi_head_attention_212[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " tf.__operators__.add_424 (TFOp  (None, 10, 1)       0           ['dropout_477[0][0]',            \n",
      " Lambda)                                                          'input_54[0][0]']               \n",
      "                                                                                                  \n",
      " layer_normalization_425 (Layer  (None, 10, 1)       2           ['tf.__operators__.add_424[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " conv1d_424 (Conv1D)            (None, 10, 4)        8           ['layer_normalization_425[0][0]']\n",
      "                                                                                                  \n",
      " dropout_478 (Dropout)          (None, 10, 4)        0           ['conv1d_424[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d_425 (Conv1D)            (None, 10, 1)        5           ['dropout_478[0][0]']            \n",
      "                                                                                                  \n",
      " tf.__operators__.add_425 (TFOp  (None, 10, 1)       0           ['conv1d_425[0][0]',             \n",
      " Lambda)                                                          'tf.__operators__.add_424[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_426 (Layer  (None, 10, 1)       2           ['tf.__operators__.add_425[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " multi_head_attention_213 (Mult  (None, 10, 1)       7169        ['layer_normalization_426[0][0]',\n",
      " iHeadAttention)                                                  'layer_normalization_426[0][0]']\n",
      "                                                                                                  \n",
      " dropout_479 (Dropout)          (None, 10, 1)        0           ['multi_head_attention_213[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " tf.__operators__.add_426 (TFOp  (None, 10, 1)       0           ['dropout_479[0][0]',            \n",
      " Lambda)                                                          'tf.__operators__.add_425[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_427 (Layer  (None, 10, 1)       2           ['tf.__operators__.add_426[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " conv1d_426 (Conv1D)            (None, 10, 4)        8           ['layer_normalization_427[0][0]']\n",
      "                                                                                                  \n",
      " dropout_480 (Dropout)          (None, 10, 4)        0           ['conv1d_426[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d_427 (Conv1D)            (None, 10, 1)        5           ['dropout_480[0][0]']            \n",
      "                                                                                                  \n",
      " tf.__operators__.add_427 (TFOp  (None, 10, 1)       0           ['conv1d_427[0][0]',             \n",
      " Lambda)                                                          'tf.__operators__.add_426[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_428 (Layer  (None, 10, 1)       2           ['tf.__operators__.add_427[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " multi_head_attention_214 (Mult  (None, 10, 1)       7169        ['layer_normalization_428[0][0]',\n",
      " iHeadAttention)                                                  'layer_normalization_428[0][0]']\n",
      "                                                                                                  \n",
      " dropout_481 (Dropout)          (None, 10, 1)        0           ['multi_head_attention_214[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " tf.__operators__.add_428 (TFOp  (None, 10, 1)       0           ['dropout_481[0][0]',            \n",
      " Lambda)                                                          'tf.__operators__.add_427[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_429 (Layer  (None, 10, 1)       2           ['tf.__operators__.add_428[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " conv1d_428 (Conv1D)            (None, 10, 4)        8           ['layer_normalization_429[0][0]']\n",
      "                                                                                                  \n",
      " dropout_482 (Dropout)          (None, 10, 4)        0           ['conv1d_428[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d_429 (Conv1D)            (None, 10, 1)        5           ['dropout_482[0][0]']            \n",
      "                                                                                                  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " tf.__operators__.add_429 (TFOp  (None, 10, 1)       0           ['conv1d_429[0][0]',             \n",
      " Lambda)                                                          'tf.__operators__.add_428[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_430 (Layer  (None, 10, 1)       2           ['tf.__operators__.add_429[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " multi_head_attention_215 (Mult  (None, 10, 1)       7169        ['layer_normalization_430[0][0]',\n",
      " iHeadAttention)                                                  'layer_normalization_430[0][0]']\n",
      "                                                                                                  \n",
      " dropout_483 (Dropout)          (None, 10, 1)        0           ['multi_head_attention_215[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " tf.__operators__.add_430 (TFOp  (None, 10, 1)       0           ['dropout_483[0][0]',            \n",
      " Lambda)                                                          'tf.__operators__.add_429[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_431 (Layer  (None, 10, 1)       2           ['tf.__operators__.add_430[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " conv1d_430 (Conv1D)            (None, 10, 4)        8           ['layer_normalization_431[0][0]']\n",
      "                                                                                                  \n",
      " dropout_484 (Dropout)          (None, 10, 4)        0           ['conv1d_430[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d_431 (Conv1D)            (None, 10, 1)        5           ['dropout_484[0][0]']            \n",
      "                                                                                                  \n",
      " tf.__operators__.add_431 (TFOp  (None, 10, 1)       0           ['conv1d_431[0][0]',             \n",
      " Lambda)                                                          'tf.__operators__.add_430[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " global_average_pooling1d_53 (G  (None, 10)          0           ['tf.__operators__.add_431[0][0]'\n",
      " lobalAveragePooling1D)                                          ]                                \n",
      "                                                                                                  \n",
      " dense_106 (Dense)              (None, 128)          1408        ['global_average_pooling1d_53[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      " dropout_485 (Dropout)          (None, 128)          0           ['dense_106[0][0]']              \n",
      "                                                                                                  \n",
      " dense_107 (Dense)              (None, 1)            129         ['dropout_485[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 30,281\n",
      "Trainable params: 30,281\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/10\n",
      "88/88 [==============================] - 14s 132ms/step - loss: 0.0012 - val_loss: 0.0014\n",
      "Epoch 2/10\n",
      "88/88 [==============================] - 11s 128ms/step - loss: 0.0011 - val_loss: 0.0014\n",
      "Epoch 3/10\n",
      "88/88 [==============================] - 11s 128ms/step - loss: 0.0011 - val_loss: 0.0014\n",
      "Epoch 4/10\n",
      "88/88 [==============================] - 11s 127ms/step - loss: 0.0010 - val_loss: 0.0014\n",
      "Epoch 5/10\n",
      "88/88 [==============================] - 11s 127ms/step - loss: 0.0011 - val_loss: 0.0014\n",
      "Epoch 6/10\n",
      "88/88 [==============================] - 11s 127ms/step - loss: 0.0010 - val_loss: 0.0013\n",
      "Epoch 7/10\n",
      "88/88 [==============================] - 11s 127ms/step - loss: 0.0010 - val_loss: 0.0013\n",
      "Epoch 8/10\n",
      "88/88 [==============================] - 11s 127ms/step - loss: 9.6178e-04 - val_loss: 0.0013\n",
      "Epoch 9/10\n",
      "88/88 [==============================] - 11s 128ms/step - loss: 0.0010 - val_loss: 0.0013\n",
      "Epoch 10/10\n",
      "88/88 [==============================] - 11s 128ms/step - loss: 9.8957e-04 - val_loss: 0.0013\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 7.7787e-04\n",
      "2/2 [==============================] - 0s 11ms/step\n",
      "Score (RMSE): 0.027890236170889066\n",
      "time to execute =  0:21:05.828132\n",
      "Iteration x =  7550  to row-stepsize  7797\n",
      "Model: \"model_54\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_55 (InputLayer)          [(None, 10, 1)]      0           []                               \n",
      "                                                                                                  \n",
      " layer_normalization_432 (Layer  (None, 10, 1)       2           ['input_55[0][0]']               \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " multi_head_attention_216 (Mult  (None, 10, 1)       7169        ['layer_normalization_432[0][0]',\n",
      " iHeadAttention)                                                  'layer_normalization_432[0][0]']\n",
      "                                                                                                  \n",
      " dropout_486 (Dropout)          (None, 10, 1)        0           ['multi_head_attention_216[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " tf.__operators__.add_432 (TFOp  (None, 10, 1)       0           ['dropout_486[0][0]',            \n",
      " Lambda)                                                          'input_55[0][0]']               \n",
      "                                                                                                  \n",
      " layer_normalization_433 (Layer  (None, 10, 1)       2           ['tf.__operators__.add_432[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " conv1d_432 (Conv1D)            (None, 10, 4)        8           ['layer_normalization_433[0][0]']\n",
      "                                                                                                  \n",
      " dropout_487 (Dropout)          (None, 10, 4)        0           ['conv1d_432[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d_433 (Conv1D)            (None, 10, 1)        5           ['dropout_487[0][0]']            \n",
      "                                                                                                  \n",
      " tf.__operators__.add_433 (TFOp  (None, 10, 1)       0           ['conv1d_433[0][0]',             \n",
      " Lambda)                                                          'tf.__operators__.add_432[0][0]'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_434 (Layer  (None, 10, 1)       2           ['tf.__operators__.add_433[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " multi_head_attention_217 (Mult  (None, 10, 1)       7169        ['layer_normalization_434[0][0]',\n",
      " iHeadAttention)                                                  'layer_normalization_434[0][0]']\n",
      "                                                                                                  \n",
      " dropout_488 (Dropout)          (None, 10, 1)        0           ['multi_head_attention_217[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " tf.__operators__.add_434 (TFOp  (None, 10, 1)       0           ['dropout_488[0][0]',            \n",
      " Lambda)                                                          'tf.__operators__.add_433[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_435 (Layer  (None, 10, 1)       2           ['tf.__operators__.add_434[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " conv1d_434 (Conv1D)            (None, 10, 4)        8           ['layer_normalization_435[0][0]']\n",
      "                                                                                                  \n",
      " dropout_489 (Dropout)          (None, 10, 4)        0           ['conv1d_434[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d_435 (Conv1D)            (None, 10, 1)        5           ['dropout_489[0][0]']            \n",
      "                                                                                                  \n",
      " tf.__operators__.add_435 (TFOp  (None, 10, 1)       0           ['conv1d_435[0][0]',             \n",
      " Lambda)                                                          'tf.__operators__.add_434[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_436 (Layer  (None, 10, 1)       2           ['tf.__operators__.add_435[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " multi_head_attention_218 (Mult  (None, 10, 1)       7169        ['layer_normalization_436[0][0]',\n",
      " iHeadAttention)                                                  'layer_normalization_436[0][0]']\n",
      "                                                                                                  \n",
      " dropout_490 (Dropout)          (None, 10, 1)        0           ['multi_head_attention_218[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " tf.__operators__.add_436 (TFOp  (None, 10, 1)       0           ['dropout_490[0][0]',            \n",
      " Lambda)                                                          'tf.__operators__.add_435[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_437 (Layer  (None, 10, 1)       2           ['tf.__operators__.add_436[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " conv1d_436 (Conv1D)            (None, 10, 4)        8           ['layer_normalization_437[0][0]']\n",
      "                                                                                                  \n",
      " dropout_491 (Dropout)          (None, 10, 4)        0           ['conv1d_436[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d_437 (Conv1D)            (None, 10, 1)        5           ['dropout_491[0][0]']            \n",
      "                                                                                                  \n",
      " tf.__operators__.add_437 (TFOp  (None, 10, 1)       0           ['conv1d_437[0][0]',             \n",
      " Lambda)                                                          'tf.__operators__.add_436[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_438 (Layer  (None, 10, 1)       2           ['tf.__operators__.add_437[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " multi_head_attention_219 (Mult  (None, 10, 1)       7169        ['layer_normalization_438[0][0]',\n",
      " iHeadAttention)                                                  'layer_normalization_438[0][0]']\n",
      "                                                                                                  \n",
      " dropout_492 (Dropout)          (None, 10, 1)        0           ['multi_head_attention_219[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " tf.__operators__.add_438 (TFOp  (None, 10, 1)       0           ['dropout_492[0][0]',            \n",
      " Lambda)                                                          'tf.__operators__.add_437[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_439 (Layer  (None, 10, 1)       2           ['tf.__operators__.add_438[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " conv1d_438 (Conv1D)            (None, 10, 4)        8           ['layer_normalization_439[0][0]']\n",
      "                                                                                                  \n",
      " dropout_493 (Dropout)          (None, 10, 4)        0           ['conv1d_438[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d_439 (Conv1D)            (None, 10, 1)        5           ['dropout_493[0][0]']            \n",
      "                                                                                                  \n",
      " tf.__operators__.add_439 (TFOp  (None, 10, 1)       0           ['conv1d_439[0][0]',             \n",
      " Lambda)                                                          'tf.__operators__.add_438[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " global_average_pooling1d_54 (G  (None, 10)          0           ['tf.__operators__.add_439[0][0]'\n",
      " lobalAveragePooling1D)                                          ]                                \n",
      "                                                                                                  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " dense_108 (Dense)              (None, 128)          1408        ['global_average_pooling1d_54[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      " dropout_494 (Dropout)          (None, 128)          0           ['dense_108[0][0]']              \n",
      "                                                                                                  \n",
      " dense_109 (Dense)              (None, 1)            129         ['dropout_494[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 30,281\n",
      "Trainable params: 30,281\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/10\n",
      "88/88 [==============================] - 14s 130ms/step - loss: 0.0012 - val_loss: 0.0014\n",
      "Epoch 2/10\n",
      "88/88 [==============================] - 11s 126ms/step - loss: 0.0011 - val_loss: 0.0014\n",
      "Epoch 3/10\n",
      "88/88 [==============================] - 11s 125ms/step - loss: 0.0011 - val_loss: 0.0014\n",
      "Epoch 4/10\n",
      "88/88 [==============================] - 11s 125ms/step - loss: 0.0011 - val_loss: 0.0014\n",
      "Epoch 5/10\n",
      "88/88 [==============================] - 11s 126ms/step - loss: 0.0010 - val_loss: 0.0014\n",
      "Epoch 6/10\n",
      "88/88 [==============================] - 11s 126ms/step - loss: 9.7937e-04 - val_loss: 0.0014\n",
      "Epoch 7/10\n",
      "88/88 [==============================] - 11s 125ms/step - loss: 9.9144e-04 - val_loss: 0.0014\n",
      "Epoch 8/10\n",
      "88/88 [==============================] - 11s 124ms/step - loss: 0.0010 - val_loss: 0.0014\n",
      "Epoch 9/10\n",
      "88/88 [==============================] - 11s 125ms/step - loss: 9.8811e-04 - val_loss: 0.0014\n",
      "Epoch 10/10\n",
      "88/88 [==============================] - 11s 127ms/step - loss: 0.0010 - val_loss: 0.0014\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0017\n",
      "2/2 [==============================] - 0s 9ms/step\n",
      "Score (RMSE): 0.041651581751360765\n",
      "time to execute =  0:23:00.285654\n",
      "Iteration x =  7600  to row-stepsize  7797\n",
      "Model: \"model_55\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_56 (InputLayer)          [(None, 10, 1)]      0           []                               \n",
      "                                                                                                  \n",
      " layer_normalization_440 (Layer  (None, 10, 1)       2           ['input_56[0][0]']               \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " multi_head_attention_220 (Mult  (None, 10, 1)       7169        ['layer_normalization_440[0][0]',\n",
      " iHeadAttention)                                                  'layer_normalization_440[0][0]']\n",
      "                                                                                                  \n",
      " dropout_495 (Dropout)          (None, 10, 1)        0           ['multi_head_attention_220[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " tf.__operators__.add_440 (TFOp  (None, 10, 1)       0           ['dropout_495[0][0]',            \n",
      " Lambda)                                                          'input_56[0][0]']               \n",
      "                                                                                                  \n",
      " layer_normalization_441 (Layer  (None, 10, 1)       2           ['tf.__operators__.add_440[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " conv1d_440 (Conv1D)            (None, 10, 4)        8           ['layer_normalization_441[0][0]']\n",
      "                                                                                                  \n",
      " dropout_496 (Dropout)          (None, 10, 4)        0           ['conv1d_440[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d_441 (Conv1D)            (None, 10, 1)        5           ['dropout_496[0][0]']            \n",
      "                                                                                                  \n",
      " tf.__operators__.add_441 (TFOp  (None, 10, 1)       0           ['conv1d_441[0][0]',             \n",
      " Lambda)                                                          'tf.__operators__.add_440[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_442 (Layer  (None, 10, 1)       2           ['tf.__operators__.add_441[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " multi_head_attention_221 (Mult  (None, 10, 1)       7169        ['layer_normalization_442[0][0]',\n",
      " iHeadAttention)                                                  'layer_normalization_442[0][0]']\n",
      "                                                                                                  \n",
      " dropout_497 (Dropout)          (None, 10, 1)        0           ['multi_head_attention_221[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " tf.__operators__.add_442 (TFOp  (None, 10, 1)       0           ['dropout_497[0][0]',            \n",
      " Lambda)                                                          'tf.__operators__.add_441[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_443 (Layer  (None, 10, 1)       2           ['tf.__operators__.add_442[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " conv1d_442 (Conv1D)            (None, 10, 4)        8           ['layer_normalization_443[0][0]']\n",
      "                                                                                                  \n",
      " dropout_498 (Dropout)          (None, 10, 4)        0           ['conv1d_442[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d_443 (Conv1D)            (None, 10, 1)        5           ['dropout_498[0][0]']            \n",
      "                                                                                                  \n",
      " tf.__operators__.add_443 (TFOp  (None, 10, 1)       0           ['conv1d_443[0][0]',             \n",
      " Lambda)                                                          'tf.__operators__.add_442[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_444 (Layer  (None, 10, 1)       2           ['tf.__operators__.add_443[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " multi_head_attention_222 (Mult  (None, 10, 1)       7169        ['layer_normalization_444[0][0]',\n",
      " iHeadAttention)                                                  'layer_normalization_444[0][0]']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                                                  \n",
      " dropout_499 (Dropout)          (None, 10, 1)        0           ['multi_head_attention_222[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " tf.__operators__.add_444 (TFOp  (None, 10, 1)       0           ['dropout_499[0][0]',            \n",
      " Lambda)                                                          'tf.__operators__.add_443[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_445 (Layer  (None, 10, 1)       2           ['tf.__operators__.add_444[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " conv1d_444 (Conv1D)            (None, 10, 4)        8           ['layer_normalization_445[0][0]']\n",
      "                                                                                                  \n",
      " dropout_500 (Dropout)          (None, 10, 4)        0           ['conv1d_444[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d_445 (Conv1D)            (None, 10, 1)        5           ['dropout_500[0][0]']            \n",
      "                                                                                                  \n",
      " tf.__operators__.add_445 (TFOp  (None, 10, 1)       0           ['conv1d_445[0][0]',             \n",
      " Lambda)                                                          'tf.__operators__.add_444[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_446 (Layer  (None, 10, 1)       2           ['tf.__operators__.add_445[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " multi_head_attention_223 (Mult  (None, 10, 1)       7169        ['layer_normalization_446[0][0]',\n",
      " iHeadAttention)                                                  'layer_normalization_446[0][0]']\n",
      "                                                                                                  \n",
      " dropout_501 (Dropout)          (None, 10, 1)        0           ['multi_head_attention_223[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " tf.__operators__.add_446 (TFOp  (None, 10, 1)       0           ['dropout_501[0][0]',            \n",
      " Lambda)                                                          'tf.__operators__.add_445[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_447 (Layer  (None, 10, 1)       2           ['tf.__operators__.add_446[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " conv1d_446 (Conv1D)            (None, 10, 4)        8           ['layer_normalization_447[0][0]']\n",
      "                                                                                                  \n",
      " dropout_502 (Dropout)          (None, 10, 4)        0           ['conv1d_446[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d_447 (Conv1D)            (None, 10, 1)        5           ['dropout_502[0][0]']            \n",
      "                                                                                                  \n",
      " tf.__operators__.add_447 (TFOp  (None, 10, 1)       0           ['conv1d_447[0][0]',             \n",
      " Lambda)                                                          'tf.__operators__.add_446[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " global_average_pooling1d_55 (G  (None, 10)          0           ['tf.__operators__.add_447[0][0]'\n",
      " lobalAveragePooling1D)                                          ]                                \n",
      "                                                                                                  \n",
      " dense_110 (Dense)              (None, 128)          1408        ['global_average_pooling1d_55[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      " dropout_503 (Dropout)          (None, 128)          0           ['dense_110[0][0]']              \n",
      "                                                                                                  \n",
      " dense_111 (Dense)              (None, 1)            129         ['dropout_503[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 30,281\n",
      "Trainable params: 30,281\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/10\n",
      "88/88 [==============================] - 14s 127ms/step - loss: 0.0011 - val_loss: 0.0014\n",
      "Epoch 2/10\n",
      "88/88 [==============================] - 11s 123ms/step - loss: 0.0011 - val_loss: 0.0014\n",
      "Epoch 3/10\n",
      "88/88 [==============================] - 11s 122ms/step - loss: 0.0010 - val_loss: 0.0014\n",
      "Epoch 4/10\n",
      "88/88 [==============================] - 11s 124ms/step - loss: 9.9730e-04 - val_loss: 0.0014\n",
      "Epoch 5/10\n",
      "88/88 [==============================] - 11s 122ms/step - loss: 0.0010 - val_loss: 0.0014\n",
      "Epoch 6/10\n",
      "88/88 [==============================] - 11s 123ms/step - loss: 9.7657e-04 - val_loss: 0.0014\n",
      "Epoch 7/10\n",
      "88/88 [==============================] - 11s 122ms/step - loss: 9.9945e-04 - val_loss: 0.0014\n",
      "Epoch 8/10\n",
      "88/88 [==============================] - 11s 122ms/step - loss: 9.9798e-04 - val_loss: 0.0014\n",
      "Epoch 9/10\n",
      "88/88 [==============================] - 11s 123ms/step - loss: 9.6523e-04 - val_loss: 0.0014\n",
      "Epoch 10/10\n",
      "88/88 [==============================] - 11s 123ms/step - loss: 9.4358e-04 - val_loss: 0.0014\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 9.2217e-04\n",
      "2/2 [==============================] - 0s 11ms/step\n",
      "Score (RMSE): 0.030367302423589572\n",
      "time to execute =  0:24:52.194653\n",
      "Iteration x =  7650  to row-stepsize  7797\n",
      "Model: \"model_56\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_57 (InputLayer)          [(None, 10, 1)]      0           []                               \n",
      "                                                                                                  \n",
      " layer_normalization_448 (Layer  (None, 10, 1)       2           ['input_57[0][0]']               \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " multi_head_attention_224 (Mult  (None, 10, 1)       7169        ['layer_normalization_448[0][0]',\n",
      " iHeadAttention)                                                  'layer_normalization_448[0][0]']\n",
      "                                                                                                  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " dropout_504 (Dropout)          (None, 10, 1)        0           ['multi_head_attention_224[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " tf.__operators__.add_448 (TFOp  (None, 10, 1)       0           ['dropout_504[0][0]',            \n",
      " Lambda)                                                          'input_57[0][0]']               \n",
      "                                                                                                  \n",
      " layer_normalization_449 (Layer  (None, 10, 1)       2           ['tf.__operators__.add_448[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " conv1d_448 (Conv1D)            (None, 10, 4)        8           ['layer_normalization_449[0][0]']\n",
      "                                                                                                  \n",
      " dropout_505 (Dropout)          (None, 10, 4)        0           ['conv1d_448[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d_449 (Conv1D)            (None, 10, 1)        5           ['dropout_505[0][0]']            \n",
      "                                                                                                  \n",
      " tf.__operators__.add_449 (TFOp  (None, 10, 1)       0           ['conv1d_449[0][0]',             \n",
      " Lambda)                                                          'tf.__operators__.add_448[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_450 (Layer  (None, 10, 1)       2           ['tf.__operators__.add_449[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " multi_head_attention_225 (Mult  (None, 10, 1)       7169        ['layer_normalization_450[0][0]',\n",
      " iHeadAttention)                                                  'layer_normalization_450[0][0]']\n",
      "                                                                                                  \n",
      " dropout_506 (Dropout)          (None, 10, 1)        0           ['multi_head_attention_225[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " tf.__operators__.add_450 (TFOp  (None, 10, 1)       0           ['dropout_506[0][0]',            \n",
      " Lambda)                                                          'tf.__operators__.add_449[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_451 (Layer  (None, 10, 1)       2           ['tf.__operators__.add_450[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " conv1d_450 (Conv1D)            (None, 10, 4)        8           ['layer_normalization_451[0][0]']\n",
      "                                                                                                  \n",
      " dropout_507 (Dropout)          (None, 10, 4)        0           ['conv1d_450[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d_451 (Conv1D)            (None, 10, 1)        5           ['dropout_507[0][0]']            \n",
      "                                                                                                  \n",
      " tf.__operators__.add_451 (TFOp  (None, 10, 1)       0           ['conv1d_451[0][0]',             \n",
      " Lambda)                                                          'tf.__operators__.add_450[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_452 (Layer  (None, 10, 1)       2           ['tf.__operators__.add_451[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " multi_head_attention_226 (Mult  (None, 10, 1)       7169        ['layer_normalization_452[0][0]',\n",
      " iHeadAttention)                                                  'layer_normalization_452[0][0]']\n",
      "                                                                                                  \n",
      " dropout_508 (Dropout)          (None, 10, 1)        0           ['multi_head_attention_226[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " tf.__operators__.add_452 (TFOp  (None, 10, 1)       0           ['dropout_508[0][0]',            \n",
      " Lambda)                                                          'tf.__operators__.add_451[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_453 (Layer  (None, 10, 1)       2           ['tf.__operators__.add_452[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " conv1d_452 (Conv1D)            (None, 10, 4)        8           ['layer_normalization_453[0][0]']\n",
      "                                                                                                  \n",
      " dropout_509 (Dropout)          (None, 10, 4)        0           ['conv1d_452[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d_453 (Conv1D)            (None, 10, 1)        5           ['dropout_509[0][0]']            \n",
      "                                                                                                  \n",
      " tf.__operators__.add_453 (TFOp  (None, 10, 1)       0           ['conv1d_453[0][0]',             \n",
      " Lambda)                                                          'tf.__operators__.add_452[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_454 (Layer  (None, 10, 1)       2           ['tf.__operators__.add_453[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " multi_head_attention_227 (Mult  (None, 10, 1)       7169        ['layer_normalization_454[0][0]',\n",
      " iHeadAttention)                                                  'layer_normalization_454[0][0]']\n",
      "                                                                                                  \n",
      " dropout_510 (Dropout)          (None, 10, 1)        0           ['multi_head_attention_227[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " tf.__operators__.add_454 (TFOp  (None, 10, 1)       0           ['dropout_510[0][0]',            \n",
      " Lambda)                                                          'tf.__operators__.add_453[0][0]'\n",
      "                                                                 ]                                \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                                                  \n",
      " layer_normalization_455 (Layer  (None, 10, 1)       2           ['tf.__operators__.add_454[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " conv1d_454 (Conv1D)            (None, 10, 4)        8           ['layer_normalization_455[0][0]']\n",
      "                                                                                                  \n",
      " dropout_511 (Dropout)          (None, 10, 4)        0           ['conv1d_454[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d_455 (Conv1D)            (None, 10, 1)        5           ['dropout_511[0][0]']            \n",
      "                                                                                                  \n",
      " tf.__operators__.add_455 (TFOp  (None, 10, 1)       0           ['conv1d_455[0][0]',             \n",
      " Lambda)                                                          'tf.__operators__.add_454[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " global_average_pooling1d_56 (G  (None, 10)          0           ['tf.__operators__.add_455[0][0]'\n",
      " lobalAveragePooling1D)                                          ]                                \n",
      "                                                                                                  \n",
      " dense_112 (Dense)              (None, 128)          1408        ['global_average_pooling1d_56[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      " dropout_512 (Dropout)          (None, 128)          0           ['dense_112[0][0]']              \n",
      "                                                                                                  \n",
      " dense_113 (Dense)              (None, 1)            129         ['dropout_512[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 30,281\n",
      "Trainable params: 30,281\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/10\n",
      "88/88 [==============================] - 14s 129ms/step - loss: 0.0011 - val_loss: 0.0015\n",
      "Epoch 2/10\n",
      "88/88 [==============================] - 11s 125ms/step - loss: 0.0011 - val_loss: 0.0014\n",
      "Epoch 3/10\n",
      "88/88 [==============================] - 11s 125ms/step - loss: 0.0010 - val_loss: 0.0014\n",
      "Epoch 4/10\n",
      "88/88 [==============================] - 11s 124ms/step - loss: 0.0010 - val_loss: 0.0014\n",
      "Epoch 5/10\n",
      "88/88 [==============================] - 11s 123ms/step - loss: 0.0010 - val_loss: 0.0014\n",
      "Epoch 6/10\n",
      "88/88 [==============================] - 11s 124ms/step - loss: 0.0010 - val_loss: 0.0014\n",
      "Epoch 7/10\n",
      "88/88 [==============================] - 11s 124ms/step - loss: 0.0010 - val_loss: 0.0014\n",
      "Epoch 8/10\n",
      "88/88 [==============================] - 11s 124ms/step - loss: 9.9427e-04 - val_loss: 0.0014\n",
      "Epoch 9/10\n",
      "88/88 [==============================] - 11s 124ms/step - loss: 9.4241e-04 - val_loss: 0.0014\n",
      "Epoch 10/10\n",
      "88/88 [==============================] - 11s 124ms/step - loss: 9.6379e-04 - val_loss: 0.0014\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 6.5797e-04\n",
      "2/2 [==============================] - 0s 10ms/step\n",
      "Score (RMSE): 0.0256509729964244\n",
      "time to execute =  0:26:45.700168\n",
      "Iteration x =  7700  to row-stepsize  7797\n",
      "Model: \"model_57\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_58 (InputLayer)          [(None, 10, 1)]      0           []                               \n",
      "                                                                                                  \n",
      " layer_normalization_456 (Layer  (None, 10, 1)       2           ['input_58[0][0]']               \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " multi_head_attention_228 (Mult  (None, 10, 1)       7169        ['layer_normalization_456[0][0]',\n",
      " iHeadAttention)                                                  'layer_normalization_456[0][0]']\n",
      "                                                                                                  \n",
      " dropout_513 (Dropout)          (None, 10, 1)        0           ['multi_head_attention_228[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " tf.__operators__.add_456 (TFOp  (None, 10, 1)       0           ['dropout_513[0][0]',            \n",
      " Lambda)                                                          'input_58[0][0]']               \n",
      "                                                                                                  \n",
      " layer_normalization_457 (Layer  (None, 10, 1)       2           ['tf.__operators__.add_456[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " conv1d_456 (Conv1D)            (None, 10, 4)        8           ['layer_normalization_457[0][0]']\n",
      "                                                                                                  \n",
      " dropout_514 (Dropout)          (None, 10, 4)        0           ['conv1d_456[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d_457 (Conv1D)            (None, 10, 1)        5           ['dropout_514[0][0]']            \n",
      "                                                                                                  \n",
      " tf.__operators__.add_457 (TFOp  (None, 10, 1)       0           ['conv1d_457[0][0]',             \n",
      " Lambda)                                                          'tf.__operators__.add_456[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_458 (Layer  (None, 10, 1)       2           ['tf.__operators__.add_457[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " multi_head_attention_229 (Mult  (None, 10, 1)       7169        ['layer_normalization_458[0][0]',\n",
      " iHeadAttention)                                                  'layer_normalization_458[0][0]']\n",
      "                                                                                                  \n",
      " dropout_515 (Dropout)          (None, 10, 1)        0           ['multi_head_attention_229[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " tf.__operators__.add_458 (TFOp  (None, 10, 1)       0           ['dropout_515[0][0]',            \n",
      " Lambda)                                                          'tf.__operators__.add_457[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_459 (Layer  (None, 10, 1)       2           ['tf.__operators__.add_458[0][0]'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " conv1d_458 (Conv1D)            (None, 10, 4)        8           ['layer_normalization_459[0][0]']\n",
      "                                                                                                  \n",
      " dropout_516 (Dropout)          (None, 10, 4)        0           ['conv1d_458[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d_459 (Conv1D)            (None, 10, 1)        5           ['dropout_516[0][0]']            \n",
      "                                                                                                  \n",
      " tf.__operators__.add_459 (TFOp  (None, 10, 1)       0           ['conv1d_459[0][0]',             \n",
      " Lambda)                                                          'tf.__operators__.add_458[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_460 (Layer  (None, 10, 1)       2           ['tf.__operators__.add_459[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " multi_head_attention_230 (Mult  (None, 10, 1)       7169        ['layer_normalization_460[0][0]',\n",
      " iHeadAttention)                                                  'layer_normalization_460[0][0]']\n",
      "                                                                                                  \n",
      " dropout_517 (Dropout)          (None, 10, 1)        0           ['multi_head_attention_230[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " tf.__operators__.add_460 (TFOp  (None, 10, 1)       0           ['dropout_517[0][0]',            \n",
      " Lambda)                                                          'tf.__operators__.add_459[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_461 (Layer  (None, 10, 1)       2           ['tf.__operators__.add_460[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " conv1d_460 (Conv1D)            (None, 10, 4)        8           ['layer_normalization_461[0][0]']\n",
      "                                                                                                  \n",
      " dropout_518 (Dropout)          (None, 10, 4)        0           ['conv1d_460[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d_461 (Conv1D)            (None, 10, 1)        5           ['dropout_518[0][0]']            \n",
      "                                                                                                  \n",
      " tf.__operators__.add_461 (TFOp  (None, 10, 1)       0           ['conv1d_461[0][0]',             \n",
      " Lambda)                                                          'tf.__operators__.add_460[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_462 (Layer  (None, 10, 1)       2           ['tf.__operators__.add_461[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " multi_head_attention_231 (Mult  (None, 10, 1)       7169        ['layer_normalization_462[0][0]',\n",
      " iHeadAttention)                                                  'layer_normalization_462[0][0]']\n",
      "                                                                                                  \n",
      " dropout_519 (Dropout)          (None, 10, 1)        0           ['multi_head_attention_231[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " tf.__operators__.add_462 (TFOp  (None, 10, 1)       0           ['dropout_519[0][0]',            \n",
      " Lambda)                                                          'tf.__operators__.add_461[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_463 (Layer  (None, 10, 1)       2           ['tf.__operators__.add_462[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " conv1d_462 (Conv1D)            (None, 10, 4)        8           ['layer_normalization_463[0][0]']\n",
      "                                                                                                  \n",
      " dropout_520 (Dropout)          (None, 10, 4)        0           ['conv1d_462[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d_463 (Conv1D)            (None, 10, 1)        5           ['dropout_520[0][0]']            \n",
      "                                                                                                  \n",
      " tf.__operators__.add_463 (TFOp  (None, 10, 1)       0           ['conv1d_463[0][0]',             \n",
      " Lambda)                                                          'tf.__operators__.add_462[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " global_average_pooling1d_57 (G  (None, 10)          0           ['tf.__operators__.add_463[0][0]'\n",
      " lobalAveragePooling1D)                                          ]                                \n",
      "                                                                                                  \n",
      " dense_114 (Dense)              (None, 128)          1408        ['global_average_pooling1d_57[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      " dropout_521 (Dropout)          (None, 128)          0           ['dense_114[0][0]']              \n",
      "                                                                                                  \n",
      " dense_115 (Dense)              (None, 1)            129         ['dropout_521[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 30,281\n",
      "Trainable params: 30,281\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/10\n",
      "88/88 [==============================] - 14s 127ms/step - loss: 0.0012 - val_loss: 0.0014\n",
      "Epoch 2/10\n",
      "88/88 [==============================] - 11s 122ms/step - loss: 0.0011 - val_loss: 0.0014\n",
      "Epoch 3/10\n",
      "88/88 [==============================] - 11s 122ms/step - loss: 0.0010 - val_loss: 0.0014\n",
      "Epoch 4/10\n",
      "88/88 [==============================] - 11s 122ms/step - loss: 0.0010 - val_loss: 0.0014\n",
      "Epoch 5/10\n",
      "88/88 [==============================] - 11s 123ms/step - loss: 0.0010 - val_loss: 0.0014\n",
      "Epoch 6/10\n",
      "88/88 [==============================] - 11s 123ms/step - loss: 0.0011 - val_loss: 0.0014\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/10\n",
      "88/88 [==============================] - 11s 125ms/step - loss: 0.0010 - val_loss: 0.0014\n",
      "Epoch 8/10\n",
      "88/88 [==============================] - 11s 124ms/step - loss: 9.9602e-04 - val_loss: 0.0014\n",
      "Epoch 9/10\n",
      "88/88 [==============================] - 11s 124ms/step - loss: 9.7446e-04 - val_loss: 0.0014\n",
      "Epoch 10/10\n",
      "88/88 [==============================] - 11s 123ms/step - loss: 0.0010 - val_loss: 0.0014\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0012\n",
      "2/2 [==============================] - 0s 9ms/step\n",
      "Score (RMSE): 0.0342321417508105\n",
      "time to execute =  0:28:37.811167\n",
      "Iteration x =  7750  to row-stepsize  7797\n",
      "Model: \"model_58\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_59 (InputLayer)          [(None, 10, 1)]      0           []                               \n",
      "                                                                                                  \n",
      " layer_normalization_464 (Layer  (None, 10, 1)       2           ['input_59[0][0]']               \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " multi_head_attention_232 (Mult  (None, 10, 1)       7169        ['layer_normalization_464[0][0]',\n",
      " iHeadAttention)                                                  'layer_normalization_464[0][0]']\n",
      "                                                                                                  \n",
      " dropout_522 (Dropout)          (None, 10, 1)        0           ['multi_head_attention_232[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " tf.__operators__.add_464 (TFOp  (None, 10, 1)       0           ['dropout_522[0][0]',            \n",
      " Lambda)                                                          'input_59[0][0]']               \n",
      "                                                                                                  \n",
      " layer_normalization_465 (Layer  (None, 10, 1)       2           ['tf.__operators__.add_464[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " conv1d_464 (Conv1D)            (None, 10, 4)        8           ['layer_normalization_465[0][0]']\n",
      "                                                                                                  \n",
      " dropout_523 (Dropout)          (None, 10, 4)        0           ['conv1d_464[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d_465 (Conv1D)            (None, 10, 1)        5           ['dropout_523[0][0]']            \n",
      "                                                                                                  \n",
      " tf.__operators__.add_465 (TFOp  (None, 10, 1)       0           ['conv1d_465[0][0]',             \n",
      " Lambda)                                                          'tf.__operators__.add_464[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_466 (Layer  (None, 10, 1)       2           ['tf.__operators__.add_465[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " multi_head_attention_233 (Mult  (None, 10, 1)       7169        ['layer_normalization_466[0][0]',\n",
      " iHeadAttention)                                                  'layer_normalization_466[0][0]']\n",
      "                                                                                                  \n",
      " dropout_524 (Dropout)          (None, 10, 1)        0           ['multi_head_attention_233[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " tf.__operators__.add_466 (TFOp  (None, 10, 1)       0           ['dropout_524[0][0]',            \n",
      " Lambda)                                                          'tf.__operators__.add_465[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_467 (Layer  (None, 10, 1)       2           ['tf.__operators__.add_466[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " conv1d_466 (Conv1D)            (None, 10, 4)        8           ['layer_normalization_467[0][0]']\n",
      "                                                                                                  \n",
      " dropout_525 (Dropout)          (None, 10, 4)        0           ['conv1d_466[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d_467 (Conv1D)            (None, 10, 1)        5           ['dropout_525[0][0]']            \n",
      "                                                                                                  \n",
      " tf.__operators__.add_467 (TFOp  (None, 10, 1)       0           ['conv1d_467[0][0]',             \n",
      " Lambda)                                                          'tf.__operators__.add_466[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_468 (Layer  (None, 10, 1)       2           ['tf.__operators__.add_467[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " multi_head_attention_234 (Mult  (None, 10, 1)       7169        ['layer_normalization_468[0][0]',\n",
      " iHeadAttention)                                                  'layer_normalization_468[0][0]']\n",
      "                                                                                                  \n",
      " dropout_526 (Dropout)          (None, 10, 1)        0           ['multi_head_attention_234[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " tf.__operators__.add_468 (TFOp  (None, 10, 1)       0           ['dropout_526[0][0]',            \n",
      " Lambda)                                                          'tf.__operators__.add_467[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_469 (Layer  (None, 10, 1)       2           ['tf.__operators__.add_468[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " conv1d_468 (Conv1D)            (None, 10, 4)        8           ['layer_normalization_469[0][0]']\n",
      "                                                                                                  \n",
      " dropout_527 (Dropout)          (None, 10, 4)        0           ['conv1d_468[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d_469 (Conv1D)            (None, 10, 1)        5           ['dropout_527[0][0]']            \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                                                  \n",
      " tf.__operators__.add_469 (TFOp  (None, 10, 1)       0           ['conv1d_469[0][0]',             \n",
      " Lambda)                                                          'tf.__operators__.add_468[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_470 (Layer  (None, 10, 1)       2           ['tf.__operators__.add_469[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " multi_head_attention_235 (Mult  (None, 10, 1)       7169        ['layer_normalization_470[0][0]',\n",
      " iHeadAttention)                                                  'layer_normalization_470[0][0]']\n",
      "                                                                                                  \n",
      " dropout_528 (Dropout)          (None, 10, 1)        0           ['multi_head_attention_235[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " tf.__operators__.add_470 (TFOp  (None, 10, 1)       0           ['dropout_528[0][0]',            \n",
      " Lambda)                                                          'tf.__operators__.add_469[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_471 (Layer  (None, 10, 1)       2           ['tf.__operators__.add_470[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " conv1d_470 (Conv1D)            (None, 10, 4)        8           ['layer_normalization_471[0][0]']\n",
      "                                                                                                  \n",
      " dropout_529 (Dropout)          (None, 10, 4)        0           ['conv1d_470[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d_471 (Conv1D)            (None, 10, 1)        5           ['dropout_529[0][0]']            \n",
      "                                                                                                  \n",
      " tf.__operators__.add_471 (TFOp  (None, 10, 1)       0           ['conv1d_471[0][0]',             \n",
      " Lambda)                                                          'tf.__operators__.add_470[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " global_average_pooling1d_58 (G  (None, 10)          0           ['tf.__operators__.add_471[0][0]'\n",
      " lobalAveragePooling1D)                                          ]                                \n",
      "                                                                                                  \n",
      " dense_116 (Dense)              (None, 128)          1408        ['global_average_pooling1d_58[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      " dropout_530 (Dropout)          (None, 128)          0           ['dense_116[0][0]']              \n",
      "                                                                                                  \n",
      " dense_117 (Dense)              (None, 1)            129         ['dropout_530[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 30,281\n",
      "Trainable params: 30,281\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/10\n",
      "88/88 [==============================] - 14s 127ms/step - loss: 0.0012 - val_loss: 0.0014\n",
      "Epoch 2/10\n",
      "88/88 [==============================] - 11s 121ms/step - loss: 0.0011 - val_loss: 0.0014\n",
      "Epoch 3/10\n",
      "88/88 [==============================] - 11s 121ms/step - loss: 0.0010 - val_loss: 0.0014\n",
      "Epoch 4/10\n",
      "88/88 [==============================] - 11s 120ms/step - loss: 0.0010 - val_loss: 0.0014\n",
      "Epoch 5/10\n",
      "88/88 [==============================] - 11s 120ms/step - loss: 0.0011 - val_loss: 0.0014\n",
      "Epoch 6/10\n",
      "88/88 [==============================] - 11s 120ms/step - loss: 0.0010 - val_loss: 0.0014\n",
      "Epoch 7/10\n",
      "88/88 [==============================] - 10s 119ms/step - loss: 0.0010 - val_loss: 0.0014\n",
      "Epoch 8/10\n",
      "88/88 [==============================] - 11s 120ms/step - loss: 9.8803e-04 - val_loss: 0.0014\n",
      "Epoch 9/10\n",
      "88/88 [==============================] - 10s 119ms/step - loss: 0.0010 - val_loss: 0.0014\n",
      "Epoch 10/10\n",
      "88/88 [==============================] - 10s 119ms/step - loss: 0.0010 - val_loss: 0.0013\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 7.6222e-04\n",
      "2/2 [==============================] - 0s 9ms/step\n",
      "Score (RMSE): 0.02760829574829171\n",
      "time to execute =  0:30:27.461168\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n#dfpnl = pd.DataFrame(data = pnls, columns=[\\'cumpnl\\'])\\ndfpnl = pd.DataFrame(data = pnlsOnly, columns=[\\'cumpnl\\'])\\ndfpnl[\\'pnl\\'] = dfpnl[\\'cumpnl\\'] - dfpnl[\\'cumpnl\\'].shift(1)\\n\\ndfpnl[\\'cummax\\'] = dfpnl[\\'cumpnl\\'].cummax()\\nret = dfpnl[\\'pnl\\'].mean()*252\\nvol = dfpnl[\\'pnl\\'].std()*pow(252,0.5)\\ndfpnl[\\'dd\\'] = dfpnl[\\'cummax\\'] - df[\\'cumpnl\\']\\nmdd = dfpnl[\\'dd\\'].max()\\nprint(\"Return = \",ret)\\nprint(\"Vol    = \",vol)\\ninfo =0\\nif(vol>0):\\n    info = ret/vol\\nprint(\"Info  = \",info)\\ncalmar=0\\nif (mdd>0):\\n    calmar = ret/mdd\\nprint(\"MDD  = \",mdd)\\nprint(\"Calmar = \",calmar)\\ndf[\\'cumpnl\\'].plot()\\ndf[\\'cummax\\'].plot()\\n'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SEQUENCE_SIZE   = 10\n",
    "pnls    = []\n",
    "pnlsOnly = []\n",
    "row,col = df.shape\n",
    "start = datetime.datetime.now()\n",
    "\n",
    "for x in range(windowsize,row-stepsize,stepsize):\n",
    "    print(\"Iteration x = \",x,\" to row-stepsize \",row-stepsize)\n",
    "    df_train = df.iloc[x-windowsize:x,:]\n",
    "    df_test  = df.iloc[x:x+stepsize]\n",
    "    df = df.loc[:,input_fields]\n",
    "    spots_train = df_train[target_col].tolist()\n",
    "    spots_test = df_test[target_col].tolist()\n",
    "    #spots_train = df.apply(lambda x: x.tolist(), axis=1).tolist()\n",
    "    #spots_test = df.apply(lambda x: x.tolist(), axis=1).tolist()\n",
    "\n",
    "#    print(\"Training set has {} observations.\".format(len(spots_train)))\n",
    "#    print(\"Test set has {} observations.\".format(len(spots_test)))\n",
    "    x_train,y_train = to_sequences(SEQUENCE_SIZE,spots_train)\n",
    "    x_test,y_test   = to_sequences(SEQUENCE_SIZE,spots_test)\n",
    "\n",
    "#    print(\"Shape of training set: {}\".format(x_train.shape))\n",
    "#    print(\"Shape of test set: {}\".format(x_test.shape))\n",
    "\n",
    "    input_shape = x_train.shape[1:]\n",
    "#    print(input_shape)\n",
    "    \n",
    "    model = build_model(\n",
    "        \n",
    "        input_shape,\n",
    "        head_size=256,\n",
    "        num_heads=4,\n",
    "        ff_dim=4,\n",
    "        num_transformer_blocks=4,\n",
    "        mlp_units=[128],\n",
    "        mlp_dropout=0.4,\n",
    "        dropout=0.25,\n",
    "    )\n",
    "\n",
    "    model.compile(\n",
    "        loss=\"mean_squared_error\",\n",
    "        optimizer=keras.optimizers.Adam(learning_rate=1e-4)\n",
    "    )\n",
    "\n",
    "    model.summary()\n",
    "\n",
    "    callbacks = [keras.callbacks.EarlyStopping(patience=10, \\\n",
    "        restore_best_weights=True)]\n",
    "\n",
    "    model.fit(\n",
    "        x_train,\n",
    "        y_train,\n",
    "        validation_split=0.2,\n",
    "        epochs=10, #200,\n",
    "        batch_size=64,\n",
    "        callbacks=callbacks,\n",
    "    )\n",
    "    finish = datetime.datetime.now()\n",
    "    \n",
    "    model.evaluate(x_test, y_test, verbose=1)\n",
    "\n",
    "\n",
    "\n",
    "    pred = model.predict(x_test)\n",
    "    score = np.sqrt(metrics.mean_squared_error(pred,y_test))\n",
    "    print(\"Score (RMSE): {}\".format(score)) \n",
    "\n",
    "    total   = 0\n",
    "    counter = 0\n",
    "\n",
    "    for x in range(len(pred)):\n",
    "        if pred[x] > 0.0:\n",
    "            total = y_test[x]\n",
    "        elif pred[x] < 0.0:\n",
    "            total = -1*y_test[x]\n",
    "            \n",
    "        pnls.append([x,pred[x],y_test[x],total])\n",
    "        pnlsOnly.append (total)\n",
    "\n",
    "    print(\"time to execute = \",finish-start)\n",
    "\"\"\"\n",
    "#dfpnl = pd.DataFrame(data = pnls, columns=['cumpnl'])\n",
    "dfpnl = pd.DataFrame(data = pnlsOnly, columns=['cumpnl'])\n",
    "dfpnl['pnl'] = dfpnl['cumpnl'] - dfpnl['cumpnl'].shift(1)\n",
    "\n",
    "dfpnl['cummax'] = dfpnl['cumpnl'].cummax()\n",
    "ret = dfpnl['pnl'].mean()*252\n",
    "vol = dfpnl['pnl'].std()*pow(252,0.5)\n",
    "dfpnl['dd'] = dfpnl['cummax'] - df['cumpnl']\n",
    "mdd = dfpnl['dd'].max()\n",
    "print(\"Return = \",ret)\n",
    "print(\"Vol    = \",vol)\n",
    "info =0\n",
    "if(vol>0):\n",
    "    info = ret/vol\n",
    "print(\"Info  = \",info)\n",
    "calmar=0\n",
    "if (mdd>0):\n",
    "    calmar = ret/mdd\n",
    "print(\"MDD  = \",mdd)\n",
    "print(\"Calmar = \",calmar)\n",
    "df['cumpnl'].plot()\n",
    "df['cummax'].plot()\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "640\n",
      "[10, array([-0.00220942], dtype=float32), 0.0296875, -0.0296875]\n"
     ]
    }
   ],
   "source": [
    "print(len(pnls))\n",
    "print(pnls[10])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of PNL =  640\n",
      "periods =  32000\n",
      "days =  5333.333333333333\n",
      "days in each step =  8.333333333333334\n"
     ]
    }
   ],
   "source": [
    "print(\"length of PNL = \",len(pnls))\n",
    "x = len(pnls)\n",
    "periods = x*stepsize\n",
    "print(\"periods = \",periods)\n",
    "days = periods/periodsperday\n",
    "print(\"days = \",days)\n",
    "daysperstep = stepsize/periodsperday\n",
    "print(\"days in each step = \",daysperstep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   index      pred    actual       pnl\n",
      "0      0  0.002288 -0.005468 -0.005468\n",
      "1      1 -0.000890  0.023436 -0.023436\n",
      "2      2 -0.002429 -0.000781  0.000781\n",
      "3      3 -0.000301 -0.006250  0.006250\n",
      "4      4  0.000369 -0.050000 -0.050000\n",
      "     index      pred    actual       pnl  switch    cumpnl\n",
      "635     35 -0.003892 -0.011719  0.011719      -1  0.893726\n",
      "636     36  0.001324 -0.002344 -0.002344       1  0.891382\n",
      "637     37  0.002768 -0.018749 -0.018749       1  0.872633\n",
      "638     38  0.002367 -0.011719 -0.011719       1  0.860914\n",
      "639     39 -0.000583  0.002343 -0.002343      -1  0.858571\n",
      "Return =  0.17886901041666664\n",
      "Vol    =  0.38644137672571766\n",
      "Info  =  0.4628619531692164\n",
      "MDD  =  0.94765975\n",
      "Calmar =  0.188748134989026\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cols = ['index','pred','actual','pnl']\n",
    "dfpnl = pd.DataFrame(data = pnls, columns=cols)\n",
    "dfpnl['pred'] = dfpnl['pred'].apply(lambda x: x[0])\n",
    "print(dfpnl.head())\n",
    "\n",
    "dfpnl['switch'] = dfpnl['pred'].apply(lambda x  : 1 if x>0 else -1 )\n",
    "dfpnl['pnl'] = dfpnl['switch'] * dfpnl['actual']\n",
    "#dfpnl = dfpnl.assign(pnl = lambda r: r['actual'] if r['pred'] > 0   else -1* r['actual'])\n",
    "\n",
    "\n",
    "for index,row in dfpnl.iterrows():\n",
    "    row['pred2'] = row['pred']\n",
    "    wt = 1.0\n",
    "    if (row['pred']<0):\n",
    "        wt = -1.0\n",
    "    dfpnl.loc[index,'pnl'] = wt * dfpnl.loc[index,'actual']\n",
    "\n",
    "dfpnl['cumpnl'] = dfpnl['pnl'].cumsum()\n",
    "print(dfpnl.tail())\n",
    "dfpnl['cummax'] = dfpnl['cumpnl'].cummax()\n",
    "ret = dfpnl['pnl'].mean()*(252/1.89)\n",
    "vol = dfpnl['pnl'].std()*pow(252/1.89,0.5)\n",
    "dfpnl['dd'] = dfpnl['cummax'] - dfpnl['cumpnl']\n",
    "mdd = dfpnl['dd'].max()\n",
    "print(\"Return = \",ret)\n",
    "print(\"Vol    = \",vol)\n",
    "info =0\n",
    "if(vol>0):\n",
    "    info = ret/vol\n",
    "print(\"Info  = \",info)\n",
    "calmar=0\n",
    "if (mdd>0):\n",
    "    calmar = ret/mdd\n",
    "print(\"MDD  = \",mdd)\n",
    "print(\"Calmar = \",calmar)\n",
    "dfpnl['cumpnl'].plot()\n",
    "dfpnl['cummax'].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfpnl.to_csv(\"c://data//transformer_output_\" + ticker + \".csv\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_env",
   "language": "python",
   "name": "torch_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
