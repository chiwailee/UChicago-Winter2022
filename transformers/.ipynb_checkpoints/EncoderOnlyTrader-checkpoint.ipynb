{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: not using Google CoLab\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive', force_remount=True)\n",
    "    COLAB = True\n",
    "    print(\"Note: using Google CoLab\")\n",
    "    %tensorflow_version 2.x\n",
    "except:\n",
    "    print(\"Note: not using Google CoLab\")\n",
    "    COLAB = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from sklearn import metrics\n",
    "import datetime\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_sequences(seq_size, obs):\n",
    "    x = []\n",
    "    y = []\n",
    "\n",
    "    for i in range(len(obs)-SEQUENCE_SIZE):\n",
    "        #print(i)\n",
    "        window = obs[i:(i+SEQUENCE_SIZE)]\n",
    "        after_window = obs[i+SEQUENCE_SIZE]\n",
    "        window = [[x] for x in window]\n",
    "        #print(\"{} - {}\".format(window,after_window))\n",
    "        x.append(window)\n",
    "        y.append(after_window)\n",
    "        \n",
    "    return np.array(x),np.array(y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transformer_encoder(inputs, head_size, num_heads, ff_dim, dropout=0):\n",
    "    # Normalization and Attention\n",
    "    x = layers.LayerNormalization(epsilon=1e-6)(inputs)\n",
    "    x = layers.MultiHeadAttention(\n",
    "        key_dim=head_size, num_heads=num_heads, dropout=dropout\n",
    "    )(x, x)\n",
    "    x = layers.Dropout(dropout)(x)\n",
    "    res = x + inputs\n",
    "\n",
    "    # Feed Forward Part\n",
    "    x = layers.LayerNormalization(epsilon=1e-6)(res)\n",
    "    x = layers.Conv1D(filters=ff_dim, kernel_size=1, activation=\"relu\")(x)\n",
    "    x = layers.Dropout(dropout)(x)\n",
    "    x = layers.Conv1D(filters=inputs.shape[-1], kernel_size=1)(x)\n",
    "    return x + res\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(\n",
    "    input_shape,\n",
    "    head_size,\n",
    "    num_heads,\n",
    "    ff_dim,\n",
    "    num_transformer_blocks,\n",
    "    mlp_units,\n",
    "    dropout=0,\n",
    "    mlp_dropout=0,\n",
    "):\n",
    "    inputs = keras.Input(shape=input_shape)\n",
    "    x = inputs\n",
    "    for _ in range(num_transformer_blocks):\n",
    "        x = transformer_encoder(x, head_size, num_heads, ff_dim, dropout)\n",
    "\n",
    "    #x = layers.GlobalAveragePooling2D(data_format=\"channels_first\")(x)\n",
    "    x = layers.GlobalAveragePooling1D(data_format=\"channels_first\")(x)\n",
    "    for dim in mlp_units:\n",
    "        x = layers.Dense(dim, activation=\"relu\")(x)\n",
    "        x = layers.Dropout(mlp_dropout)(x)\n",
    "    outputs = layers.Dense(1)(x)\n",
    "    return keras.Model(inputs, outputs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_original = False\n",
    "if use_original:\n",
    "    names = ['year', 'month', 'day', 'dec_year', 'sn_value' , 'sn_error', 'obs_num', 'extra']\n",
    "    target_col = 'sn_value'\n",
    "    periods_per_day = 6\n",
    "\n",
    "    fn = \"https://data.heatonresearch.com/data/t81-558/SN_d_tot_V2.0.csv\"\n",
    "    df = pd.read_csv(fn,\n",
    "        sep=';',header=None,names=names,\n",
    "        na_values=['-1'], index_col=False)\n",
    "\n",
    "else:\n",
    "    names = ['date', 'year','close', 'target',]\n",
    "    target_col = 'target'\n",
    "    perdiods_per_day = 10\n",
    "    ticker = 'fvty'\n",
    "\n",
    "    #fn = \"c://data//transformer_data_heaton.csv\"\n",
    "    fn = \"c:/dev/github/UChicago/Winter2023/UChicago-Winter2023/transformers/transformer_data_\" + ticker + \".csv\"\n",
    "    df = pd.read_csv(fn, sep=',', na_values=['-1'], index_col=False)\n",
    "\n",
    "\n",
    "\n",
    "# Find the last zero and move one beyond\n",
    "#start_id = max(df[df['obs_num'] == 0].index.tolist())+1  \n",
    "#print(start_id)\n",
    "#df = df[start_id:] # Trim the rows that have missing observatio\n",
    "\n",
    "#df['sn_value'] = df['sn_value'].astype(float)\n",
    "\n",
    "#wrap a loop starting here and grab train and test data from the original df..\n",
    "\n",
    "windowsize = 7000\n",
    "stepsize   = 50\n",
    "periodsperday = 6\n",
    "perdiods_per_day = periodsperday\n",
    "input_fields = [target_col,'obs_num','sn_error']\n",
    "target_field = [target_col]\n",
    "input_fields = target_field\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration x =  7000  to row-stepsize  7797\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 10, 1)]      0           []                               \n",
      "                                                                                                  \n",
      " layer_normalization (LayerNorm  (None, 10, 1)       2           ['input_1[0][0]']                \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " multi_head_attention (MultiHea  (None, 10, 1)       7169        ['layer_normalization[0][0]',    \n",
      " dAttention)                                                      'layer_normalization[0][0]']    \n",
      "                                                                                                  \n",
      " dropout (Dropout)              (None, 10, 1)        0           ['multi_head_attention[0][0]']   \n",
      "                                                                                                  \n",
      " tf.__operators__.add (TFOpLamb  (None, 10, 1)       0           ['dropout[0][0]',                \n",
      " da)                                                              'input_1[0][0]']                \n",
      "                                                                                                  \n",
      " layer_normalization_1 (LayerNo  (None, 10, 1)       2           ['tf.__operators__.add[0][0]']   \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv1d (Conv1D)                (None, 10, 4)        8           ['layer_normalization_1[0][0]']  \n",
      "                                                                                                  \n",
      " dropout_1 (Dropout)            (None, 10, 4)        0           ['conv1d[0][0]']                 \n",
      "                                                                                                  \n",
      " conv1d_1 (Conv1D)              (None, 10, 1)        5           ['dropout_1[0][0]']              \n",
      "                                                                                                  \n",
      " tf.__operators__.add_1 (TFOpLa  (None, 10, 1)       0           ['conv1d_1[0][0]',               \n",
      " mbda)                                                            'tf.__operators__.add[0][0]']   \n",
      "                                                                                                  \n",
      " layer_normalization_2 (LayerNo  (None, 10, 1)       2           ['tf.__operators__.add_1[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " multi_head_attention_1 (MultiH  (None, 10, 1)       7169        ['layer_normalization_2[0][0]',  \n",
      " eadAttention)                                                    'layer_normalization_2[0][0]']  \n",
      "                                                                                                  \n",
      " dropout_2 (Dropout)            (None, 10, 1)        0           ['multi_head_attention_1[0][0]'] \n",
      "                                                                                                  \n",
      " tf.__operators__.add_2 (TFOpLa  (None, 10, 1)       0           ['dropout_2[0][0]',              \n",
      " mbda)                                                            'tf.__operators__.add_1[0][0]'] \n",
      "                                                                                                  \n",
      " layer_normalization_3 (LayerNo  (None, 10, 1)       2           ['tf.__operators__.add_2[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv1d_2 (Conv1D)              (None, 10, 4)        8           ['layer_normalization_3[0][0]']  \n",
      "                                                                                                  \n",
      " dropout_3 (Dropout)            (None, 10, 4)        0           ['conv1d_2[0][0]']               \n",
      "                                                                                                  \n",
      " conv1d_3 (Conv1D)              (None, 10, 1)        5           ['dropout_3[0][0]']              \n",
      "                                                                                                  \n",
      " tf.__operators__.add_3 (TFOpLa  (None, 10, 1)       0           ['conv1d_3[0][0]',               \n",
      " mbda)                                                            'tf.__operators__.add_2[0][0]'] \n",
      "                                                                                                  \n",
      " layer_normalization_4 (LayerNo  (None, 10, 1)       2           ['tf.__operators__.add_3[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " multi_head_attention_2 (MultiH  (None, 10, 1)       7169        ['layer_normalization_4[0][0]',  \n",
      " eadAttention)                                                    'layer_normalization_4[0][0]']  \n",
      "                                                                                                  \n",
      " dropout_4 (Dropout)            (None, 10, 1)        0           ['multi_head_attention_2[0][0]'] \n",
      "                                                                                                  \n",
      " tf.__operators__.add_4 (TFOpLa  (None, 10, 1)       0           ['dropout_4[0][0]',              \n",
      " mbda)                                                            'tf.__operators__.add_3[0][0]'] \n",
      "                                                                                                  \n",
      " layer_normalization_5 (LayerNo  (None, 10, 1)       2           ['tf.__operators__.add_4[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv1d_4 (Conv1D)              (None, 10, 4)        8           ['layer_normalization_5[0][0]']  \n",
      "                                                                                                  \n",
      " dropout_5 (Dropout)            (None, 10, 4)        0           ['conv1d_4[0][0]']               \n",
      "                                                                                                  \n",
      " conv1d_5 (Conv1D)              (None, 10, 1)        5           ['dropout_5[0][0]']              \n",
      "                                                                                                  \n",
      " tf.__operators__.add_5 (TFOpLa  (None, 10, 1)       0           ['conv1d_5[0][0]',               \n",
      " mbda)                                                            'tf.__operators__.add_4[0][0]'] \n",
      "                                                                                                  \n",
      " layer_normalization_6 (LayerNo  (None, 10, 1)       2           ['tf.__operators__.add_5[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " multi_head_attention_3 (MultiH  (None, 10, 1)       7169        ['layer_normalization_6[0][0]',  \n",
      " eadAttention)                                                    'layer_normalization_6[0][0]']  \n",
      "                                                                                                  \n",
      " dropout_6 (Dropout)            (None, 10, 1)        0           ['multi_head_attention_3[0][0]'] \n",
      "                                                                                                  \n",
      " tf.__operators__.add_6 (TFOpLa  (None, 10, 1)       0           ['dropout_6[0][0]',              \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " mbda)                                                            'tf.__operators__.add_5[0][0]'] \n",
      "                                                                                                  \n",
      " layer_normalization_7 (LayerNo  (None, 10, 1)       2           ['tf.__operators__.add_6[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv1d_6 (Conv1D)              (None, 10, 4)        8           ['layer_normalization_7[0][0]']  \n",
      "                                                                                                  \n",
      " dropout_7 (Dropout)            (None, 10, 4)        0           ['conv1d_6[0][0]']               \n",
      "                                                                                                  \n",
      " conv1d_7 (Conv1D)              (None, 10, 1)        5           ['dropout_7[0][0]']              \n",
      "                                                                                                  \n",
      " tf.__operators__.add_7 (TFOpLa  (None, 10, 1)       0           ['conv1d_7[0][0]',               \n",
      " mbda)                                                            'tf.__operators__.add_6[0][0]'] \n",
      "                                                                                                  \n",
      " global_average_pooling1d (Glob  (None, 10)          0           ['tf.__operators__.add_7[0][0]'] \n",
      " alAveragePooling1D)                                                                              \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 128)          1408        ['global_average_pooling1d[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " dropout_8 (Dropout)            (None, 128)          0           ['dense[0][0]']                  \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 1)            129         ['dropout_8[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 30,281\n",
      "Trainable params: 30,281\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/10\n",
      "88/88 [==============================] - 15s 136ms/step - loss: 0.0011 - val_loss: 0.0013\n",
      "Epoch 2/10\n",
      "88/88 [==============================] - 12s 132ms/step - loss: 0.0010 - val_loss: 0.0013\n",
      "Epoch 3/10\n",
      "88/88 [==============================] - 11s 131ms/step - loss: 0.0010 - val_loss: 0.0012\n",
      "Epoch 4/10\n",
      "88/88 [==============================] - 12s 131ms/step - loss: 9.5574e-04 - val_loss: 0.0013\n",
      "Epoch 5/10\n",
      "88/88 [==============================] - 12s 132ms/step - loss: 9.7574e-04 - val_loss: 0.0012\n",
      "Epoch 6/10\n",
      "88/88 [==============================] - 11s 130ms/step - loss: 9.5843e-04 - val_loss: 0.0013\n",
      "Epoch 7/10\n",
      "88/88 [==============================] - 12s 134ms/step - loss: 9.3936e-04 - val_loss: 0.0012\n",
      "Epoch 8/10\n",
      "88/88 [==============================] - 12s 132ms/step - loss: 9.3859e-04 - val_loss: 0.0012\n",
      "Epoch 9/10\n",
      "88/88 [==============================] - 12s 132ms/step - loss: 9.6216e-04 - val_loss: 0.0012\n",
      "Epoch 10/10\n",
      "88/88 [==============================] - 12s 131ms/step - loss: 9.2401e-04 - val_loss: 0.0012\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 7.1519e-04\n",
      "2/2 [==============================] - 0s 10ms/step\n",
      "Score (RMSE): 0.02674303485747416\n",
      "time to execute =  0:02:00.309148\n",
      "Iteration x =  7050  to row-stepsize  7797\n",
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_2 (InputLayer)           [(None, 10, 1)]      0           []                               \n",
      "                                                                                                  \n",
      " layer_normalization_8 (LayerNo  (None, 10, 1)       2           ['input_2[0][0]']                \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " multi_head_attention_4 (MultiH  (None, 10, 1)       7169        ['layer_normalization_8[0][0]',  \n",
      " eadAttention)                                                    'layer_normalization_8[0][0]']  \n",
      "                                                                                                  \n",
      " dropout_9 (Dropout)            (None, 10, 1)        0           ['multi_head_attention_4[0][0]'] \n",
      "                                                                                                  \n",
      " tf.__operators__.add_8 (TFOpLa  (None, 10, 1)       0           ['dropout_9[0][0]',              \n",
      " mbda)                                                            'input_2[0][0]']                \n",
      "                                                                                                  \n",
      " layer_normalization_9 (LayerNo  (None, 10, 1)       2           ['tf.__operators__.add_8[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv1d_8 (Conv1D)              (None, 10, 4)        8           ['layer_normalization_9[0][0]']  \n",
      "                                                                                                  \n",
      " dropout_10 (Dropout)           (None, 10, 4)        0           ['conv1d_8[0][0]']               \n",
      "                                                                                                  \n",
      " conv1d_9 (Conv1D)              (None, 10, 1)        5           ['dropout_10[0][0]']             \n",
      "                                                                                                  \n",
      " tf.__operators__.add_9 (TFOpLa  (None, 10, 1)       0           ['conv1d_9[0][0]',               \n",
      " mbda)                                                            'tf.__operators__.add_8[0][0]'] \n",
      "                                                                                                  \n",
      " layer_normalization_10 (LayerN  (None, 10, 1)       2           ['tf.__operators__.add_9[0][0]'] \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " multi_head_attention_5 (MultiH  (None, 10, 1)       7169        ['layer_normalization_10[0][0]', \n",
      " eadAttention)                                                    'layer_normalization_10[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_11 (Dropout)           (None, 10, 1)        0           ['multi_head_attention_5[0][0]'] \n",
      "                                                                                                  \n",
      " tf.__operators__.add_10 (TFOpL  (None, 10, 1)       0           ['dropout_11[0][0]',             \n",
      " ambda)                                                           'tf.__operators__.add_9[0][0]'] \n",
      "                                                                                                  \n",
      " layer_normalization_11 (LayerN  (None, 10, 1)       2           ['tf.__operators__.add_10[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv1d_10 (Conv1D)             (None, 10, 4)        8           ['layer_normalization_11[0][0]'] \n",
      "                                                                                                  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " dropout_12 (Dropout)           (None, 10, 4)        0           ['conv1d_10[0][0]']              \n",
      "                                                                                                  \n",
      " conv1d_11 (Conv1D)             (None, 10, 1)        5           ['dropout_12[0][0]']             \n",
      "                                                                                                  \n",
      " tf.__operators__.add_11 (TFOpL  (None, 10, 1)       0           ['conv1d_11[0][0]',              \n",
      " ambda)                                                           'tf.__operators__.add_10[0][0]']\n",
      "                                                                                                  \n",
      " layer_normalization_12 (LayerN  (None, 10, 1)       2           ['tf.__operators__.add_11[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " multi_head_attention_6 (MultiH  (None, 10, 1)       7169        ['layer_normalization_12[0][0]', \n",
      " eadAttention)                                                    'layer_normalization_12[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_13 (Dropout)           (None, 10, 1)        0           ['multi_head_attention_6[0][0]'] \n",
      "                                                                                                  \n",
      " tf.__operators__.add_12 (TFOpL  (None, 10, 1)       0           ['dropout_13[0][0]',             \n",
      " ambda)                                                           'tf.__operators__.add_11[0][0]']\n",
      "                                                                                                  \n",
      " layer_normalization_13 (LayerN  (None, 10, 1)       2           ['tf.__operators__.add_12[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv1d_12 (Conv1D)             (None, 10, 4)        8           ['layer_normalization_13[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_14 (Dropout)           (None, 10, 4)        0           ['conv1d_12[0][0]']              \n",
      "                                                                                                  \n",
      " conv1d_13 (Conv1D)             (None, 10, 1)        5           ['dropout_14[0][0]']             \n",
      "                                                                                                  \n",
      " tf.__operators__.add_13 (TFOpL  (None, 10, 1)       0           ['conv1d_13[0][0]',              \n",
      " ambda)                                                           'tf.__operators__.add_12[0][0]']\n",
      "                                                                                                  \n",
      " layer_normalization_14 (LayerN  (None, 10, 1)       2           ['tf.__operators__.add_13[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " multi_head_attention_7 (MultiH  (None, 10, 1)       7169        ['layer_normalization_14[0][0]', \n",
      " eadAttention)                                                    'layer_normalization_14[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_15 (Dropout)           (None, 10, 1)        0           ['multi_head_attention_7[0][0]'] \n",
      "                                                                                                  \n",
      " tf.__operators__.add_14 (TFOpL  (None, 10, 1)       0           ['dropout_15[0][0]',             \n",
      " ambda)                                                           'tf.__operators__.add_13[0][0]']\n",
      "                                                                                                  \n",
      " layer_normalization_15 (LayerN  (None, 10, 1)       2           ['tf.__operators__.add_14[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv1d_14 (Conv1D)             (None, 10, 4)        8           ['layer_normalization_15[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_16 (Dropout)           (None, 10, 4)        0           ['conv1d_14[0][0]']              \n",
      "                                                                                                  \n",
      " conv1d_15 (Conv1D)             (None, 10, 1)        5           ['dropout_16[0][0]']             \n",
      "                                                                                                  \n",
      " tf.__operators__.add_15 (TFOpL  (None, 10, 1)       0           ['conv1d_15[0][0]',              \n",
      " ambda)                                                           'tf.__operators__.add_14[0][0]']\n",
      "                                                                                                  \n",
      " global_average_pooling1d_1 (Gl  (None, 10)          0           ['tf.__operators__.add_15[0][0]']\n",
      " obalAveragePooling1D)                                                                            \n",
      "                                                                                                  \n",
      " dense_2 (Dense)                (None, 128)          1408        ['global_average_pooling1d_1[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " dropout_17 (Dropout)           (None, 128)          0           ['dense_2[0][0]']                \n",
      "                                                                                                  \n",
      " dense_3 (Dense)                (None, 1)            129         ['dropout_17[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 30,281\n",
      "Trainable params: 30,281\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/10\n",
      "88/88 [==============================] - 15s 135ms/step - loss: 0.0010 - val_loss: 0.0013\n",
      "Epoch 2/10\n",
      "88/88 [==============================] - 11s 129ms/step - loss: 9.9434e-04 - val_loss: 0.0013\n",
      "Epoch 3/10\n",
      "88/88 [==============================] - 12s 132ms/step - loss: 9.6585e-04 - val_loss: 0.0013\n",
      "Epoch 4/10\n",
      "88/88 [==============================] - 12s 133ms/step - loss: 9.6009e-04 - val_loss: 0.0013\n",
      "Epoch 5/10\n",
      "88/88 [==============================] - 12s 132ms/step - loss: 9.4403e-04 - val_loss: 0.0013\n",
      "Epoch 6/10\n",
      "88/88 [==============================] - 12s 132ms/step - loss: 9.4162e-04 - val_loss: 0.0013\n",
      "Epoch 7/10\n",
      "88/88 [==============================] - 12s 130ms/step - loss: 9.4880e-04 - val_loss: 0.0013\n",
      "Epoch 8/10\n",
      "88/88 [==============================] - 12s 131ms/step - loss: 9.0540e-04 - val_loss: 0.0013\n",
      "Epoch 9/10\n",
      "88/88 [==============================] - 12s 132ms/step - loss: 9.5243e-04 - val_loss: 0.0013\n",
      "Epoch 10/10\n",
      "88/88 [==============================] - 11s 130ms/step - loss: 9.1178e-04 - val_loss: 0.0013\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0017\n",
      "2/2 [==============================] - 0s 12ms/step\n",
      "Score (RMSE): 0.04128410298680051\n",
      "time to execute =  0:04:00.822001\n",
      "Iteration x =  7100  to row-stepsize  7797\n",
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_3 (InputLayer)           [(None, 10, 1)]      0           []                               \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                                                  \n",
      " layer_normalization_16 (LayerN  (None, 10, 1)       2           ['input_3[0][0]']                \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " multi_head_attention_8 (MultiH  (None, 10, 1)       7169        ['layer_normalization_16[0][0]', \n",
      " eadAttention)                                                    'layer_normalization_16[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_18 (Dropout)           (None, 10, 1)        0           ['multi_head_attention_8[0][0]'] \n",
      "                                                                                                  \n",
      " tf.__operators__.add_16 (TFOpL  (None, 10, 1)       0           ['dropout_18[0][0]',             \n",
      " ambda)                                                           'input_3[0][0]']                \n",
      "                                                                                                  \n",
      " layer_normalization_17 (LayerN  (None, 10, 1)       2           ['tf.__operators__.add_16[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv1d_16 (Conv1D)             (None, 10, 4)        8           ['layer_normalization_17[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_19 (Dropout)           (None, 10, 4)        0           ['conv1d_16[0][0]']              \n",
      "                                                                                                  \n",
      " conv1d_17 (Conv1D)             (None, 10, 1)        5           ['dropout_19[0][0]']             \n",
      "                                                                                                  \n",
      " tf.__operators__.add_17 (TFOpL  (None, 10, 1)       0           ['conv1d_17[0][0]',              \n",
      " ambda)                                                           'tf.__operators__.add_16[0][0]']\n",
      "                                                                                                  \n",
      " layer_normalization_18 (LayerN  (None, 10, 1)       2           ['tf.__operators__.add_17[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " multi_head_attention_9 (MultiH  (None, 10, 1)       7169        ['layer_normalization_18[0][0]', \n",
      " eadAttention)                                                    'layer_normalization_18[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_20 (Dropout)           (None, 10, 1)        0           ['multi_head_attention_9[0][0]'] \n",
      "                                                                                                  \n",
      " tf.__operators__.add_18 (TFOpL  (None, 10, 1)       0           ['dropout_20[0][0]',             \n",
      " ambda)                                                           'tf.__operators__.add_17[0][0]']\n",
      "                                                                                                  \n",
      " layer_normalization_19 (LayerN  (None, 10, 1)       2           ['tf.__operators__.add_18[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv1d_18 (Conv1D)             (None, 10, 4)        8           ['layer_normalization_19[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_21 (Dropout)           (None, 10, 4)        0           ['conv1d_18[0][0]']              \n",
      "                                                                                                  \n",
      " conv1d_19 (Conv1D)             (None, 10, 1)        5           ['dropout_21[0][0]']             \n",
      "                                                                                                  \n",
      " tf.__operators__.add_19 (TFOpL  (None, 10, 1)       0           ['conv1d_19[0][0]',              \n",
      " ambda)                                                           'tf.__operators__.add_18[0][0]']\n",
      "                                                                                                  \n",
      " layer_normalization_20 (LayerN  (None, 10, 1)       2           ['tf.__operators__.add_19[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " multi_head_attention_10 (Multi  (None, 10, 1)       7169        ['layer_normalization_20[0][0]', \n",
      " HeadAttention)                                                   'layer_normalization_20[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_22 (Dropout)           (None, 10, 1)        0           ['multi_head_attention_10[0][0]']\n",
      "                                                                                                  \n",
      " tf.__operators__.add_20 (TFOpL  (None, 10, 1)       0           ['dropout_22[0][0]',             \n",
      " ambda)                                                           'tf.__operators__.add_19[0][0]']\n",
      "                                                                                                  \n",
      " layer_normalization_21 (LayerN  (None, 10, 1)       2           ['tf.__operators__.add_20[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv1d_20 (Conv1D)             (None, 10, 4)        8           ['layer_normalization_21[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_23 (Dropout)           (None, 10, 4)        0           ['conv1d_20[0][0]']              \n",
      "                                                                                                  \n",
      " conv1d_21 (Conv1D)             (None, 10, 1)        5           ['dropout_23[0][0]']             \n",
      "                                                                                                  \n",
      " tf.__operators__.add_21 (TFOpL  (None, 10, 1)       0           ['conv1d_21[0][0]',              \n",
      " ambda)                                                           'tf.__operators__.add_20[0][0]']\n",
      "                                                                                                  \n",
      " layer_normalization_22 (LayerN  (None, 10, 1)       2           ['tf.__operators__.add_21[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " multi_head_attention_11 (Multi  (None, 10, 1)       7169        ['layer_normalization_22[0][0]', \n",
      " HeadAttention)                                                   'layer_normalization_22[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_24 (Dropout)           (None, 10, 1)        0           ['multi_head_attention_11[0][0]']\n",
      "                                                                                                  \n",
      " tf.__operators__.add_22 (TFOpL  (None, 10, 1)       0           ['dropout_24[0][0]',             \n",
      " ambda)                                                           'tf.__operators__.add_21[0][0]']\n",
      "                                                                                                  \n",
      " layer_normalization_23 (LayerN  (None, 10, 1)       2           ['tf.__operators__.add_22[0][0]']\n",
      " ormalization)                                                                                    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                                                  \n",
      " conv1d_22 (Conv1D)             (None, 10, 4)        8           ['layer_normalization_23[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_25 (Dropout)           (None, 10, 4)        0           ['conv1d_22[0][0]']              \n",
      "                                                                                                  \n",
      " conv1d_23 (Conv1D)             (None, 10, 1)        5           ['dropout_25[0][0]']             \n",
      "                                                                                                  \n",
      " tf.__operators__.add_23 (TFOpL  (None, 10, 1)       0           ['conv1d_23[0][0]',              \n",
      " ambda)                                                           'tf.__operators__.add_22[0][0]']\n",
      "                                                                                                  \n",
      " global_average_pooling1d_2 (Gl  (None, 10)          0           ['tf.__operators__.add_23[0][0]']\n",
      " obalAveragePooling1D)                                                                            \n",
      "                                                                                                  \n",
      " dense_4 (Dense)                (None, 128)          1408        ['global_average_pooling1d_2[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " dropout_26 (Dropout)           (None, 128)          0           ['dense_4[0][0]']                \n",
      "                                                                                                  \n",
      " dense_5 (Dense)                (None, 1)            129         ['dropout_26[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 30,281\n",
      "Trainable params: 30,281\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/10\n",
      "88/88 [==============================] - 15s 132ms/step - loss: 0.0010 - val_loss: 0.0014\n",
      "Epoch 2/10\n",
      "88/88 [==============================] - 12s 132ms/step - loss: 0.0010 - val_loss: 0.0014\n",
      "Epoch 3/10\n",
      "88/88 [==============================] - 12s 132ms/step - loss: 9.9706e-04 - val_loss: 0.0013\n",
      "Epoch 4/10\n",
      "88/88 [==============================] - 11s 129ms/step - loss: 9.4699e-04 - val_loss: 0.0013\n",
      "Epoch 5/10\n",
      "88/88 [==============================] - 12s 131ms/step - loss: 9.6177e-04 - val_loss: 0.0013\n",
      "Epoch 6/10\n",
      "88/88 [==============================] - 11s 129ms/step - loss: 9.5202e-04 - val_loss: 0.0013\n",
      "Epoch 7/10\n",
      "88/88 [==============================] - 11s 129ms/step - loss: 9.3692e-04 - val_loss: 0.0013\n",
      "Epoch 8/10\n",
      "88/88 [==============================] - 12s 132ms/step - loss: 9.3093e-04 - val_loss: 0.0013\n",
      "Epoch 9/10\n",
      "88/88 [==============================] - 12s 131ms/step - loss: 9.2769e-04 - val_loss: 0.0013\n",
      "Epoch 10/10\n",
      "88/88 [==============================] - 12s 132ms/step - loss: 8.9673e-04 - val_loss: 0.0013\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0012\n",
      "2/2 [==============================] - 0s 10ms/step\n",
      "Score (RMSE): 0.03414787431106099\n",
      "time to execute =  0:06:00.737371\n",
      "Iteration x =  7150  to row-stepsize  7797\n",
      "Model: \"model_3\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_4 (InputLayer)           [(None, 10, 1)]      0           []                               \n",
      "                                                                                                  \n",
      " layer_normalization_24 (LayerN  (None, 10, 1)       2           ['input_4[0][0]']                \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " multi_head_attention_12 (Multi  (None, 10, 1)       7169        ['layer_normalization_24[0][0]', \n",
      " HeadAttention)                                                   'layer_normalization_24[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_27 (Dropout)           (None, 10, 1)        0           ['multi_head_attention_12[0][0]']\n",
      "                                                                                                  \n",
      " tf.__operators__.add_24 (TFOpL  (None, 10, 1)       0           ['dropout_27[0][0]',             \n",
      " ambda)                                                           'input_4[0][0]']                \n",
      "                                                                                                  \n",
      " layer_normalization_25 (LayerN  (None, 10, 1)       2           ['tf.__operators__.add_24[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv1d_24 (Conv1D)             (None, 10, 4)        8           ['layer_normalization_25[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_28 (Dropout)           (None, 10, 4)        0           ['conv1d_24[0][0]']              \n",
      "                                                                                                  \n",
      " conv1d_25 (Conv1D)             (None, 10, 1)        5           ['dropout_28[0][0]']             \n",
      "                                                                                                  \n",
      " tf.__operators__.add_25 (TFOpL  (None, 10, 1)       0           ['conv1d_25[0][0]',              \n",
      " ambda)                                                           'tf.__operators__.add_24[0][0]']\n",
      "                                                                                                  \n",
      " layer_normalization_26 (LayerN  (None, 10, 1)       2           ['tf.__operators__.add_25[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " multi_head_attention_13 (Multi  (None, 10, 1)       7169        ['layer_normalization_26[0][0]', \n",
      " HeadAttention)                                                   'layer_normalization_26[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_29 (Dropout)           (None, 10, 1)        0           ['multi_head_attention_13[0][0]']\n",
      "                                                                                                  \n",
      " tf.__operators__.add_26 (TFOpL  (None, 10, 1)       0           ['dropout_29[0][0]',             \n",
      " ambda)                                                           'tf.__operators__.add_25[0][0]']\n",
      "                                                                                                  \n",
      " layer_normalization_27 (LayerN  (None, 10, 1)       2           ['tf.__operators__.add_26[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv1d_26 (Conv1D)             (None, 10, 4)        8           ['layer_normalization_27[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_30 (Dropout)           (None, 10, 4)        0           ['conv1d_26[0][0]']              \n",
      "                                                                                                  \n",
      " conv1d_27 (Conv1D)             (None, 10, 1)        5           ['dropout_30[0][0]']             \n",
      "                                                                                                  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " tf.__operators__.add_27 (TFOpL  (None, 10, 1)       0           ['conv1d_27[0][0]',              \n",
      " ambda)                                                           'tf.__operators__.add_26[0][0]']\n",
      "                                                                                                  \n",
      " layer_normalization_28 (LayerN  (None, 10, 1)       2           ['tf.__operators__.add_27[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " multi_head_attention_14 (Multi  (None, 10, 1)       7169        ['layer_normalization_28[0][0]', \n",
      " HeadAttention)                                                   'layer_normalization_28[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_31 (Dropout)           (None, 10, 1)        0           ['multi_head_attention_14[0][0]']\n",
      "                                                                                                  \n",
      " tf.__operators__.add_28 (TFOpL  (None, 10, 1)       0           ['dropout_31[0][0]',             \n",
      " ambda)                                                           'tf.__operators__.add_27[0][0]']\n",
      "                                                                                                  \n",
      " layer_normalization_29 (LayerN  (None, 10, 1)       2           ['tf.__operators__.add_28[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv1d_28 (Conv1D)             (None, 10, 4)        8           ['layer_normalization_29[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_32 (Dropout)           (None, 10, 4)        0           ['conv1d_28[0][0]']              \n",
      "                                                                                                  \n",
      " conv1d_29 (Conv1D)             (None, 10, 1)        5           ['dropout_32[0][0]']             \n",
      "                                                                                                  \n",
      " tf.__operators__.add_29 (TFOpL  (None, 10, 1)       0           ['conv1d_29[0][0]',              \n",
      " ambda)                                                           'tf.__operators__.add_28[0][0]']\n",
      "                                                                                                  \n",
      " layer_normalization_30 (LayerN  (None, 10, 1)       2           ['tf.__operators__.add_29[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " multi_head_attention_15 (Multi  (None, 10, 1)       7169        ['layer_normalization_30[0][0]', \n",
      " HeadAttention)                                                   'layer_normalization_30[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_33 (Dropout)           (None, 10, 1)        0           ['multi_head_attention_15[0][0]']\n",
      "                                                                                                  \n",
      " tf.__operators__.add_30 (TFOpL  (None, 10, 1)       0           ['dropout_33[0][0]',             \n",
      " ambda)                                                           'tf.__operators__.add_29[0][0]']\n",
      "                                                                                                  \n",
      " layer_normalization_31 (LayerN  (None, 10, 1)       2           ['tf.__operators__.add_30[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv1d_30 (Conv1D)             (None, 10, 4)        8           ['layer_normalization_31[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_34 (Dropout)           (None, 10, 4)        0           ['conv1d_30[0][0]']              \n",
      "                                                                                                  \n",
      " conv1d_31 (Conv1D)             (None, 10, 1)        5           ['dropout_34[0][0]']             \n",
      "                                                                                                  \n",
      " tf.__operators__.add_31 (TFOpL  (None, 10, 1)       0           ['conv1d_31[0][0]',              \n",
      " ambda)                                                           'tf.__operators__.add_30[0][0]']\n",
      "                                                                                                  \n",
      " global_average_pooling1d_3 (Gl  (None, 10)          0           ['tf.__operators__.add_31[0][0]']\n",
      " obalAveragePooling1D)                                                                            \n",
      "                                                                                                  \n",
      " dense_6 (Dense)                (None, 128)          1408        ['global_average_pooling1d_3[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " dropout_35 (Dropout)           (None, 128)          0           ['dense_6[0][0]']                \n",
      "                                                                                                  \n",
      " dense_7 (Dense)                (None, 1)            129         ['dropout_35[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 30,281\n",
      "Trainable params: 30,281\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/10\n",
      "88/88 [==============================] - 16s 140ms/step - loss: 0.0012 - val_loss: 0.0015\n",
      "Epoch 2/10\n",
      "88/88 [==============================] - 12s 132ms/step - loss: 0.0010 - val_loss: 0.0014\n",
      "Epoch 3/10\n",
      "88/88 [==============================] - 12s 131ms/step - loss: 0.0010 - val_loss: 0.0014\n",
      "Epoch 4/10\n",
      "88/88 [==============================] - 12s 134ms/step - loss: 0.0010 - val_loss: 0.0014\n",
      "Epoch 5/10\n",
      "88/88 [==============================] - 12s 131ms/step - loss: 9.7143e-04 - val_loss: 0.0014\n",
      "Epoch 6/10\n",
      "88/88 [==============================] - 11s 130ms/step - loss: 9.7821e-04 - val_loss: 0.0014\n",
      "Epoch 7/10\n",
      "88/88 [==============================] - 11s 129ms/step - loss: 9.8317e-04 - val_loss: 0.0014\n",
      "Epoch 8/10\n",
      "88/88 [==============================] - 11s 129ms/step - loss: 9.3466e-04 - val_loss: 0.0014\n",
      "Epoch 9/10\n",
      "88/88 [==============================] - 11s 129ms/step - loss: 9.4997e-04 - val_loss: 0.0013\n",
      "Epoch 10/10\n",
      "88/88 [==============================] - 11s 129ms/step - loss: 9.3612e-04 - val_loss: 0.0013\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0011\n",
      "2/2 [==============================] - 0s 10ms/step\n",
      "Score (RMSE): 0.033277578565429705\n",
      "time to execute =  0:08:01.328813\n",
      "Iteration x =  7200  to row-stepsize  7797\n",
      "Model: \"model_4\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_5 (InputLayer)           [(None, 10, 1)]      0           []                               \n",
      "                                                                                                  \n",
      " layer_normalization_32 (LayerN  (None, 10, 1)       2           ['input_5[0][0]']                \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " multi_head_attention_16 (Multi  (None, 10, 1)       7169        ['layer_normalization_32[0][0]', \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " HeadAttention)                                                   'layer_normalization_32[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_36 (Dropout)           (None, 10, 1)        0           ['multi_head_attention_16[0][0]']\n",
      "                                                                                                  \n",
      " tf.__operators__.add_32 (TFOpL  (None, 10, 1)       0           ['dropout_36[0][0]',             \n",
      " ambda)                                                           'input_5[0][0]']                \n",
      "                                                                                                  \n",
      " layer_normalization_33 (LayerN  (None, 10, 1)       2           ['tf.__operators__.add_32[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv1d_32 (Conv1D)             (None, 10, 4)        8           ['layer_normalization_33[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_37 (Dropout)           (None, 10, 4)        0           ['conv1d_32[0][0]']              \n",
      "                                                                                                  \n",
      " conv1d_33 (Conv1D)             (None, 10, 1)        5           ['dropout_37[0][0]']             \n",
      "                                                                                                  \n",
      " tf.__operators__.add_33 (TFOpL  (None, 10, 1)       0           ['conv1d_33[0][0]',              \n",
      " ambda)                                                           'tf.__operators__.add_32[0][0]']\n",
      "                                                                                                  \n",
      " layer_normalization_34 (LayerN  (None, 10, 1)       2           ['tf.__operators__.add_33[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " multi_head_attention_17 (Multi  (None, 10, 1)       7169        ['layer_normalization_34[0][0]', \n",
      " HeadAttention)                                                   'layer_normalization_34[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_38 (Dropout)           (None, 10, 1)        0           ['multi_head_attention_17[0][0]']\n",
      "                                                                                                  \n",
      " tf.__operators__.add_34 (TFOpL  (None, 10, 1)       0           ['dropout_38[0][0]',             \n",
      " ambda)                                                           'tf.__operators__.add_33[0][0]']\n",
      "                                                                                                  \n",
      " layer_normalization_35 (LayerN  (None, 10, 1)       2           ['tf.__operators__.add_34[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv1d_34 (Conv1D)             (None, 10, 4)        8           ['layer_normalization_35[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_39 (Dropout)           (None, 10, 4)        0           ['conv1d_34[0][0]']              \n",
      "                                                                                                  \n",
      " conv1d_35 (Conv1D)             (None, 10, 1)        5           ['dropout_39[0][0]']             \n",
      "                                                                                                  \n",
      " tf.__operators__.add_35 (TFOpL  (None, 10, 1)       0           ['conv1d_35[0][0]',              \n",
      " ambda)                                                           'tf.__operators__.add_34[0][0]']\n",
      "                                                                                                  \n",
      " layer_normalization_36 (LayerN  (None, 10, 1)       2           ['tf.__operators__.add_35[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " multi_head_attention_18 (Multi  (None, 10, 1)       7169        ['layer_normalization_36[0][0]', \n",
      " HeadAttention)                                                   'layer_normalization_36[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_40 (Dropout)           (None, 10, 1)        0           ['multi_head_attention_18[0][0]']\n",
      "                                                                                                  \n",
      " tf.__operators__.add_36 (TFOpL  (None, 10, 1)       0           ['dropout_40[0][0]',             \n",
      " ambda)                                                           'tf.__operators__.add_35[0][0]']\n",
      "                                                                                                  \n",
      " layer_normalization_37 (LayerN  (None, 10, 1)       2           ['tf.__operators__.add_36[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv1d_36 (Conv1D)             (None, 10, 4)        8           ['layer_normalization_37[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_41 (Dropout)           (None, 10, 4)        0           ['conv1d_36[0][0]']              \n",
      "                                                                                                  \n",
      " conv1d_37 (Conv1D)             (None, 10, 1)        5           ['dropout_41[0][0]']             \n",
      "                                                                                                  \n",
      " tf.__operators__.add_37 (TFOpL  (None, 10, 1)       0           ['conv1d_37[0][0]',              \n",
      " ambda)                                                           'tf.__operators__.add_36[0][0]']\n",
      "                                                                                                  \n",
      " layer_normalization_38 (LayerN  (None, 10, 1)       2           ['tf.__operators__.add_37[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " multi_head_attention_19 (Multi  (None, 10, 1)       7169        ['layer_normalization_38[0][0]', \n",
      " HeadAttention)                                                   'layer_normalization_38[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_42 (Dropout)           (None, 10, 1)        0           ['multi_head_attention_19[0][0]']\n",
      "                                                                                                  \n",
      " tf.__operators__.add_38 (TFOpL  (None, 10, 1)       0           ['dropout_42[0][0]',             \n",
      " ambda)                                                           'tf.__operators__.add_37[0][0]']\n",
      "                                                                                                  \n",
      " layer_normalization_39 (LayerN  (None, 10, 1)       2           ['tf.__operators__.add_38[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv1d_38 (Conv1D)             (None, 10, 4)        8           ['layer_normalization_39[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_43 (Dropout)           (None, 10, 4)        0           ['conv1d_38[0][0]']              \n",
      "                                                                                                  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " conv1d_39 (Conv1D)             (None, 10, 1)        5           ['dropout_43[0][0]']             \n",
      "                                                                                                  \n",
      " tf.__operators__.add_39 (TFOpL  (None, 10, 1)       0           ['conv1d_39[0][0]',              \n",
      " ambda)                                                           'tf.__operators__.add_38[0][0]']\n",
      "                                                                                                  \n",
      " global_average_pooling1d_4 (Gl  (None, 10)          0           ['tf.__operators__.add_39[0][0]']\n",
      " obalAveragePooling1D)                                                                            \n",
      "                                                                                                  \n",
      " dense_8 (Dense)                (None, 128)          1408        ['global_average_pooling1d_4[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " dropout_44 (Dropout)           (None, 128)          0           ['dense_8[0][0]']                \n",
      "                                                                                                  \n",
      " dense_9 (Dense)                (None, 1)            129         ['dropout_44[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 30,281\n",
      "Trainable params: 30,281\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/10\n",
      "88/88 [==============================] - 16s 138ms/step - loss: 9.6242e-04 - val_loss: 0.0013\n",
      "Epoch 2/10\n",
      "88/88 [==============================] - 11s 130ms/step - loss: 0.0010 - val_loss: 0.0013\n",
      "Epoch 3/10\n",
      "88/88 [==============================] - 11s 130ms/step - loss: 0.0010 - val_loss: 0.0013\n",
      "Epoch 4/10\n",
      "88/88 [==============================] - 11s 129ms/step - loss: 9.7892e-04 - val_loss: 0.0013\n",
      "Epoch 5/10\n",
      "88/88 [==============================] - 11s 129ms/step - loss: 9.7219e-04 - val_loss: 0.0013\n",
      "Epoch 6/10\n",
      "88/88 [==============================] - 12s 133ms/step - loss: 9.2606e-04 - val_loss: 0.0013\n",
      "Epoch 7/10\n",
      "88/88 [==============================] - 11s 129ms/step - loss: 9.2421e-04 - val_loss: 0.0013\n",
      "Epoch 8/10\n",
      "88/88 [==============================] - 11s 129ms/step - loss: 9.6494e-04 - val_loss: 0.0013\n",
      "Epoch 9/10\n",
      "88/88 [==============================] - 11s 129ms/step - loss: 9.1108e-04 - val_loss: 0.0013\n",
      "Epoch 10/10\n",
      "88/88 [==============================] - 11s 130ms/step - loss: 9.1388e-04 - val_loss: 0.0013\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 7.7981e-04\n",
      "WARNING:tensorflow:5 out of the last 9 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000002A0D7FC05E0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "Score (RMSE): 0.027925063356904454\n",
      "time to execute =  0:10:01.150033\n",
      "Iteration x =  7250  to row-stepsize  7797\n",
      "Model: \"model_5\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_6 (InputLayer)           [(None, 10, 1)]      0           []                               \n",
      "                                                                                                  \n",
      " layer_normalization_40 (LayerN  (None, 10, 1)       2           ['input_6[0][0]']                \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " multi_head_attention_20 (Multi  (None, 10, 1)       7169        ['layer_normalization_40[0][0]', \n",
      " HeadAttention)                                                   'layer_normalization_40[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_45 (Dropout)           (None, 10, 1)        0           ['multi_head_attention_20[0][0]']\n",
      "                                                                                                  \n",
      " tf.__operators__.add_40 (TFOpL  (None, 10, 1)       0           ['dropout_45[0][0]',             \n",
      " ambda)                                                           'input_6[0][0]']                \n",
      "                                                                                                  \n",
      " layer_normalization_41 (LayerN  (None, 10, 1)       2           ['tf.__operators__.add_40[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv1d_40 (Conv1D)             (None, 10, 4)        8           ['layer_normalization_41[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_46 (Dropout)           (None, 10, 4)        0           ['conv1d_40[0][0]']              \n",
      "                                                                                                  \n",
      " conv1d_41 (Conv1D)             (None, 10, 1)        5           ['dropout_46[0][0]']             \n",
      "                                                                                                  \n",
      " tf.__operators__.add_41 (TFOpL  (None, 10, 1)       0           ['conv1d_41[0][0]',              \n",
      " ambda)                                                           'tf.__operators__.add_40[0][0]']\n",
      "                                                                                                  \n",
      " layer_normalization_42 (LayerN  (None, 10, 1)       2           ['tf.__operators__.add_41[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " multi_head_attention_21 (Multi  (None, 10, 1)       7169        ['layer_normalization_42[0][0]', \n",
      " HeadAttention)                                                   'layer_normalization_42[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_47 (Dropout)           (None, 10, 1)        0           ['multi_head_attention_21[0][0]']\n",
      "                                                                                                  \n",
      " tf.__operators__.add_42 (TFOpL  (None, 10, 1)       0           ['dropout_47[0][0]',             \n",
      " ambda)                                                           'tf.__operators__.add_41[0][0]']\n",
      "                                                                                                  \n",
      " layer_normalization_43 (LayerN  (None, 10, 1)       2           ['tf.__operators__.add_42[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv1d_42 (Conv1D)             (None, 10, 4)        8           ['layer_normalization_43[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_48 (Dropout)           (None, 10, 4)        0           ['conv1d_42[0][0]']              \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                                                  \n",
      " conv1d_43 (Conv1D)             (None, 10, 1)        5           ['dropout_48[0][0]']             \n",
      "                                                                                                  \n",
      " tf.__operators__.add_43 (TFOpL  (None, 10, 1)       0           ['conv1d_43[0][0]',              \n",
      " ambda)                                                           'tf.__operators__.add_42[0][0]']\n",
      "                                                                                                  \n",
      " layer_normalization_44 (LayerN  (None, 10, 1)       2           ['tf.__operators__.add_43[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " multi_head_attention_22 (Multi  (None, 10, 1)       7169        ['layer_normalization_44[0][0]', \n",
      " HeadAttention)                                                   'layer_normalization_44[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_49 (Dropout)           (None, 10, 1)        0           ['multi_head_attention_22[0][0]']\n",
      "                                                                                                  \n",
      " tf.__operators__.add_44 (TFOpL  (None, 10, 1)       0           ['dropout_49[0][0]',             \n",
      " ambda)                                                           'tf.__operators__.add_43[0][0]']\n",
      "                                                                                                  \n",
      " layer_normalization_45 (LayerN  (None, 10, 1)       2           ['tf.__operators__.add_44[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv1d_44 (Conv1D)             (None, 10, 4)        8           ['layer_normalization_45[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_50 (Dropout)           (None, 10, 4)        0           ['conv1d_44[0][0]']              \n",
      "                                                                                                  \n",
      " conv1d_45 (Conv1D)             (None, 10, 1)        5           ['dropout_50[0][0]']             \n",
      "                                                                                                  \n",
      " tf.__operators__.add_45 (TFOpL  (None, 10, 1)       0           ['conv1d_45[0][0]',              \n",
      " ambda)                                                           'tf.__operators__.add_44[0][0]']\n",
      "                                                                                                  \n",
      " layer_normalization_46 (LayerN  (None, 10, 1)       2           ['tf.__operators__.add_45[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " multi_head_attention_23 (Multi  (None, 10, 1)       7169        ['layer_normalization_46[0][0]', \n",
      " HeadAttention)                                                   'layer_normalization_46[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_51 (Dropout)           (None, 10, 1)        0           ['multi_head_attention_23[0][0]']\n",
      "                                                                                                  \n",
      " tf.__operators__.add_46 (TFOpL  (None, 10, 1)       0           ['dropout_51[0][0]',             \n",
      " ambda)                                                           'tf.__operators__.add_45[0][0]']\n",
      "                                                                                                  \n",
      " layer_normalization_47 (LayerN  (None, 10, 1)       2           ['tf.__operators__.add_46[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv1d_46 (Conv1D)             (None, 10, 4)        8           ['layer_normalization_47[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_52 (Dropout)           (None, 10, 4)        0           ['conv1d_46[0][0]']              \n",
      "                                                                                                  \n",
      " conv1d_47 (Conv1D)             (None, 10, 1)        5           ['dropout_52[0][0]']             \n",
      "                                                                                                  \n",
      " tf.__operators__.add_47 (TFOpL  (None, 10, 1)       0           ['conv1d_47[0][0]',              \n",
      " ambda)                                                           'tf.__operators__.add_46[0][0]']\n",
      "                                                                                                  \n",
      " global_average_pooling1d_5 (Gl  (None, 10)          0           ['tf.__operators__.add_47[0][0]']\n",
      " obalAveragePooling1D)                                                                            \n",
      "                                                                                                  \n",
      " dense_10 (Dense)               (None, 128)          1408        ['global_average_pooling1d_5[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " dropout_53 (Dropout)           (None, 128)          0           ['dense_10[0][0]']               \n",
      "                                                                                                  \n",
      " dense_11 (Dense)               (None, 1)            129         ['dropout_53[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 30,281\n",
      "Trainable params: 30,281\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/10\n",
      "88/88 [==============================] - 17s 153ms/step - loss: 0.0011 - val_loss: 0.0015\n",
      "Epoch 2/10\n",
      "88/88 [==============================] - 12s 135ms/step - loss: 0.0010 - val_loss: 0.0014\n",
      "Epoch 3/10\n",
      "88/88 [==============================] - 12s 134ms/step - loss: 9.6090e-04 - val_loss: 0.0014\n",
      "Epoch 4/10\n",
      "88/88 [==============================] - 12s 135ms/step - loss: 9.4178e-04 - val_loss: 0.0014\n",
      "Epoch 5/10\n",
      "88/88 [==============================] - 12s 135ms/step - loss: 9.4537e-04 - val_loss: 0.0014\n",
      "Epoch 6/10\n",
      "88/88 [==============================] - 12s 138ms/step - loss: 9.5834e-04 - val_loss: 0.0014\n",
      "Epoch 7/10\n",
      "88/88 [==============================] - 12s 138ms/step - loss: 9.3420e-04 - val_loss: 0.0014\n",
      "Epoch 8/10\n",
      "88/88 [==============================] - 12s 136ms/step - loss: 9.0692e-04 - val_loss: 0.0014\n",
      "Epoch 9/10\n",
      "88/88 [==============================] - 12s 137ms/step - loss: 9.3449e-04 - val_loss: 0.0013\n",
      "Epoch 10/10\n",
      "88/88 [==============================] - 12s 138ms/step - loss: 8.9521e-04 - val_loss: 0.0013\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0013\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000002A0DE6A6790> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 12ms/step\n",
      "Score (RMSE): 0.03609911418126019\n",
      "time to execute =  0:12:07.588034\n",
      "Iteration x =  7300  to row-stepsize  7797\n",
      "Model: \"model_6\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_7 (InputLayer)           [(None, 10, 1)]      0           []                               \n",
      "                                                                                                  \n",
      " layer_normalization_48 (LayerN  (None, 10, 1)       2           ['input_7[0][0]']                \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " multi_head_attention_24 (Multi  (None, 10, 1)       7169        ['layer_normalization_48[0][0]', \n",
      " HeadAttention)                                                   'layer_normalization_48[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_54 (Dropout)           (None, 10, 1)        0           ['multi_head_attention_24[0][0]']\n",
      "                                                                                                  \n",
      " tf.__operators__.add_48 (TFOpL  (None, 10, 1)       0           ['dropout_54[0][0]',             \n",
      " ambda)                                                           'input_7[0][0]']                \n",
      "                                                                                                  \n",
      " layer_normalization_49 (LayerN  (None, 10, 1)       2           ['tf.__operators__.add_48[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv1d_48 (Conv1D)             (None, 10, 4)        8           ['layer_normalization_49[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_55 (Dropout)           (None, 10, 4)        0           ['conv1d_48[0][0]']              \n",
      "                                                                                                  \n",
      " conv1d_49 (Conv1D)             (None, 10, 1)        5           ['dropout_55[0][0]']             \n",
      "                                                                                                  \n",
      " tf.__operators__.add_49 (TFOpL  (None, 10, 1)       0           ['conv1d_49[0][0]',              \n",
      " ambda)                                                           'tf.__operators__.add_48[0][0]']\n",
      "                                                                                                  \n",
      " layer_normalization_50 (LayerN  (None, 10, 1)       2           ['tf.__operators__.add_49[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " multi_head_attention_25 (Multi  (None, 10, 1)       7169        ['layer_normalization_50[0][0]', \n",
      " HeadAttention)                                                   'layer_normalization_50[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_56 (Dropout)           (None, 10, 1)        0           ['multi_head_attention_25[0][0]']\n",
      "                                                                                                  \n",
      " tf.__operators__.add_50 (TFOpL  (None, 10, 1)       0           ['dropout_56[0][0]',             \n",
      " ambda)                                                           'tf.__operators__.add_49[0][0]']\n",
      "                                                                                                  \n",
      " layer_normalization_51 (LayerN  (None, 10, 1)       2           ['tf.__operators__.add_50[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv1d_50 (Conv1D)             (None, 10, 4)        8           ['layer_normalization_51[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_57 (Dropout)           (None, 10, 4)        0           ['conv1d_50[0][0]']              \n",
      "                                                                                                  \n",
      " conv1d_51 (Conv1D)             (None, 10, 1)        5           ['dropout_57[0][0]']             \n",
      "                                                                                                  \n",
      " tf.__operators__.add_51 (TFOpL  (None, 10, 1)       0           ['conv1d_51[0][0]',              \n",
      " ambda)                                                           'tf.__operators__.add_50[0][0]']\n",
      "                                                                                                  \n",
      " layer_normalization_52 (LayerN  (None, 10, 1)       2           ['tf.__operators__.add_51[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " multi_head_attention_26 (Multi  (None, 10, 1)       7169        ['layer_normalization_52[0][0]', \n",
      " HeadAttention)                                                   'layer_normalization_52[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_58 (Dropout)           (None, 10, 1)        0           ['multi_head_attention_26[0][0]']\n",
      "                                                                                                  \n",
      " tf.__operators__.add_52 (TFOpL  (None, 10, 1)       0           ['dropout_58[0][0]',             \n",
      " ambda)                                                           'tf.__operators__.add_51[0][0]']\n",
      "                                                                                                  \n",
      " layer_normalization_53 (LayerN  (None, 10, 1)       2           ['tf.__operators__.add_52[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv1d_52 (Conv1D)             (None, 10, 4)        8           ['layer_normalization_53[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_59 (Dropout)           (None, 10, 4)        0           ['conv1d_52[0][0]']              \n",
      "                                                                                                  \n",
      " conv1d_53 (Conv1D)             (None, 10, 1)        5           ['dropout_59[0][0]']             \n",
      "                                                                                                  \n",
      " tf.__operators__.add_53 (TFOpL  (None, 10, 1)       0           ['conv1d_53[0][0]',              \n",
      " ambda)                                                           'tf.__operators__.add_52[0][0]']\n",
      "                                                                                                  \n",
      " layer_normalization_54 (LayerN  (None, 10, 1)       2           ['tf.__operators__.add_53[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " multi_head_attention_27 (Multi  (None, 10, 1)       7169        ['layer_normalization_54[0][0]', \n",
      " HeadAttention)                                                   'layer_normalization_54[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_60 (Dropout)           (None, 10, 1)        0           ['multi_head_attention_27[0][0]']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                                                  \n",
      " tf.__operators__.add_54 (TFOpL  (None, 10, 1)       0           ['dropout_60[0][0]',             \n",
      " ambda)                                                           'tf.__operators__.add_53[0][0]']\n",
      "                                                                                                  \n",
      " layer_normalization_55 (LayerN  (None, 10, 1)       2           ['tf.__operators__.add_54[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv1d_54 (Conv1D)             (None, 10, 4)        8           ['layer_normalization_55[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_61 (Dropout)           (None, 10, 4)        0           ['conv1d_54[0][0]']              \n",
      "                                                                                                  \n",
      " conv1d_55 (Conv1D)             (None, 10, 1)        5           ['dropout_61[0][0]']             \n",
      "                                                                                                  \n",
      " tf.__operators__.add_55 (TFOpL  (None, 10, 1)       0           ['conv1d_55[0][0]',              \n",
      " ambda)                                                           'tf.__operators__.add_54[0][0]']\n",
      "                                                                                                  \n",
      " global_average_pooling1d_6 (Gl  (None, 10)          0           ['tf.__operators__.add_55[0][0]']\n",
      " obalAveragePooling1D)                                                                            \n",
      "                                                                                                  \n",
      " dense_12 (Dense)               (None, 128)          1408        ['global_average_pooling1d_6[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " dropout_62 (Dropout)           (None, 128)          0           ['dense_12[0][0]']               \n",
      "                                                                                                  \n",
      " dense_13 (Dense)               (None, 1)            129         ['dropout_62[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 30,281\n",
      "Trainable params: 30,281\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/10\n",
      "88/88 [==============================] - 17s 150ms/step - loss: 0.0010 - val_loss: 0.0014\n",
      "Epoch 2/10\n",
      "88/88 [==============================] - 12s 135ms/step - loss: 0.0010 - val_loss: 0.0014\n",
      "Epoch 3/10\n",
      "88/88 [==============================] - 12s 136ms/step - loss: 9.8124e-04 - val_loss: 0.0014\n",
      "Epoch 4/10\n",
      "88/88 [==============================] - 12s 135ms/step - loss: 9.6172e-04 - val_loss: 0.0014\n",
      "Epoch 5/10\n",
      "88/88 [==============================] - 12s 136ms/step - loss: 9.7919e-04 - val_loss: 0.0014\n",
      "Epoch 6/10\n",
      "88/88 [==============================] - 12s 135ms/step - loss: 9.4452e-04 - val_loss: 0.0014\n",
      "Epoch 7/10\n",
      "88/88 [==============================] - 12s 134ms/step - loss: 9.4718e-04 - val_loss: 0.0014\n",
      "Epoch 8/10\n",
      "88/88 [==============================] - 12s 134ms/step - loss: 9.4187e-04 - val_loss: 0.0014\n",
      "Epoch 9/10\n",
      "88/88 [==============================] - 12s 134ms/step - loss: 9.4567e-04 - val_loss: 0.0014\n",
      "Epoch 10/10\n",
      "88/88 [==============================] - 12s 135ms/step - loss: 9.2679e-04 - val_loss: 0.0014\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.0016\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "Score (RMSE): 0.0394287731873902\n",
      "time to execute =  0:14:12.118035\n",
      "Iteration x =  7350  to row-stepsize  7797\n",
      "Model: \"model_7\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_8 (InputLayer)           [(None, 10, 1)]      0           []                               \n",
      "                                                                                                  \n",
      " layer_normalization_56 (LayerN  (None, 10, 1)       2           ['input_8[0][0]']                \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " multi_head_attention_28 (Multi  (None, 10, 1)       7169        ['layer_normalization_56[0][0]', \n",
      " HeadAttention)                                                   'layer_normalization_56[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_63 (Dropout)           (None, 10, 1)        0           ['multi_head_attention_28[0][0]']\n",
      "                                                                                                  \n",
      " tf.__operators__.add_56 (TFOpL  (None, 10, 1)       0           ['dropout_63[0][0]',             \n",
      " ambda)                                                           'input_8[0][0]']                \n",
      "                                                                                                  \n",
      " layer_normalization_57 (LayerN  (None, 10, 1)       2           ['tf.__operators__.add_56[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv1d_56 (Conv1D)             (None, 10, 4)        8           ['layer_normalization_57[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_64 (Dropout)           (None, 10, 4)        0           ['conv1d_56[0][0]']              \n",
      "                                                                                                  \n",
      " conv1d_57 (Conv1D)             (None, 10, 1)        5           ['dropout_64[0][0]']             \n",
      "                                                                                                  \n",
      " tf.__operators__.add_57 (TFOpL  (None, 10, 1)       0           ['conv1d_57[0][0]',              \n",
      " ambda)                                                           'tf.__operators__.add_56[0][0]']\n",
      "                                                                                                  \n",
      " layer_normalization_58 (LayerN  (None, 10, 1)       2           ['tf.__operators__.add_57[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " multi_head_attention_29 (Multi  (None, 10, 1)       7169        ['layer_normalization_58[0][0]', \n",
      " HeadAttention)                                                   'layer_normalization_58[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_65 (Dropout)           (None, 10, 1)        0           ['multi_head_attention_29[0][0]']\n",
      "                                                                                                  \n",
      " tf.__operators__.add_58 (TFOpL  (None, 10, 1)       0           ['dropout_65[0][0]',             \n",
      " ambda)                                                           'tf.__operators__.add_57[0][0]']\n",
      "                                                                                                  \n",
      " layer_normalization_59 (LayerN  (None, 10, 1)       2           ['tf.__operators__.add_58[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " conv1d_58 (Conv1D)             (None, 10, 4)        8           ['layer_normalization_59[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_66 (Dropout)           (None, 10, 4)        0           ['conv1d_58[0][0]']              \n",
      "                                                                                                  \n",
      " conv1d_59 (Conv1D)             (None, 10, 1)        5           ['dropout_66[0][0]']             \n",
      "                                                                                                  \n",
      " tf.__operators__.add_59 (TFOpL  (None, 10, 1)       0           ['conv1d_59[0][0]',              \n",
      " ambda)                                                           'tf.__operators__.add_58[0][0]']\n",
      "                                                                                                  \n",
      " layer_normalization_60 (LayerN  (None, 10, 1)       2           ['tf.__operators__.add_59[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " multi_head_attention_30 (Multi  (None, 10, 1)       7169        ['layer_normalization_60[0][0]', \n",
      " HeadAttention)                                                   'layer_normalization_60[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_67 (Dropout)           (None, 10, 1)        0           ['multi_head_attention_30[0][0]']\n",
      "                                                                                                  \n",
      " tf.__operators__.add_60 (TFOpL  (None, 10, 1)       0           ['dropout_67[0][0]',             \n",
      " ambda)                                                           'tf.__operators__.add_59[0][0]']\n",
      "                                                                                                  \n",
      " layer_normalization_61 (LayerN  (None, 10, 1)       2           ['tf.__operators__.add_60[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv1d_60 (Conv1D)             (None, 10, 4)        8           ['layer_normalization_61[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_68 (Dropout)           (None, 10, 4)        0           ['conv1d_60[0][0]']              \n",
      "                                                                                                  \n",
      " conv1d_61 (Conv1D)             (None, 10, 1)        5           ['dropout_68[0][0]']             \n",
      "                                                                                                  \n",
      " tf.__operators__.add_61 (TFOpL  (None, 10, 1)       0           ['conv1d_61[0][0]',              \n",
      " ambda)                                                           'tf.__operators__.add_60[0][0]']\n",
      "                                                                                                  \n",
      " layer_normalization_62 (LayerN  (None, 10, 1)       2           ['tf.__operators__.add_61[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " multi_head_attention_31 (Multi  (None, 10, 1)       7169        ['layer_normalization_62[0][0]', \n",
      " HeadAttention)                                                   'layer_normalization_62[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_69 (Dropout)           (None, 10, 1)        0           ['multi_head_attention_31[0][0]']\n",
      "                                                                                                  \n",
      " tf.__operators__.add_62 (TFOpL  (None, 10, 1)       0           ['dropout_69[0][0]',             \n",
      " ambda)                                                           'tf.__operators__.add_61[0][0]']\n",
      "                                                                                                  \n",
      " layer_normalization_63 (LayerN  (None, 10, 1)       2           ['tf.__operators__.add_62[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv1d_62 (Conv1D)             (None, 10, 4)        8           ['layer_normalization_63[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_70 (Dropout)           (None, 10, 4)        0           ['conv1d_62[0][0]']              \n",
      "                                                                                                  \n",
      " conv1d_63 (Conv1D)             (None, 10, 1)        5           ['dropout_70[0][0]']             \n",
      "                                                                                                  \n",
      " tf.__operators__.add_63 (TFOpL  (None, 10, 1)       0           ['conv1d_63[0][0]',              \n",
      " ambda)                                                           'tf.__operators__.add_62[0][0]']\n",
      "                                                                                                  \n",
      " global_average_pooling1d_7 (Gl  (None, 10)          0           ['tf.__operators__.add_63[0][0]']\n",
      " obalAveragePooling1D)                                                                            \n",
      "                                                                                                  \n",
      " dense_14 (Dense)               (None, 128)          1408        ['global_average_pooling1d_7[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " dropout_71 (Dropout)           (None, 128)          0           ['dense_14[0][0]']               \n",
      "                                                                                                  \n",
      " dense_15 (Dense)               (None, 1)            129         ['dropout_71[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 30,281\n",
      "Trainable params: 30,281\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/10\n",
      "88/88 [==============================] - 16s 139ms/step - loss: 0.0010 - val_loss: 0.0014\n",
      "Epoch 2/10\n",
      "88/88 [==============================] - 11s 128ms/step - loss: 0.0010 - val_loss: 0.0014\n",
      "Epoch 3/10\n",
      "88/88 [==============================] - 12s 131ms/step - loss: 0.0010 - val_loss: 0.0014\n",
      "Epoch 4/10\n",
      "88/88 [==============================] - 11s 127ms/step - loss: 0.0010 - val_loss: 0.0014\n",
      "Epoch 5/10\n",
      "88/88 [==============================] - 11s 129ms/step - loss: 9.7628e-04 - val_loss: 0.0014\n",
      "Epoch 6/10\n",
      "88/88 [==============================] - 11s 128ms/step - loss: 9.5767e-04 - val_loss: 0.0014\n",
      "Epoch 7/10\n",
      "88/88 [==============================] - 11s 127ms/step - loss: 9.8310e-04 - val_loss: 0.0014\n",
      "Epoch 8/10\n",
      "88/88 [==============================] - 11s 129ms/step - loss: 9.5445e-04 - val_loss: 0.0014\n",
      "Epoch 9/10\n",
      "88/88 [==============================] - 11s 128ms/step - loss: 9.3428e-04 - val_loss: 0.0014\n",
      "Epoch 10/10\n",
      "88/88 [==============================] - 11s 128ms/step - loss: 9.2856e-04 - val_loss: 0.0014\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0012\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Score (RMSE): 0.03432045714273508\n",
      "time to execute =  0:16:10.764577\n",
      "Iteration x =  7400  to row-stepsize  7797\n",
      "Model: \"model_8\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " input_9 (InputLayer)           [(None, 10, 1)]      0           []                               \n",
      "                                                                                                  \n",
      " layer_normalization_64 (LayerN  (None, 10, 1)       2           ['input_9[0][0]']                \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " multi_head_attention_32 (Multi  (None, 10, 1)       7169        ['layer_normalization_64[0][0]', \n",
      " HeadAttention)                                                   'layer_normalization_64[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_72 (Dropout)           (None, 10, 1)        0           ['multi_head_attention_32[0][0]']\n",
      "                                                                                                  \n",
      " tf.__operators__.add_64 (TFOpL  (None, 10, 1)       0           ['dropout_72[0][0]',             \n",
      " ambda)                                                           'input_9[0][0]']                \n",
      "                                                                                                  \n",
      " layer_normalization_65 (LayerN  (None, 10, 1)       2           ['tf.__operators__.add_64[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv1d_64 (Conv1D)             (None, 10, 4)        8           ['layer_normalization_65[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_73 (Dropout)           (None, 10, 4)        0           ['conv1d_64[0][0]']              \n",
      "                                                                                                  \n",
      " conv1d_65 (Conv1D)             (None, 10, 1)        5           ['dropout_73[0][0]']             \n",
      "                                                                                                  \n",
      " tf.__operators__.add_65 (TFOpL  (None, 10, 1)       0           ['conv1d_65[0][0]',              \n",
      " ambda)                                                           'tf.__operators__.add_64[0][0]']\n",
      "                                                                                                  \n",
      " layer_normalization_66 (LayerN  (None, 10, 1)       2           ['tf.__operators__.add_65[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " multi_head_attention_33 (Multi  (None, 10, 1)       7169        ['layer_normalization_66[0][0]', \n",
      " HeadAttention)                                                   'layer_normalization_66[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_74 (Dropout)           (None, 10, 1)        0           ['multi_head_attention_33[0][0]']\n",
      "                                                                                                  \n",
      " tf.__operators__.add_66 (TFOpL  (None, 10, 1)       0           ['dropout_74[0][0]',             \n",
      " ambda)                                                           'tf.__operators__.add_65[0][0]']\n",
      "                                                                                                  \n",
      " layer_normalization_67 (LayerN  (None, 10, 1)       2           ['tf.__operators__.add_66[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv1d_66 (Conv1D)             (None, 10, 4)        8           ['layer_normalization_67[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_75 (Dropout)           (None, 10, 4)        0           ['conv1d_66[0][0]']              \n",
      "                                                                                                  \n",
      " conv1d_67 (Conv1D)             (None, 10, 1)        5           ['dropout_75[0][0]']             \n",
      "                                                                                                  \n",
      " tf.__operators__.add_67 (TFOpL  (None, 10, 1)       0           ['conv1d_67[0][0]',              \n",
      " ambda)                                                           'tf.__operators__.add_66[0][0]']\n",
      "                                                                                                  \n",
      " layer_normalization_68 (LayerN  (None, 10, 1)       2           ['tf.__operators__.add_67[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " multi_head_attention_34 (Multi  (None, 10, 1)       7169        ['layer_normalization_68[0][0]', \n",
      " HeadAttention)                                                   'layer_normalization_68[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_76 (Dropout)           (None, 10, 1)        0           ['multi_head_attention_34[0][0]']\n",
      "                                                                                                  \n",
      " tf.__operators__.add_68 (TFOpL  (None, 10, 1)       0           ['dropout_76[0][0]',             \n",
      " ambda)                                                           'tf.__operators__.add_67[0][0]']\n",
      "                                                                                                  \n",
      " layer_normalization_69 (LayerN  (None, 10, 1)       2           ['tf.__operators__.add_68[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv1d_68 (Conv1D)             (None, 10, 4)        8           ['layer_normalization_69[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_77 (Dropout)           (None, 10, 4)        0           ['conv1d_68[0][0]']              \n",
      "                                                                                                  \n",
      " conv1d_69 (Conv1D)             (None, 10, 1)        5           ['dropout_77[0][0]']             \n",
      "                                                                                                  \n",
      " tf.__operators__.add_69 (TFOpL  (None, 10, 1)       0           ['conv1d_69[0][0]',              \n",
      " ambda)                                                           'tf.__operators__.add_68[0][0]']\n",
      "                                                                                                  \n",
      " layer_normalization_70 (LayerN  (None, 10, 1)       2           ['tf.__operators__.add_69[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " multi_head_attention_35 (Multi  (None, 10, 1)       7169        ['layer_normalization_70[0][0]', \n",
      " HeadAttention)                                                   'layer_normalization_70[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_78 (Dropout)           (None, 10, 1)        0           ['multi_head_attention_35[0][0]']\n",
      "                                                                                                  \n",
      " tf.__operators__.add_70 (TFOpL  (None, 10, 1)       0           ['dropout_78[0][0]',             \n",
      " ambda)                                                           'tf.__operators__.add_69[0][0]']\n",
      "                                                                                                  \n",
      " layer_normalization_71 (LayerN  (None, 10, 1)       2           ['tf.__operators__.add_70[0][0]']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv1d_70 (Conv1D)             (None, 10, 4)        8           ['layer_normalization_71[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_79 (Dropout)           (None, 10, 4)        0           ['conv1d_70[0][0]']              \n",
      "                                                                                                  \n",
      " conv1d_71 (Conv1D)             (None, 10, 1)        5           ['dropout_79[0][0]']             \n",
      "                                                                                                  \n",
      " tf.__operators__.add_71 (TFOpL  (None, 10, 1)       0           ['conv1d_71[0][0]',              \n",
      " ambda)                                                           'tf.__operators__.add_70[0][0]']\n",
      "                                                                                                  \n",
      " global_average_pooling1d_8 (Gl  (None, 10)          0           ['tf.__operators__.add_71[0][0]']\n",
      " obalAveragePooling1D)                                                                            \n",
      "                                                                                                  \n",
      " dense_16 (Dense)               (None, 128)          1408        ['global_average_pooling1d_8[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " dropout_80 (Dropout)           (None, 128)          0           ['dense_16[0][0]']               \n",
      "                                                                                                  \n",
      " dense_17 (Dense)               (None, 1)            129         ['dropout_80[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 30,281\n",
      "Trainable params: 30,281\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/10\n",
      "88/88 [==============================] - 16s 146ms/step - loss: 0.0011 - val_loss: 0.0014\n",
      "Epoch 2/10\n",
      "88/88 [==============================] - 12s 133ms/step - loss: 0.0010 - val_loss: 0.0014\n",
      "Epoch 3/10\n",
      "88/88 [==============================] - 12s 134ms/step - loss: 0.0010 - val_loss: 0.0014\n",
      "Epoch 4/10\n",
      "88/88 [==============================] - 12s 133ms/step - loss: 0.0010 - val_loss: 0.0014\n",
      "Epoch 5/10\n",
      "88/88 [==============================] - 12s 132ms/step - loss: 0.0010 - val_loss: 0.0014\n",
      "Epoch 6/10\n",
      "88/88 [==============================] - 12s 133ms/step - loss: 9.7989e-04 - val_loss: 0.0014\n",
      "Epoch 7/10\n",
      "88/88 [==============================] - 12s 135ms/step - loss: 9.8002e-04 - val_loss: 0.0014\n",
      "Epoch 8/10\n",
      "88/88 [==============================] - 12s 133ms/step - loss: 9.8135e-04 - val_loss: 0.0014\n",
      "Epoch 9/10\n",
      "88/88 [==============================] - 12s 132ms/step - loss: 9.4748e-04 - val_loss: 0.0014\n",
      "Epoch 10/10\n",
      "88/88 [==============================] - 12s 131ms/step - loss: 9.4824e-04 - val_loss: 0.0014\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0014\n",
      "2/2 [==============================] - 0s 10ms/step\n",
      "Score (RMSE): 0.03725759338642618\n",
      "time to execute =  0:18:13.722552\n",
      "Iteration x =  7450  to row-stepsize  7797\n",
      "Model: \"model_9\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_10 (InputLayer)          [(None, 10, 1)]      0           []                               \n",
      "                                                                                                  \n",
      " layer_normalization_72 (LayerN  (None, 10, 1)       2           ['input_10[0][0]']               \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " multi_head_attention_36 (Multi  (None, 10, 1)       7169        ['layer_normalization_72[0][0]', \n",
      " HeadAttention)                                                   'layer_normalization_72[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_81 (Dropout)           (None, 10, 1)        0           ['multi_head_attention_36[0][0]']\n",
      "                                                                                                  \n",
      " tf.__operators__.add_72 (TFOpL  (None, 10, 1)       0           ['dropout_81[0][0]',             \n",
      " ambda)                                                           'input_10[0][0]']               \n",
      "                                                                                                  \n",
      " layer_normalization_73 (LayerN  (None, 10, 1)       2           ['tf.__operators__.add_72[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv1d_72 (Conv1D)             (None, 10, 4)        8           ['layer_normalization_73[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_82 (Dropout)           (None, 10, 4)        0           ['conv1d_72[0][0]']              \n",
      "                                                                                                  \n",
      " conv1d_73 (Conv1D)             (None, 10, 1)        5           ['dropout_82[0][0]']             \n",
      "                                                                                                  \n",
      " tf.__operators__.add_73 (TFOpL  (None, 10, 1)       0           ['conv1d_73[0][0]',              \n",
      " ambda)                                                           'tf.__operators__.add_72[0][0]']\n",
      "                                                                                                  \n",
      " layer_normalization_74 (LayerN  (None, 10, 1)       2           ['tf.__operators__.add_73[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " multi_head_attention_37 (Multi  (None, 10, 1)       7169        ['layer_normalization_74[0][0]', \n",
      " HeadAttention)                                                   'layer_normalization_74[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_83 (Dropout)           (None, 10, 1)        0           ['multi_head_attention_37[0][0]']\n",
      "                                                                                                  \n",
      " tf.__operators__.add_74 (TFOpL  (None, 10, 1)       0           ['dropout_83[0][0]',             \n",
      " ambda)                                                           'tf.__operators__.add_73[0][0]']\n",
      "                                                                                                  \n",
      " layer_normalization_75 (LayerN  (None, 10, 1)       2           ['tf.__operators__.add_74[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv1d_74 (Conv1D)             (None, 10, 4)        8           ['layer_normalization_75[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_84 (Dropout)           (None, 10, 4)        0           ['conv1d_74[0][0]']              \n",
      "                                                                                                  \n",
      " conv1d_75 (Conv1D)             (None, 10, 1)        5           ['dropout_84[0][0]']             \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                                                  \n",
      " tf.__operators__.add_75 (TFOpL  (None, 10, 1)       0           ['conv1d_75[0][0]',              \n",
      " ambda)                                                           'tf.__operators__.add_74[0][0]']\n",
      "                                                                                                  \n",
      " layer_normalization_76 (LayerN  (None, 10, 1)       2           ['tf.__operators__.add_75[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " multi_head_attention_38 (Multi  (None, 10, 1)       7169        ['layer_normalization_76[0][0]', \n",
      " HeadAttention)                                                   'layer_normalization_76[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_85 (Dropout)           (None, 10, 1)        0           ['multi_head_attention_38[0][0]']\n",
      "                                                                                                  \n",
      " tf.__operators__.add_76 (TFOpL  (None, 10, 1)       0           ['dropout_85[0][0]',             \n",
      " ambda)                                                           'tf.__operators__.add_75[0][0]']\n",
      "                                                                                                  \n",
      " layer_normalization_77 (LayerN  (None, 10, 1)       2           ['tf.__operators__.add_76[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv1d_76 (Conv1D)             (None, 10, 4)        8           ['layer_normalization_77[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_86 (Dropout)           (None, 10, 4)        0           ['conv1d_76[0][0]']              \n",
      "                                                                                                  \n",
      " conv1d_77 (Conv1D)             (None, 10, 1)        5           ['dropout_86[0][0]']             \n",
      "                                                                                                  \n",
      " tf.__operators__.add_77 (TFOpL  (None, 10, 1)       0           ['conv1d_77[0][0]',              \n",
      " ambda)                                                           'tf.__operators__.add_76[0][0]']\n",
      "                                                                                                  \n",
      " layer_normalization_78 (LayerN  (None, 10, 1)       2           ['tf.__operators__.add_77[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " multi_head_attention_39 (Multi  (None, 10, 1)       7169        ['layer_normalization_78[0][0]', \n",
      " HeadAttention)                                                   'layer_normalization_78[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_87 (Dropout)           (None, 10, 1)        0           ['multi_head_attention_39[0][0]']\n",
      "                                                                                                  \n",
      " tf.__operators__.add_78 (TFOpL  (None, 10, 1)       0           ['dropout_87[0][0]',             \n",
      " ambda)                                                           'tf.__operators__.add_77[0][0]']\n",
      "                                                                                                  \n",
      " layer_normalization_79 (LayerN  (None, 10, 1)       2           ['tf.__operators__.add_78[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv1d_78 (Conv1D)             (None, 10, 4)        8           ['layer_normalization_79[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_88 (Dropout)           (None, 10, 4)        0           ['conv1d_78[0][0]']              \n",
      "                                                                                                  \n",
      " conv1d_79 (Conv1D)             (None, 10, 1)        5           ['dropout_88[0][0]']             \n",
      "                                                                                                  \n",
      " tf.__operators__.add_79 (TFOpL  (None, 10, 1)       0           ['conv1d_79[0][0]',              \n",
      " ambda)                                                           'tf.__operators__.add_78[0][0]']\n",
      "                                                                                                  \n",
      " global_average_pooling1d_9 (Gl  (None, 10)          0           ['tf.__operators__.add_79[0][0]']\n",
      " obalAveragePooling1D)                                                                            \n",
      "                                                                                                  \n",
      " dense_18 (Dense)               (None, 128)          1408        ['global_average_pooling1d_9[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " dropout_89 (Dropout)           (None, 128)          0           ['dense_18[0][0]']               \n",
      "                                                                                                  \n",
      " dense_19 (Dense)               (None, 1)            129         ['dropout_89[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 30,281\n",
      "Trainable params: 30,281\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/10\n",
      "88/88 [==============================] - 17s 153ms/step - loss: 0.0011 - val_loss: 0.0014\n",
      "Epoch 2/10\n",
      "88/88 [==============================] - 12s 140ms/step - loss: 0.0012 - val_loss: 0.0013\n",
      "Epoch 3/10\n",
      "88/88 [==============================] - 12s 141ms/step - loss: 0.0011 - val_loss: 0.0013\n",
      "Epoch 4/10\n",
      "88/88 [==============================] - 12s 142ms/step - loss: 0.0010 - val_loss: 0.0013\n",
      "Epoch 5/10\n",
      "88/88 [==============================] - 12s 141ms/step - loss: 0.0011 - val_loss: 0.0013\n",
      "Epoch 6/10\n",
      "88/88 [==============================] - 12s 141ms/step - loss: 0.0010 - val_loss: 0.0013\n",
      "Epoch 7/10\n",
      "88/88 [==============================] - 12s 140ms/step - loss: 0.0010 - val_loss: 0.0013\n",
      "Epoch 8/10\n",
      "88/88 [==============================] - 12s 140ms/step - loss: 0.0010 - val_loss: 0.0013\n",
      "Epoch 9/10\n",
      "88/88 [==============================] - 12s 141ms/step - loss: 9.8661e-04 - val_loss: 0.0013\n",
      "Epoch 10/10\n",
      "88/88 [==============================] - 12s 140ms/step - loss: 9.6771e-04 - val_loss: 0.0013\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0010\n",
      "2/2 [==============================] - 0s 12ms/step\n",
      "Score (RMSE): 0.03207021687493765\n",
      "time to execute =  0:20:23.534749\n",
      "Iteration x =  7500  to row-stepsize  7797\n",
      "Model: \"model_10\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_11 (InputLayer)          [(None, 10, 1)]      0           []                               \n",
      "                                                                                                  \n",
      " layer_normalization_80 (LayerN  (None, 10, 1)       2           ['input_11[0][0]']               \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " multi_head_attention_40 (Multi  (None, 10, 1)       7169        ['layer_normalization_80[0][0]', \n",
      " HeadAttention)                                                   'layer_normalization_80[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_90 (Dropout)           (None, 10, 1)        0           ['multi_head_attention_40[0][0]']\n",
      "                                                                                                  \n",
      " tf.__operators__.add_80 (TFOpL  (None, 10, 1)       0           ['dropout_90[0][0]',             \n",
      " ambda)                                                           'input_11[0][0]']               \n",
      "                                                                                                  \n",
      " layer_normalization_81 (LayerN  (None, 10, 1)       2           ['tf.__operators__.add_80[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv1d_80 (Conv1D)             (None, 10, 4)        8           ['layer_normalization_81[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_91 (Dropout)           (None, 10, 4)        0           ['conv1d_80[0][0]']              \n",
      "                                                                                                  \n",
      " conv1d_81 (Conv1D)             (None, 10, 1)        5           ['dropout_91[0][0]']             \n",
      "                                                                                                  \n",
      " tf.__operators__.add_81 (TFOpL  (None, 10, 1)       0           ['conv1d_81[0][0]',              \n",
      " ambda)                                                           'tf.__operators__.add_80[0][0]']\n",
      "                                                                                                  \n",
      " layer_normalization_82 (LayerN  (None, 10, 1)       2           ['tf.__operators__.add_81[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " multi_head_attention_41 (Multi  (None, 10, 1)       7169        ['layer_normalization_82[0][0]', \n",
      " HeadAttention)                                                   'layer_normalization_82[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_92 (Dropout)           (None, 10, 1)        0           ['multi_head_attention_41[0][0]']\n",
      "                                                                                                  \n",
      " tf.__operators__.add_82 (TFOpL  (None, 10, 1)       0           ['dropout_92[0][0]',             \n",
      " ambda)                                                           'tf.__operators__.add_81[0][0]']\n",
      "                                                                                                  \n",
      " layer_normalization_83 (LayerN  (None, 10, 1)       2           ['tf.__operators__.add_82[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv1d_82 (Conv1D)             (None, 10, 4)        8           ['layer_normalization_83[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_93 (Dropout)           (None, 10, 4)        0           ['conv1d_82[0][0]']              \n",
      "                                                                                                  \n",
      " conv1d_83 (Conv1D)             (None, 10, 1)        5           ['dropout_93[0][0]']             \n",
      "                                                                                                  \n",
      " tf.__operators__.add_83 (TFOpL  (None, 10, 1)       0           ['conv1d_83[0][0]',              \n",
      " ambda)                                                           'tf.__operators__.add_82[0][0]']\n",
      "                                                                                                  \n",
      " layer_normalization_84 (LayerN  (None, 10, 1)       2           ['tf.__operators__.add_83[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " multi_head_attention_42 (Multi  (None, 10, 1)       7169        ['layer_normalization_84[0][0]', \n",
      " HeadAttention)                                                   'layer_normalization_84[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_94 (Dropout)           (None, 10, 1)        0           ['multi_head_attention_42[0][0]']\n",
      "                                                                                                  \n",
      " tf.__operators__.add_84 (TFOpL  (None, 10, 1)       0           ['dropout_94[0][0]',             \n",
      " ambda)                                                           'tf.__operators__.add_83[0][0]']\n",
      "                                                                                                  \n",
      " layer_normalization_85 (LayerN  (None, 10, 1)       2           ['tf.__operators__.add_84[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv1d_84 (Conv1D)             (None, 10, 4)        8           ['layer_normalization_85[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_95 (Dropout)           (None, 10, 4)        0           ['conv1d_84[0][0]']              \n",
      "                                                                                                  \n",
      " conv1d_85 (Conv1D)             (None, 10, 1)        5           ['dropout_95[0][0]']             \n",
      "                                                                                                  \n",
      " tf.__operators__.add_85 (TFOpL  (None, 10, 1)       0           ['conv1d_85[0][0]',              \n",
      " ambda)                                                           'tf.__operators__.add_84[0][0]']\n",
      "                                                                                                  \n",
      " layer_normalization_86 (LayerN  (None, 10, 1)       2           ['tf.__operators__.add_85[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " multi_head_attention_43 (Multi  (None, 10, 1)       7169        ['layer_normalization_86[0][0]', \n",
      " HeadAttention)                                                   'layer_normalization_86[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_96 (Dropout)           (None, 10, 1)        0           ['multi_head_attention_43[0][0]']\n",
      "                                                                                                  \n",
      " tf.__operators__.add_86 (TFOpL  (None, 10, 1)       0           ['dropout_96[0][0]',             \n",
      " ambda)                                                           'tf.__operators__.add_85[0][0]']\n",
      "                                                                                                  \n",
      " layer_normalization_87 (LayerN  (None, 10, 1)       2           ['tf.__operators__.add_86[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv1d_86 (Conv1D)             (None, 10, 4)        8           ['layer_normalization_87[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_97 (Dropout)           (None, 10, 4)        0           ['conv1d_86[0][0]']              \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                                                  \n",
      " conv1d_87 (Conv1D)             (None, 10, 1)        5           ['dropout_97[0][0]']             \n",
      "                                                                                                  \n",
      " tf.__operators__.add_87 (TFOpL  (None, 10, 1)       0           ['conv1d_87[0][0]',              \n",
      " ambda)                                                           'tf.__operators__.add_86[0][0]']\n",
      "                                                                                                  \n",
      " global_average_pooling1d_10 (G  (None, 10)          0           ['tf.__operators__.add_87[0][0]']\n",
      " lobalAveragePooling1D)                                                                           \n",
      "                                                                                                  \n",
      " dense_20 (Dense)               (None, 128)          1408        ['global_average_pooling1d_10[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      " dropout_98 (Dropout)           (None, 128)          0           ['dense_20[0][0]']               \n",
      "                                                                                                  \n",
      " dense_21 (Dense)               (None, 1)            129         ['dropout_98[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 30,281\n",
      "Trainable params: 30,281\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/10\n",
      "88/88 [==============================] - 16s 143ms/step - loss: 0.0011 - val_loss: 0.0013\n",
      "Epoch 2/10\n",
      "88/88 [==============================] - 12s 136ms/step - loss: 0.0010 - val_loss: 0.0013\n",
      "Epoch 3/10\n",
      "88/88 [==============================] - 12s 134ms/step - loss: 0.0010 - val_loss: 0.0013\n",
      "Epoch 4/10\n",
      "88/88 [==============================] - 12s 136ms/step - loss: 0.0010 - val_loss: 0.0013\n",
      "Epoch 5/10\n",
      "88/88 [==============================] - 12s 137ms/step - loss: 0.0010 - val_loss: 0.0014\n",
      "Epoch 6/10\n",
      "88/88 [==============================] - 12s 136ms/step - loss: 0.0010 - val_loss: 0.0013\n",
      "Epoch 7/10\n",
      "88/88 [==============================] - 12s 136ms/step - loss: 0.0010 - val_loss: 0.0014\n",
      "Epoch 8/10\n",
      "88/88 [==============================] - 12s 136ms/step - loss: 9.6161e-04 - val_loss: 0.0013\n",
      "Epoch 9/10\n",
      "88/88 [==============================] - 12s 135ms/step - loss: 9.6176e-04 - val_loss: 0.0013\n",
      "Epoch 10/10\n",
      "88/88 [==============================] - 12s 136ms/step - loss: 9.6938e-04 - val_loss: 0.0013\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 8.0371e-04\n",
      "2/2 [==============================] - 0s 12ms/step\n",
      "Score (RMSE): 0.028349694731977147\n",
      "time to execute =  0:22:28.396261\n",
      "Iteration x =  7550  to row-stepsize  7797\n",
      "Model: \"model_11\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_12 (InputLayer)          [(None, 10, 1)]      0           []                               \n",
      "                                                                                                  \n",
      " layer_normalization_88 (LayerN  (None, 10, 1)       2           ['input_12[0][0]']               \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " multi_head_attention_44 (Multi  (None, 10, 1)       7169        ['layer_normalization_88[0][0]', \n",
      " HeadAttention)                                                   'layer_normalization_88[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_99 (Dropout)           (None, 10, 1)        0           ['multi_head_attention_44[0][0]']\n",
      "                                                                                                  \n",
      " tf.__operators__.add_88 (TFOpL  (None, 10, 1)       0           ['dropout_99[0][0]',             \n",
      " ambda)                                                           'input_12[0][0]']               \n",
      "                                                                                                  \n",
      " layer_normalization_89 (LayerN  (None, 10, 1)       2           ['tf.__operators__.add_88[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv1d_88 (Conv1D)             (None, 10, 4)        8           ['layer_normalization_89[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_100 (Dropout)          (None, 10, 4)        0           ['conv1d_88[0][0]']              \n",
      "                                                                                                  \n",
      " conv1d_89 (Conv1D)             (None, 10, 1)        5           ['dropout_100[0][0]']            \n",
      "                                                                                                  \n",
      " tf.__operators__.add_89 (TFOpL  (None, 10, 1)       0           ['conv1d_89[0][0]',              \n",
      " ambda)                                                           'tf.__operators__.add_88[0][0]']\n",
      "                                                                                                  \n",
      " layer_normalization_90 (LayerN  (None, 10, 1)       2           ['tf.__operators__.add_89[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " multi_head_attention_45 (Multi  (None, 10, 1)       7169        ['layer_normalization_90[0][0]', \n",
      " HeadAttention)                                                   'layer_normalization_90[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_101 (Dropout)          (None, 10, 1)        0           ['multi_head_attention_45[0][0]']\n",
      "                                                                                                  \n",
      " tf.__operators__.add_90 (TFOpL  (None, 10, 1)       0           ['dropout_101[0][0]',            \n",
      " ambda)                                                           'tf.__operators__.add_89[0][0]']\n",
      "                                                                                                  \n",
      " layer_normalization_91 (LayerN  (None, 10, 1)       2           ['tf.__operators__.add_90[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv1d_90 (Conv1D)             (None, 10, 4)        8           ['layer_normalization_91[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_102 (Dropout)          (None, 10, 4)        0           ['conv1d_90[0][0]']              \n",
      "                                                                                                  \n",
      " conv1d_91 (Conv1D)             (None, 10, 1)        5           ['dropout_102[0][0]']            \n",
      "                                                                                                  \n",
      " tf.__operators__.add_91 (TFOpL  (None, 10, 1)       0           ['conv1d_91[0][0]',              \n",
      " ambda)                                                           'tf.__operators__.add_90[0][0]']\n",
      "                                                                                                  \n",
      " layer_normalization_92 (LayerN  (None, 10, 1)       2           ['tf.__operators__.add_91[0][0]']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " multi_head_attention_46 (Multi  (None, 10, 1)       7169        ['layer_normalization_92[0][0]', \n",
      " HeadAttention)                                                   'layer_normalization_92[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_103 (Dropout)          (None, 10, 1)        0           ['multi_head_attention_46[0][0]']\n",
      "                                                                                                  \n",
      " tf.__operators__.add_92 (TFOpL  (None, 10, 1)       0           ['dropout_103[0][0]',            \n",
      " ambda)                                                           'tf.__operators__.add_91[0][0]']\n",
      "                                                                                                  \n",
      " layer_normalization_93 (LayerN  (None, 10, 1)       2           ['tf.__operators__.add_92[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv1d_92 (Conv1D)             (None, 10, 4)        8           ['layer_normalization_93[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_104 (Dropout)          (None, 10, 4)        0           ['conv1d_92[0][0]']              \n",
      "                                                                                                  \n",
      " conv1d_93 (Conv1D)             (None, 10, 1)        5           ['dropout_104[0][0]']            \n",
      "                                                                                                  \n",
      " tf.__operators__.add_93 (TFOpL  (None, 10, 1)       0           ['conv1d_93[0][0]',              \n",
      " ambda)                                                           'tf.__operators__.add_92[0][0]']\n",
      "                                                                                                  \n",
      " layer_normalization_94 (LayerN  (None, 10, 1)       2           ['tf.__operators__.add_93[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " multi_head_attention_47 (Multi  (None, 10, 1)       7169        ['layer_normalization_94[0][0]', \n",
      " HeadAttention)                                                   'layer_normalization_94[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_105 (Dropout)          (None, 10, 1)        0           ['multi_head_attention_47[0][0]']\n",
      "                                                                                                  \n",
      " tf.__operators__.add_94 (TFOpL  (None, 10, 1)       0           ['dropout_105[0][0]',            \n",
      " ambda)                                                           'tf.__operators__.add_93[0][0]']\n",
      "                                                                                                  \n",
      " layer_normalization_95 (LayerN  (None, 10, 1)       2           ['tf.__operators__.add_94[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv1d_94 (Conv1D)             (None, 10, 4)        8           ['layer_normalization_95[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_106 (Dropout)          (None, 10, 4)        0           ['conv1d_94[0][0]']              \n",
      "                                                                                                  \n",
      " conv1d_95 (Conv1D)             (None, 10, 1)        5           ['dropout_106[0][0]']            \n",
      "                                                                                                  \n",
      " tf.__operators__.add_95 (TFOpL  (None, 10, 1)       0           ['conv1d_95[0][0]',              \n",
      " ambda)                                                           'tf.__operators__.add_94[0][0]']\n",
      "                                                                                                  \n",
      " global_average_pooling1d_11 (G  (None, 10)          0           ['tf.__operators__.add_95[0][0]']\n",
      " lobalAveragePooling1D)                                                                           \n",
      "                                                                                                  \n",
      " dense_22 (Dense)               (None, 128)          1408        ['global_average_pooling1d_11[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      " dropout_107 (Dropout)          (None, 128)          0           ['dense_22[0][0]']               \n",
      "                                                                                                  \n",
      " dense_23 (Dense)               (None, 1)            129         ['dropout_107[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 30,281\n",
      "Trainable params: 30,281\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/10\n",
      "88/88 [==============================] - 17s 150ms/step - loss: 0.0010 - val_loss: 0.0014\n",
      "Epoch 2/10\n",
      "88/88 [==============================] - 12s 135ms/step - loss: 0.0010 - val_loss: 0.0014\n",
      "Epoch 3/10\n",
      "88/88 [==============================] - 12s 137ms/step - loss: 9.9680e-04 - val_loss: 0.0014\n",
      "Epoch 4/10\n",
      "88/88 [==============================] - 12s 137ms/step - loss: 0.0010 - val_loss: 0.0014\n",
      "Epoch 5/10\n",
      "88/88 [==============================] - 12s 137ms/step - loss: 9.8930e-04 - val_loss: 0.0014\n",
      "Epoch 6/10\n",
      "88/88 [==============================] - 12s 138ms/step - loss: 9.5625e-04 - val_loss: 0.0014\n",
      "Epoch 7/10\n",
      "88/88 [==============================] - 12s 138ms/step - loss: 9.8198e-04 - val_loss: 0.0014\n",
      "Epoch 8/10\n",
      "88/88 [==============================] - 12s 138ms/step - loss: 9.5863e-04 - val_loss: 0.0014\n",
      "Epoch 9/10\n",
      "88/88 [==============================] - 12s 138ms/step - loss: 9.6009e-04 - val_loss: 0.0014\n",
      "Epoch 10/10\n",
      "88/88 [==============================] - 12s 136ms/step - loss: 9.9379e-04 - val_loss: 0.0014\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0018\n",
      "2/2 [==============================] - 0s 11ms/step\n",
      "Score (RMSE): 0.04234754887622898\n",
      "time to execute =  0:24:35.199778\n",
      "Iteration x =  7600  to row-stepsize  7797\n",
      "Model: \"model_12\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_13 (InputLayer)          [(None, 10, 1)]      0           []                               \n",
      "                                                                                                  \n",
      " layer_normalization_96 (LayerN  (None, 10, 1)       2           ['input_13[0][0]']               \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " multi_head_attention_48 (Multi  (None, 10, 1)       7169        ['layer_normalization_96[0][0]', \n",
      " HeadAttention)                                                   'layer_normalization_96[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_108 (Dropout)          (None, 10, 1)        0           ['multi_head_attention_48[0][0]']\n",
      "                                                                                                  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " tf.__operators__.add_96 (TFOpL  (None, 10, 1)       0           ['dropout_108[0][0]',            \n",
      " ambda)                                                           'input_13[0][0]']               \n",
      "                                                                                                  \n",
      " layer_normalization_97 (LayerN  (None, 10, 1)       2           ['tf.__operators__.add_96[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv1d_96 (Conv1D)             (None, 10, 4)        8           ['layer_normalization_97[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_109 (Dropout)          (None, 10, 4)        0           ['conv1d_96[0][0]']              \n",
      "                                                                                                  \n",
      " conv1d_97 (Conv1D)             (None, 10, 1)        5           ['dropout_109[0][0]']            \n",
      "                                                                                                  \n",
      " tf.__operators__.add_97 (TFOpL  (None, 10, 1)       0           ['conv1d_97[0][0]',              \n",
      " ambda)                                                           'tf.__operators__.add_96[0][0]']\n",
      "                                                                                                  \n",
      " layer_normalization_98 (LayerN  (None, 10, 1)       2           ['tf.__operators__.add_97[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " multi_head_attention_49 (Multi  (None, 10, 1)       7169        ['layer_normalization_98[0][0]', \n",
      " HeadAttention)                                                   'layer_normalization_98[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_110 (Dropout)          (None, 10, 1)        0           ['multi_head_attention_49[0][0]']\n",
      "                                                                                                  \n",
      " tf.__operators__.add_98 (TFOpL  (None, 10, 1)       0           ['dropout_110[0][0]',            \n",
      " ambda)                                                           'tf.__operators__.add_97[0][0]']\n",
      "                                                                                                  \n",
      " layer_normalization_99 (LayerN  (None, 10, 1)       2           ['tf.__operators__.add_98[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv1d_98 (Conv1D)             (None, 10, 4)        8           ['layer_normalization_99[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_111 (Dropout)          (None, 10, 4)        0           ['conv1d_98[0][0]']              \n",
      "                                                                                                  \n",
      " conv1d_99 (Conv1D)             (None, 10, 1)        5           ['dropout_111[0][0]']            \n",
      "                                                                                                  \n",
      " tf.__operators__.add_99 (TFOpL  (None, 10, 1)       0           ['conv1d_99[0][0]',              \n",
      " ambda)                                                           'tf.__operators__.add_98[0][0]']\n",
      "                                                                                                  \n",
      " layer_normalization_100 (Layer  (None, 10, 1)       2           ['tf.__operators__.add_99[0][0]']\n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " multi_head_attention_50 (Multi  (None, 10, 1)       7169        ['layer_normalization_100[0][0]',\n",
      " HeadAttention)                                                   'layer_normalization_100[0][0]']\n",
      "                                                                                                  \n",
      " dropout_112 (Dropout)          (None, 10, 1)        0           ['multi_head_attention_50[0][0]']\n",
      "                                                                                                  \n",
      " tf.__operators__.add_100 (TFOp  (None, 10, 1)       0           ['dropout_112[0][0]',            \n",
      " Lambda)                                                          'tf.__operators__.add_99[0][0]']\n",
      "                                                                                                  \n",
      " layer_normalization_101 (Layer  (None, 10, 1)       2           ['tf.__operators__.add_100[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " conv1d_100 (Conv1D)            (None, 10, 4)        8           ['layer_normalization_101[0][0]']\n",
      "                                                                                                  \n",
      " dropout_113 (Dropout)          (None, 10, 4)        0           ['conv1d_100[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d_101 (Conv1D)            (None, 10, 1)        5           ['dropout_113[0][0]']            \n",
      "                                                                                                  \n",
      " tf.__operators__.add_101 (TFOp  (None, 10, 1)       0           ['conv1d_101[0][0]',             \n",
      " Lambda)                                                          'tf.__operators__.add_100[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_102 (Layer  (None, 10, 1)       2           ['tf.__operators__.add_101[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " multi_head_attention_51 (Multi  (None, 10, 1)       7169        ['layer_normalization_102[0][0]',\n",
      " HeadAttention)                                                   'layer_normalization_102[0][0]']\n",
      "                                                                                                  \n",
      " dropout_114 (Dropout)          (None, 10, 1)        0           ['multi_head_attention_51[0][0]']\n",
      "                                                                                                  \n",
      " tf.__operators__.add_102 (TFOp  (None, 10, 1)       0           ['dropout_114[0][0]',            \n",
      " Lambda)                                                          'tf.__operators__.add_101[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_103 (Layer  (None, 10, 1)       2           ['tf.__operators__.add_102[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " conv1d_102 (Conv1D)            (None, 10, 4)        8           ['layer_normalization_103[0][0]']\n",
      "                                                                                                  \n",
      " dropout_115 (Dropout)          (None, 10, 4)        0           ['conv1d_102[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d_103 (Conv1D)            (None, 10, 1)        5           ['dropout_115[0][0]']            \n",
      "                                                                                                  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " tf.__operators__.add_103 (TFOp  (None, 10, 1)       0           ['conv1d_103[0][0]',             \n",
      " Lambda)                                                          'tf.__operators__.add_102[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " global_average_pooling1d_12 (G  (None, 10)          0           ['tf.__operators__.add_103[0][0]'\n",
      " lobalAveragePooling1D)                                          ]                                \n",
      "                                                                                                  \n",
      " dense_24 (Dense)               (None, 128)          1408        ['global_average_pooling1d_12[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      " dropout_116 (Dropout)          (None, 128)          0           ['dense_24[0][0]']               \n",
      "                                                                                                  \n",
      " dense_25 (Dense)               (None, 1)            129         ['dropout_116[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 30,281\n",
      "Trainable params: 30,281\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/10\n",
      "88/88 [==============================] - 17s 155ms/step - loss: 0.0012 - val_loss: 0.0014\n",
      "Epoch 2/10\n",
      "88/88 [==============================] - 13s 150ms/step - loss: 0.0011 - val_loss: 0.0014\n",
      "Epoch 3/10\n",
      "88/88 [==============================] - 13s 150ms/step - loss: 0.0011 - val_loss: 0.0014\n",
      "Epoch 4/10\n",
      "88/88 [==============================] - 13s 150ms/step - loss: 0.0010 - val_loss: 0.0014\n",
      "Epoch 5/10\n",
      "88/88 [==============================] - 13s 150ms/step - loss: 0.0011 - val_loss: 0.0014\n",
      "Epoch 6/10\n",
      "88/88 [==============================] - 13s 150ms/step - loss: 9.7546e-04 - val_loss: 0.0014\n",
      "Epoch 7/10\n",
      "88/88 [==============================] - 13s 150ms/step - loss: 0.0010 - val_loss: 0.0014\n",
      "Epoch 8/10\n",
      "88/88 [==============================] - 13s 150ms/step - loss: 0.0010 - val_loss: 0.0014\n",
      "Epoch 9/10\n",
      "88/88 [==============================] - 13s 149ms/step - loss: 0.0010 - val_loss: 0.0014\n",
      "Epoch 10/10\n",
      "88/88 [==============================] - 13s 151ms/step - loss: 0.0010 - val_loss: 0.0014\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 9.2251e-04\n",
      "2/2 [==============================] - 0s 12ms/step\n",
      "Score (RMSE): 0.030372873728869886\n",
      "time to execute =  0:26:52.566819\n",
      "Iteration x =  7650  to row-stepsize  7797\n",
      "Model: \"model_13\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_14 (InputLayer)          [(None, 10, 1)]      0           []                               \n",
      "                                                                                                  \n",
      " layer_normalization_104 (Layer  (None, 10, 1)       2           ['input_14[0][0]']               \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " multi_head_attention_52 (Multi  (None, 10, 1)       7169        ['layer_normalization_104[0][0]',\n",
      " HeadAttention)                                                   'layer_normalization_104[0][0]']\n",
      "                                                                                                  \n",
      " dropout_117 (Dropout)          (None, 10, 1)        0           ['multi_head_attention_52[0][0]']\n",
      "                                                                                                  \n",
      " tf.__operators__.add_104 (TFOp  (None, 10, 1)       0           ['dropout_117[0][0]',            \n",
      " Lambda)                                                          'input_14[0][0]']               \n",
      "                                                                                                  \n",
      " layer_normalization_105 (Layer  (None, 10, 1)       2           ['tf.__operators__.add_104[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " conv1d_104 (Conv1D)            (None, 10, 4)        8           ['layer_normalization_105[0][0]']\n",
      "                                                                                                  \n",
      " dropout_118 (Dropout)          (None, 10, 4)        0           ['conv1d_104[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d_105 (Conv1D)            (None, 10, 1)        5           ['dropout_118[0][0]']            \n",
      "                                                                                                  \n",
      " tf.__operators__.add_105 (TFOp  (None, 10, 1)       0           ['conv1d_105[0][0]',             \n",
      " Lambda)                                                          'tf.__operators__.add_104[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_106 (Layer  (None, 10, 1)       2           ['tf.__operators__.add_105[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " multi_head_attention_53 (Multi  (None, 10, 1)       7169        ['layer_normalization_106[0][0]',\n",
      " HeadAttention)                                                   'layer_normalization_106[0][0]']\n",
      "                                                                                                  \n",
      " dropout_119 (Dropout)          (None, 10, 1)        0           ['multi_head_attention_53[0][0]']\n",
      "                                                                                                  \n",
      " tf.__operators__.add_106 (TFOp  (None, 10, 1)       0           ['dropout_119[0][0]',            \n",
      " Lambda)                                                          'tf.__operators__.add_105[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_107 (Layer  (None, 10, 1)       2           ['tf.__operators__.add_106[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " conv1d_106 (Conv1D)            (None, 10, 4)        8           ['layer_normalization_107[0][0]']\n",
      "                                                                                                  \n",
      " dropout_120 (Dropout)          (None, 10, 4)        0           ['conv1d_106[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d_107 (Conv1D)            (None, 10, 1)        5           ['dropout_120[0][0]']            \n",
      "                                                                                                  \n",
      " tf.__operators__.add_107 (TFOp  (None, 10, 1)       0           ['conv1d_107[0][0]',             \n",
      " Lambda)                                                          'tf.__operators__.add_106[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " layer_normalization_108 (Layer  (None, 10, 1)       2           ['tf.__operators__.add_107[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " multi_head_attention_54 (Multi  (None, 10, 1)       7169        ['layer_normalization_108[0][0]',\n",
      " HeadAttention)                                                   'layer_normalization_108[0][0]']\n",
      "                                                                                                  \n",
      " dropout_121 (Dropout)          (None, 10, 1)        0           ['multi_head_attention_54[0][0]']\n",
      "                                                                                                  \n",
      " tf.__operators__.add_108 (TFOp  (None, 10, 1)       0           ['dropout_121[0][0]',            \n",
      " Lambda)                                                          'tf.__operators__.add_107[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_109 (Layer  (None, 10, 1)       2           ['tf.__operators__.add_108[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " conv1d_108 (Conv1D)            (None, 10, 4)        8           ['layer_normalization_109[0][0]']\n",
      "                                                                                                  \n",
      " dropout_122 (Dropout)          (None, 10, 4)        0           ['conv1d_108[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d_109 (Conv1D)            (None, 10, 1)        5           ['dropout_122[0][0]']            \n",
      "                                                                                                  \n",
      " tf.__operators__.add_109 (TFOp  (None, 10, 1)       0           ['conv1d_109[0][0]',             \n",
      " Lambda)                                                          'tf.__operators__.add_108[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_110 (Layer  (None, 10, 1)       2           ['tf.__operators__.add_109[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " multi_head_attention_55 (Multi  (None, 10, 1)       7169        ['layer_normalization_110[0][0]',\n",
      " HeadAttention)                                                   'layer_normalization_110[0][0]']\n",
      "                                                                                                  \n",
      " dropout_123 (Dropout)          (None, 10, 1)        0           ['multi_head_attention_55[0][0]']\n",
      "                                                                                                  \n",
      " tf.__operators__.add_110 (TFOp  (None, 10, 1)       0           ['dropout_123[0][0]',            \n",
      " Lambda)                                                          'tf.__operators__.add_109[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_111 (Layer  (None, 10, 1)       2           ['tf.__operators__.add_110[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " conv1d_110 (Conv1D)            (None, 10, 4)        8           ['layer_normalization_111[0][0]']\n",
      "                                                                                                  \n",
      " dropout_124 (Dropout)          (None, 10, 4)        0           ['conv1d_110[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d_111 (Conv1D)            (None, 10, 1)        5           ['dropout_124[0][0]']            \n",
      "                                                                                                  \n",
      " tf.__operators__.add_111 (TFOp  (None, 10, 1)       0           ['conv1d_111[0][0]',             \n",
      " Lambda)                                                          'tf.__operators__.add_110[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " global_average_pooling1d_13 (G  (None, 10)          0           ['tf.__operators__.add_111[0][0]'\n",
      " lobalAveragePooling1D)                                          ]                                \n",
      "                                                                                                  \n",
      " dense_26 (Dense)               (None, 128)          1408        ['global_average_pooling1d_13[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      " dropout_125 (Dropout)          (None, 128)          0           ['dense_26[0][0]']               \n",
      "                                                                                                  \n",
      " dense_27 (Dense)               (None, 1)            129         ['dropout_125[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 30,281\n",
      "Trainable params: 30,281\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/10\n",
      "88/88 [==============================] - 17s 157ms/step - loss: 0.0012 - val_loss: 0.0015\n",
      "Epoch 2/10\n",
      "88/88 [==============================] - 13s 145ms/step - loss: 0.0011 - val_loss: 0.0014\n",
      "Epoch 3/10\n",
      "88/88 [==============================] - 13s 145ms/step - loss: 0.0011 - val_loss: 0.0014\n",
      "Epoch 4/10\n",
      "88/88 [==============================] - 13s 147ms/step - loss: 0.0010 - val_loss: 0.0014\n",
      "Epoch 5/10\n",
      "88/88 [==============================] - 13s 145ms/step - loss: 0.0010 - val_loss: 0.0014\n",
      "Epoch 6/10\n",
      "88/88 [==============================] - 13s 147ms/step - loss: 0.0010 - val_loss: 0.0014\n",
      "Epoch 7/10\n",
      "88/88 [==============================] - 13s 146ms/step - loss: 9.8726e-04 - val_loss: 0.0014\n",
      "Epoch 8/10\n",
      "88/88 [==============================] - 13s 146ms/step - loss: 9.9569e-04 - val_loss: 0.0014\n",
      "Epoch 9/10\n",
      "88/88 [==============================] - 13s 148ms/step - loss: 9.7704e-04 - val_loss: 0.0014\n",
      "Epoch 10/10\n",
      "88/88 [==============================] - 13s 146ms/step - loss: 0.0010 - val_loss: 0.0014\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 6.3987e-04\n",
      "2/2 [==============================] - 0s 20ms/step\n",
      "Score (RMSE): 0.02529566667365344\n",
      "time to execute =  0:29:06.794332\n",
      "Iteration x =  7700  to row-stepsize  7797\n",
      "Model: \"model_14\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_15 (InputLayer)          [(None, 10, 1)]      0           []                               \n",
      "                                                                                                  \n",
      " layer_normalization_112 (Layer  (None, 10, 1)       2           ['input_15[0][0]']               \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " multi_head_attention_56 (Multi  (None, 10, 1)       7169        ['layer_normalization_112[0][0]',\n",
      " HeadAttention)                                                   'layer_normalization_112[0][0]']\n",
      "                                                                                                  \n",
      " dropout_126 (Dropout)          (None, 10, 1)        0           ['multi_head_attention_56[0][0]']\n",
      "                                                                                                  \n",
      " tf.__operators__.add_112 (TFOp  (None, 10, 1)       0           ['dropout_126[0][0]',            \n",
      " Lambda)                                                          'input_15[0][0]']               \n",
      "                                                                                                  \n",
      " layer_normalization_113 (Layer  (None, 10, 1)       2           ['tf.__operators__.add_112[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " conv1d_112 (Conv1D)            (None, 10, 4)        8           ['layer_normalization_113[0][0]']\n",
      "                                                                                                  \n",
      " dropout_127 (Dropout)          (None, 10, 4)        0           ['conv1d_112[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d_113 (Conv1D)            (None, 10, 1)        5           ['dropout_127[0][0]']            \n",
      "                                                                                                  \n",
      " tf.__operators__.add_113 (TFOp  (None, 10, 1)       0           ['conv1d_113[0][0]',             \n",
      " Lambda)                                                          'tf.__operators__.add_112[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_114 (Layer  (None, 10, 1)       2           ['tf.__operators__.add_113[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " multi_head_attention_57 (Multi  (None, 10, 1)       7169        ['layer_normalization_114[0][0]',\n",
      " HeadAttention)                                                   'layer_normalization_114[0][0]']\n",
      "                                                                                                  \n",
      " dropout_128 (Dropout)          (None, 10, 1)        0           ['multi_head_attention_57[0][0]']\n",
      "                                                                                                  \n",
      " tf.__operators__.add_114 (TFOp  (None, 10, 1)       0           ['dropout_128[0][0]',            \n",
      " Lambda)                                                          'tf.__operators__.add_113[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_115 (Layer  (None, 10, 1)       2           ['tf.__operators__.add_114[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " conv1d_114 (Conv1D)            (None, 10, 4)        8           ['layer_normalization_115[0][0]']\n",
      "                                                                                                  \n",
      " dropout_129 (Dropout)          (None, 10, 4)        0           ['conv1d_114[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d_115 (Conv1D)            (None, 10, 1)        5           ['dropout_129[0][0]']            \n",
      "                                                                                                  \n",
      " tf.__operators__.add_115 (TFOp  (None, 10, 1)       0           ['conv1d_115[0][0]',             \n",
      " Lambda)                                                          'tf.__operators__.add_114[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_116 (Layer  (None, 10, 1)       2           ['tf.__operators__.add_115[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " multi_head_attention_58 (Multi  (None, 10, 1)       7169        ['layer_normalization_116[0][0]',\n",
      " HeadAttention)                                                   'layer_normalization_116[0][0]']\n",
      "                                                                                                  \n",
      " dropout_130 (Dropout)          (None, 10, 1)        0           ['multi_head_attention_58[0][0]']\n",
      "                                                                                                  \n",
      " tf.__operators__.add_116 (TFOp  (None, 10, 1)       0           ['dropout_130[0][0]',            \n",
      " Lambda)                                                          'tf.__operators__.add_115[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_117 (Layer  (None, 10, 1)       2           ['tf.__operators__.add_116[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " conv1d_116 (Conv1D)            (None, 10, 4)        8           ['layer_normalization_117[0][0]']\n",
      "                                                                                                  \n",
      " dropout_131 (Dropout)          (None, 10, 4)        0           ['conv1d_116[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d_117 (Conv1D)            (None, 10, 1)        5           ['dropout_131[0][0]']            \n",
      "                                                                                                  \n",
      " tf.__operators__.add_117 (TFOp  (None, 10, 1)       0           ['conv1d_117[0][0]',             \n",
      " Lambda)                                                          'tf.__operators__.add_116[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_118 (Layer  (None, 10, 1)       2           ['tf.__operators__.add_117[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " multi_head_attention_59 (Multi  (None, 10, 1)       7169        ['layer_normalization_118[0][0]',\n",
      " HeadAttention)                                                   'layer_normalization_118[0][0]']\n",
      "                                                                                                  \n",
      " dropout_132 (Dropout)          (None, 10, 1)        0           ['multi_head_attention_59[0][0]']\n",
      "                                                                                                  \n",
      " tf.__operators__.add_118 (TFOp  (None, 10, 1)       0           ['dropout_132[0][0]',            \n",
      " Lambda)                                                          'tf.__operators__.add_117[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " layer_normalization_119 (Layer  (None, 10, 1)       2           ['tf.__operators__.add_118[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " conv1d_118 (Conv1D)            (None, 10, 4)        8           ['layer_normalization_119[0][0]']\n",
      "                                                                                                  \n",
      " dropout_133 (Dropout)          (None, 10, 4)        0           ['conv1d_118[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d_119 (Conv1D)            (None, 10, 1)        5           ['dropout_133[0][0]']            \n",
      "                                                                                                  \n",
      " tf.__operators__.add_119 (TFOp  (None, 10, 1)       0           ['conv1d_119[0][0]',             \n",
      " Lambda)                                                          'tf.__operators__.add_118[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " global_average_pooling1d_14 (G  (None, 10)          0           ['tf.__operators__.add_119[0][0]'\n",
      " lobalAveragePooling1D)                                          ]                                \n",
      "                                                                                                  \n",
      " dense_28 (Dense)               (None, 128)          1408        ['global_average_pooling1d_14[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      " dropout_134 (Dropout)          (None, 128)          0           ['dense_28[0][0]']               \n",
      "                                                                                                  \n",
      " dense_29 (Dense)               (None, 1)            129         ['dropout_134[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 30,281\n",
      "Trainable params: 30,281\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/10\n",
      "88/88 [==============================] - 16s 145ms/step - loss: 0.0011 - val_loss: 0.0014\n",
      "Epoch 2/10\n",
      "88/88 [==============================] - 12s 138ms/step - loss: 0.0011 - val_loss: 0.0014\n",
      "Epoch 3/10\n",
      "88/88 [==============================] - 12s 136ms/step - loss: 0.0010 - val_loss: 0.0014\n",
      "Epoch 4/10\n",
      "88/88 [==============================] - 12s 137ms/step - loss: 0.0010 - val_loss: 0.0014\n",
      "Epoch 5/10\n",
      "88/88 [==============================] - 12s 138ms/step - loss: 0.0010 - val_loss: 0.0014\n",
      "Epoch 6/10\n",
      "88/88 [==============================] - 12s 137ms/step - loss: 0.0010 - val_loss: 0.0014\n",
      "Epoch 7/10\n",
      "88/88 [==============================] - 12s 136ms/step - loss: 9.9815e-04 - val_loss: 0.0013\n",
      "Epoch 8/10\n",
      "88/88 [==============================] - 12s 137ms/step - loss: 9.9745e-04 - val_loss: 0.0013\n",
      "Epoch 9/10\n",
      "88/88 [==============================] - 12s 137ms/step - loss: 9.9119e-04 - val_loss: 0.0013\n",
      "Epoch 10/10\n",
      "88/88 [==============================] - 12s 138ms/step - loss: 9.6969e-04 - val_loss: 0.0013\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0012\n",
      "2/2 [==============================] - 0s 11ms/step\n",
      "Score (RMSE): 0.03430735374296821\n",
      "time to execute =  0:31:13.038333\n",
      "Iteration x =  7750  to row-stepsize  7797\n",
      "Model: \"model_15\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_16 (InputLayer)          [(None, 10, 1)]      0           []                               \n",
      "                                                                                                  \n",
      " layer_normalization_120 (Layer  (None, 10, 1)       2           ['input_16[0][0]']               \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " multi_head_attention_60 (Multi  (None, 10, 1)       7169        ['layer_normalization_120[0][0]',\n",
      " HeadAttention)                                                   'layer_normalization_120[0][0]']\n",
      "                                                                                                  \n",
      " dropout_135 (Dropout)          (None, 10, 1)        0           ['multi_head_attention_60[0][0]']\n",
      "                                                                                                  \n",
      " tf.__operators__.add_120 (TFOp  (None, 10, 1)       0           ['dropout_135[0][0]',            \n",
      " Lambda)                                                          'input_16[0][0]']               \n",
      "                                                                                                  \n",
      " layer_normalization_121 (Layer  (None, 10, 1)       2           ['tf.__operators__.add_120[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " conv1d_120 (Conv1D)            (None, 10, 4)        8           ['layer_normalization_121[0][0]']\n",
      "                                                                                                  \n",
      " dropout_136 (Dropout)          (None, 10, 4)        0           ['conv1d_120[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d_121 (Conv1D)            (None, 10, 1)        5           ['dropout_136[0][0]']            \n",
      "                                                                                                  \n",
      " tf.__operators__.add_121 (TFOp  (None, 10, 1)       0           ['conv1d_121[0][0]',             \n",
      " Lambda)                                                          'tf.__operators__.add_120[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_122 (Layer  (None, 10, 1)       2           ['tf.__operators__.add_121[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " multi_head_attention_61 (Multi  (None, 10, 1)       7169        ['layer_normalization_122[0][0]',\n",
      " HeadAttention)                                                   'layer_normalization_122[0][0]']\n",
      "                                                                                                  \n",
      " dropout_137 (Dropout)          (None, 10, 1)        0           ['multi_head_attention_61[0][0]']\n",
      "                                                                                                  \n",
      " tf.__operators__.add_122 (TFOp  (None, 10, 1)       0           ['dropout_137[0][0]',            \n",
      " Lambda)                                                          'tf.__operators__.add_121[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_123 (Layer  (None, 10, 1)       2           ['tf.__operators__.add_122[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " conv1d_122 (Conv1D)            (None, 10, 4)        8           ['layer_normalization_123[0][0]']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                                                  \n",
      " dropout_138 (Dropout)          (None, 10, 4)        0           ['conv1d_122[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d_123 (Conv1D)            (None, 10, 1)        5           ['dropout_138[0][0]']            \n",
      "                                                                                                  \n",
      " tf.__operators__.add_123 (TFOp  (None, 10, 1)       0           ['conv1d_123[0][0]',             \n",
      " Lambda)                                                          'tf.__operators__.add_122[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_124 (Layer  (None, 10, 1)       2           ['tf.__operators__.add_123[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " multi_head_attention_62 (Multi  (None, 10, 1)       7169        ['layer_normalization_124[0][0]',\n",
      " HeadAttention)                                                   'layer_normalization_124[0][0]']\n",
      "                                                                                                  \n",
      " dropout_139 (Dropout)          (None, 10, 1)        0           ['multi_head_attention_62[0][0]']\n",
      "                                                                                                  \n",
      " tf.__operators__.add_124 (TFOp  (None, 10, 1)       0           ['dropout_139[0][0]',            \n",
      " Lambda)                                                          'tf.__operators__.add_123[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_125 (Layer  (None, 10, 1)       2           ['tf.__operators__.add_124[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " conv1d_124 (Conv1D)            (None, 10, 4)        8           ['layer_normalization_125[0][0]']\n",
      "                                                                                                  \n",
      " dropout_140 (Dropout)          (None, 10, 4)        0           ['conv1d_124[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d_125 (Conv1D)            (None, 10, 1)        5           ['dropout_140[0][0]']            \n",
      "                                                                                                  \n",
      " tf.__operators__.add_125 (TFOp  (None, 10, 1)       0           ['conv1d_125[0][0]',             \n",
      " Lambda)                                                          'tf.__operators__.add_124[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_126 (Layer  (None, 10, 1)       2           ['tf.__operators__.add_125[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " multi_head_attention_63 (Multi  (None, 10, 1)       7169        ['layer_normalization_126[0][0]',\n",
      " HeadAttention)                                                   'layer_normalization_126[0][0]']\n",
      "                                                                                                  \n",
      " dropout_141 (Dropout)          (None, 10, 1)        0           ['multi_head_attention_63[0][0]']\n",
      "                                                                                                  \n",
      " tf.__operators__.add_126 (TFOp  (None, 10, 1)       0           ['dropout_141[0][0]',            \n",
      " Lambda)                                                          'tf.__operators__.add_125[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_127 (Layer  (None, 10, 1)       2           ['tf.__operators__.add_126[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " conv1d_126 (Conv1D)            (None, 10, 4)        8           ['layer_normalization_127[0][0]']\n",
      "                                                                                                  \n",
      " dropout_142 (Dropout)          (None, 10, 4)        0           ['conv1d_126[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d_127 (Conv1D)            (None, 10, 1)        5           ['dropout_142[0][0]']            \n",
      "                                                                                                  \n",
      " tf.__operators__.add_127 (TFOp  (None, 10, 1)       0           ['conv1d_127[0][0]',             \n",
      " Lambda)                                                          'tf.__operators__.add_126[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " global_average_pooling1d_15 (G  (None, 10)          0           ['tf.__operators__.add_127[0][0]'\n",
      " lobalAveragePooling1D)                                          ]                                \n",
      "                                                                                                  \n",
      " dense_30 (Dense)               (None, 128)          1408        ['global_average_pooling1d_15[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      " dropout_143 (Dropout)          (None, 128)          0           ['dense_30[0][0]']               \n",
      "                                                                                                  \n",
      " dense_31 (Dense)               (None, 1)            129         ['dropout_143[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 30,281\n",
      "Trainable params: 30,281\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/10\n",
      "88/88 [==============================] - 17s 150ms/step - loss: 0.0011 - val_loss: 0.0014\n",
      "Epoch 2/10\n",
      "88/88 [==============================] - 13s 143ms/step - loss: 0.0010 - val_loss: 0.0014\n",
      "Epoch 3/10\n",
      "88/88 [==============================] - 13s 143ms/step - loss: 0.0010 - val_loss: 0.0014\n",
      "Epoch 4/10\n",
      "88/88 [==============================] - 12s 141ms/step - loss: 0.0010 - val_loss: 0.0014\n",
      "Epoch 5/10\n",
      "88/88 [==============================] - 13s 144ms/step - loss: 0.0010 - val_loss: 0.0014\n",
      "Epoch 6/10\n",
      "88/88 [==============================] - 13s 143ms/step - loss: 0.0010 - val_loss: 0.0014\n",
      "Epoch 7/10\n",
      "88/88 [==============================] - 13s 144ms/step - loss: 0.0010 - val_loss: 0.0014\n",
      "Epoch 8/10\n",
      "88/88 [==============================] - 13s 142ms/step - loss: 9.9630e-04 - val_loss: 0.0014\n",
      "Epoch 9/10\n",
      "88/88 [==============================] - 13s 145ms/step - loss: 9.9507e-04 - val_loss: 0.0014\n",
      "Epoch 10/10\n",
      "88/88 [==============================] - 13s 143ms/step - loss: 0.0010 - val_loss: 0.0014\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 7.1799e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 12ms/step\n",
      "Score (RMSE): 0.02679530534425051\n",
      "time to execute =  0:33:24.472333\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n#dfpnl = pd.DataFrame(data = pnls, columns=[\\'cumpnl\\'])\\ndfpnl = pd.DataFrame(data = pnlsOnly, columns=[\\'cumpnl\\'])\\ndfpnl[\\'pnl\\'] = dfpnl[\\'cumpnl\\'] - dfpnl[\\'cumpnl\\'].shift(1)\\n\\ndfpnl[\\'cummax\\'] = dfpnl[\\'cumpnl\\'].cummax()\\nret = dfpnl[\\'pnl\\'].mean()*252\\nvol = dfpnl[\\'pnl\\'].std()*pow(252,0.5)\\ndfpnl[\\'dd\\'] = dfpnl[\\'cummax\\'] - df[\\'cumpnl\\']\\nmdd = dfpnl[\\'dd\\'].max()\\nprint(\"Return = \",ret)\\nprint(\"Vol    = \",vol)\\ninfo =0\\nif(vol>0):\\n    info = ret/vol\\nprint(\"Info  = \",info)\\ncalmar=0\\nif (mdd>0):\\n    calmar = ret/mdd\\nprint(\"MDD  = \",mdd)\\nprint(\"Calmar = \",calmar)\\ndf[\\'cumpnl\\'].plot()\\ndf[\\'cummax\\'].plot()\\n'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SEQUENCE_SIZE   = 10\n",
    "pnls    = []\n",
    "pnlsOnly = []\n",
    "row,col = df.shape\n",
    "start = datetime.datetime.now()\n",
    "\n",
    "for x in range(windowsize,row-stepsize,stepsize):\n",
    "    print(\"Iteration x = \",x,\" to row-stepsize \",row-stepsize)\n",
    "    df_train = df.iloc[x-windowsize:x,:]\n",
    "    df_test  = df.iloc[x:x+stepsize]\n",
    "    df = df.loc[:,input_fields]\n",
    "    spots_train = df_train[target_col].tolist()\n",
    "    spots_test = df_test[target_col].tolist()\n",
    "    #spots_train = df.apply(lambda x: x.tolist(), axis=1).tolist()\n",
    "    #spots_test = df.apply(lambda x: x.tolist(), axis=1).tolist()\n",
    "\n",
    "#    print(\"Training set has {} observations.\".format(len(spots_train)))\n",
    "#    print(\"Test set has {} observations.\".format(len(spots_test)))\n",
    "    x_train,y_train = to_sequences(SEQUENCE_SIZE,spots_train)\n",
    "    x_test,y_test   = to_sequences(SEQUENCE_SIZE,spots_test)\n",
    "\n",
    "#    print(\"Shape of training set: {}\".format(x_train.shape))\n",
    "#    print(\"Shape of test set: {}\".format(x_test.shape))\n",
    "\n",
    "    input_shape = x_train.shape[1:]\n",
    "#    print(input_shape)\n",
    "    \n",
    "    model = build_model(\n",
    "        \n",
    "        input_shape,\n",
    "        head_size=256,\n",
    "        num_heads=4,\n",
    "        ff_dim=4,\n",
    "        num_transformer_blocks=4,\n",
    "        mlp_units=[128],\n",
    "        mlp_dropout=0.4,\n",
    "        dropout=0.25,\n",
    "    )\n",
    "\n",
    "    model.compile(\n",
    "        loss=\"mean_squared_error\",\n",
    "        optimizer=keras.optimizers.Adam(learning_rate=1e-4)\n",
    "    )\n",
    "\n",
    "    model.summary()\n",
    "\n",
    "    callbacks = [keras.callbacks.EarlyStopping(patience=10, \\\n",
    "        restore_best_weights=True)]\n",
    "\n",
    "    model.fit(\n",
    "        x_train,\n",
    "        y_train,\n",
    "        validation_split=0.2,\n",
    "        epochs=10, #200,\n",
    "        batch_size=64,\n",
    "        callbacks=callbacks,\n",
    "    )\n",
    "    finish = datetime.datetime.now()\n",
    "    \n",
    "    model.evaluate(x_test, y_test, verbose=1)\n",
    "\n",
    "\n",
    "\n",
    "    pred = model.predict(x_test)\n",
    "    score = np.sqrt(metrics.mean_squared_error(pred,y_test))\n",
    "    print(\"Score (RMSE): {}\".format(score)) \n",
    "\n",
    "    total   = 0\n",
    "    counter = 0\n",
    "\n",
    "    for x in range(len(pred)):\n",
    "        if pred[x] > 0.0:\n",
    "            total = y_test[x]\n",
    "        elif pred[x] < 0.0:\n",
    "            total = -1*y_test[x]\n",
    "            \n",
    "        pnls.append([x,pred[x],y_test[x],total])\n",
    "        pnlsOnly.append (total)\n",
    "\n",
    "    print(\"time to execute = \",finish-start)\n",
    "\"\"\"\n",
    "#dfpnl = pd.DataFrame(data = pnls, columns=['cumpnl'])\n",
    "dfpnl = pd.DataFrame(data = pnlsOnly, columns=['cumpnl'])\n",
    "dfpnl['pnl'] = dfpnl['cumpnl'] - dfpnl['cumpnl'].shift(1)\n",
    "\n",
    "dfpnl['cummax'] = dfpnl['cumpnl'].cummax()\n",
    "ret = dfpnl['pnl'].mean()*252\n",
    "vol = dfpnl['pnl'].std()*pow(252,0.5)\n",
    "dfpnl['dd'] = dfpnl['cummax'] - df['cumpnl']\n",
    "mdd = dfpnl['dd'].max()\n",
    "print(\"Return = \",ret)\n",
    "print(\"Vol    = \",vol)\n",
    "info =0\n",
    "if(vol>0):\n",
    "    info = ret/vol\n",
    "print(\"Info  = \",info)\n",
    "calmar=0\n",
    "if (mdd>0):\n",
    "    calmar = ret/mdd\n",
    "print(\"MDD  = \",mdd)\n",
    "print(\"Calmar = \",calmar)\n",
    "df['cumpnl'].plot()\n",
    "df['cummax'].plot()\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "640\n",
      "[10, array([0.00175942], dtype=float32), 0.0296875, 0.0296875]\n"
     ]
    }
   ],
   "source": [
    "print(len(pnls))\n",
    "print(pnls[10])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of PNL =  640\n",
      "periods =  32000\n",
      "days =  5333.333333333333\n",
      "days in each step =  8.333333333333334\n"
     ]
    }
   ],
   "source": [
    "print(\"length of PNL = \",len(pnls))\n",
    "x = len(pnls)\n",
    "periods = x*stepsize\n",
    "print(\"periods = \",periods)\n",
    "days = periods/periodsperday\n",
    "print(\"days = \",days)\n",
    "daysperstep = stepsize/periodsperday\n",
    "print(\"days in each step = \",daysperstep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   index      pred    actual       pnl\n",
      "0      0  0.002114 -0.005468 -0.005468\n",
      "1      1  0.000297  0.023436  0.023436\n",
      "2      2 -0.000872 -0.000781  0.000781\n",
      "3      3  0.004190 -0.006250 -0.006250\n",
      "4      4  0.000432 -0.050000 -0.050000\n",
      "     index      pred    actual       pnl  switch    cumpnl\n",
      "635     35 -0.004281 -0.011719  0.011719      -1  0.856232\n",
      "636     36  0.006116 -0.002344 -0.002344       1  0.853888\n",
      "637     37  0.000141 -0.018749 -0.018749       1  0.835139\n",
      "638     38  0.002512 -0.011719 -0.011719       1  0.823420\n",
      "639     39 -0.001300  0.002343 -0.002343      -1  0.821077\n",
      "Return =  0.1710577604166667\n",
      "Vol    =  0.38646794170873716\n",
      "Info  =  0.4426182406239143\n",
      "MDD  =  0.5413977499999998\n",
      "Calmar =  0.31595580221134417\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cols = ['index','pred','actual','pnl']\n",
    "dfpnl = pd.DataFrame(data = pnls, columns=cols)\n",
    "dfpnl['pred'] = dfpnl['pred'].apply(lambda x: x[0])\n",
    "print(dfpnl.head())\n",
    "\n",
    "dfpnl['switch'] = dfpnl['pred'].apply(lambda x  : 1 if x>0 else -1 )\n",
    "dfpnl['pnl'] = dfpnl['switch'] * dfpnl['actual']\n",
    "#dfpnl = dfpnl.assign(pnl = lambda r: r['actual'] if r['pred'] > 0   else -1* r['actual'])\n",
    "\n",
    "\n",
    "for index,row in dfpnl.iterrows():\n",
    "    row['pred2'] = row['pred']\n",
    "    wt = 1.0\n",
    "    if (row['pred']<0):\n",
    "        wt = -1.0\n",
    "    dfpnl.loc[index,'pnl'] = wt * dfpnl.loc[index,'actual']\n",
    "\n",
    "dfpnl['cumpnl'] = dfpnl['pnl'].cumsum()\n",
    "print(dfpnl.tail())\n",
    "dfpnl['cummax'] = dfpnl['cumpnl'].cummax()\n",
    "ret = dfpnl['pnl'].mean()*(252/1.89)\n",
    "vol = dfpnl['pnl'].std()*pow(252/1.89,0.5)\n",
    "dfpnl['dd'] = dfpnl['cummax'] - dfpnl['cumpnl']\n",
    "mdd = dfpnl['dd'].max()\n",
    "print(\"Return = \",ret)\n",
    "print(\"Vol    = \",vol)\n",
    "info =0\n",
    "if(vol>0):\n",
    "    info = ret/vol\n",
    "print(\"Info  = \",info)\n",
    "calmar=0\n",
    "if (mdd>0):\n",
    "    calmar = ret/mdd\n",
    "print(\"MDD  = \",mdd)\n",
    "print(\"Calmar = \",calmar)\n",
    "dfpnl['cumpnl'].plot()\n",
    "dfpnl['cummax'].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfpnl.to_csv(\"c:/data/transformer_output_\" + ticker + \".csv\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_env",
   "language": "python",
   "name": "torch_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
